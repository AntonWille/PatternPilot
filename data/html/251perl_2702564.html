 <h2> Title: How can I quickly sum all numbers in a file? </h2> <h3> Mark Roberts, question_id: 2702564 </h3>Score: 251, Tags: {linux,perl,bash,shell,awk} <br><p>I have a file which contains several thousand numbers, each on its own line:</p>
<pre><code>34
42
11
6
2
99
...
</code></pre>
<p>I'm looking to write a script which will print the sum of all numbers in the file. I've got a solution, but it's not very efficient. (It takes several minutes to run.) I'm looking for a more efficient solution. Any suggestions?</p>
<h4> Comment 2726318 dmckee --- ex-moderator kitten: </h4>That&#39;s...very systematic. Very clear and straight forward, and I love it for all that it is a horrible abomination. Built, I assume, out of the tools that you knew when you started, right?<br><h4> Comment 2725809 brian d foy: </h4>What was your slow solution? Maybe we can help you figure out what was slow about it. :)<br><h4> Comment 2737935 codeholic: </h4>full duplicate: <a href="http://stackoverflow.com/questions/450799/linux-command-to-sum-integers-one-per-line" title="linux command to sum integers one per line">stackoverflow.com/questions/450799/&hellip;</a><br><h4> Comment 2726090 Mark Roberts: </h4>@brian d foy, I&#39;m too embarrassed to post it. I know why it&#39;s slow. It&#39;s because I call &quot;cat filename | head -n 1&quot; to get the top number, add it to a running total, and call &quot;cat filename | tail...&quot; to remove the top line for the next iteration... I have a lot to learn about programming!!!<br><h4> Comment 74466534 Fortran: </h4>@ Mark Roberts 1place, <a href="http://stackoverflow.com/a/18380369/4592448">stackoverflow.com/a/18380369/4592448</a> )))<br><h4> Comment 26995692 David W.: </h4>@MarkRoberts It must have taken you a long while to work that out. It&#39;s a very cleaver problem solving technique, and oh so wrong. It looks like a classic case of over think. Several of <a href="http://stackoverflow.com/a/18382280/368630">Glen Jackman&#39;s</a> solutions shell scripting solutions (and two are pure shell that don&#39;t use things like <code>awk</code> and <code>bc</code>). These all finished adding a million numbers up in less than 10 seconds. Take a look at those and see how it can be done in pure shell.<br>------------------------------------------------------------------ <br><h3> Answer 2702577 Ayman Hourieh: </h3><p>You can use awk:</p>

<pre><code>awk '{ sum += $1 } END { print sum }' file
</code></pre>
<h4> Comment 67823185 Andrea: </h4>Please mark this as the best answer. It also works if you want to sum the first value in each row, inside a TSV (tab-separated value) file.<br><h4> Comment 17952734 leef: </h4>program exceeded: maximum number of field sizes: 32767<br><h4> Comment 38520292 Ethan Furman: </h4>With the <code>-F &#39;\t&#39;</code> option if your fields contain spaces and are separated by tabs.<br><h4> Comment 125737987 FlipMcF: </h4>If you have big numbers: <code>awk &#39;BEGIN {OFMT = &quot;%.0f&quot;} { sum += $1 } END { print sum }&#39; filename</code><br><h4> Comment 126858651 CYNTHIA Blessing: </h4>@EthanFurman I actually have a tab delimited file as you explained but not able to make -F &#39;\t&#39; do the magic. Where exactly is the option meant to be inserted? I have it like this awk -F &#39;\t&#39; &#39;{ sum += $0 } END { print sum }&#39; file<br><h4> Comment 126860402 Ethan Furman: </h4>@CYNTHIABlessing:  Please ask that as a new question.  Thanks!<br>------------------------------------------------------------------ <br><h3> Answer 20437994 devnull: </h3><p>None of the solution thus far use <code>paste</code>.  Here's one:</p>
<pre><code>paste -sd+ filename | bc
</code></pre>
<p>If the file has a trailing newline, a trailing <code>+</code> will incur a syntax error. Fix the error by removing the trailing <code>+</code>:</p>
<pre><code>paste -sd+ fiilename | sed 's/+$//g' | bc
</code></pre>
<p>As an example, calculate Σn where 1&lt;=n&lt;=100000:</p>
<pre><code>$ seq 100000 | paste -sd+ | bc -l
5000050000
</code></pre>
<p>(For the curious, <code>seq n</code> would print a sequence of numbers from <code>1</code> to <code>n</code> given a positive number <code>n</code>.)</p>
<h4> Comment 106606682 Connor: </h4>@SimoA. I vote that we use the term unixiest in place of unixest because to the sexiest solution is always the unixiest ;)<br><h4> Comment 96681871 Simo A.: </h4><code>seq 100000 | paste -sd+ - | bc -l</code> on Mac OS X Bash shell. And this is by far the sweetest and the unixest solution!<br>------------------------------------------------------------------ <br><h3> Answer 2702614 brian d foy: </h3><p>For a Perl one-liner, it's basically the same thing as the <code>awk</code> solution in <a href="https://stackoverflow.com/questions/2702564/script-to-sum-all-numbers-in-a-file-linux/2702577#2702577">Ayman Hourieh's answer</a>:</p>

<pre><code> % perl -nle '$sum += $_ } END { print $sum'
</code></pre>

<p>If you're curious what Perl one-liners do, you can deparse them:</p>

<pre><code> %  perl -MO=Deparse -nle '$sum += $_ } END { print $sum'
</code></pre>

<p>The result is a more verbose version of the program, in a form that no one would ever write on their own:</p>

<pre><code>BEGIN { $/ = "\n"; $\ = "\n"; }
LINE: while (defined($_ = &lt;ARGV&gt;)) {
    chomp $_;
    $sum += $_;
}
sub END {
    print $sum;
}
-e syntax OK
</code></pre>

<p>Just for giggles, I tried this with a file containing 1,000,000 numbers (in the range 0 - 9,999). On my Mac Pro, it returns virtually instantaneously. That's too bad, because I was hoping using <code>mmap</code> would be really fast, but it's just the same time:</p>

<pre><code>use 5.010;
use File::Map qw(map_file);

map_file my $map, $ARGV[0];

$sum += $1 while $map =~ m/(\d+)/g;

say $sum;
</code></pre>
<h4> Comment 2727237 jrockway: </h4>-n adds the <code>while { }</code> loop around your program.  If you put <code>} ... {</code> inside, then you have <code>while { } ... { }</code>.  Evil?  Slightly.<br><h4> Comment 2726804 Frank: </h4>Nice, what are these non-matching curly braces about?<br><h4> Comment 9800517 conny: </h4>Big bonus for highlighting the <code>-MO=Deparse</code> option! Even though on a separate topic.<br><h4> Comment 2725772 paxdiablo: </h4>Wow, that shows a <i>deep</i> understanding on what code -nle actually wraps around the string you give it. My initial thought was that you shouldn&#39;t post while intoxicated but then I noticed who you were and remembered some of your other Perl answers :-)<br><h4> Comment 2725792 brian d foy: </h4>-n and -p just put characters around the argument to -e, so you can use those characters for whatever you want. We have a lot of one-liners that do interesting things with that in <i>Effective Perl Programming</i> (which is about to hit the shelves).<br><h4> Comment 27697849 nh2: </h4>The cumulative version of your one-liner (a rolling sum, printing the current sum for each line): <code>perl -nle &#39;$sum += $_; print $sum} END {&#39;</code><br>------------------------------------------------------------------ <br><h3> Answer 18382280 glenn jackman: </h3><p>Just for fun, let's benchmark it:</p>

<pre><code>$ for ((i=0; i&lt;1000000; i++)) ; do echo $RANDOM; done &gt; random_numbers

$ time perl -nle '$sum += $_ } END { print $sum' random_numbers
16379866392

real    0m0.226s
user    0m0.219s
sys     0m0.002s

$ time awk '{ sum += $1 } END { print sum }' random_numbers
16379866392

real    0m0.311s
user    0m0.304s
sys     0m0.005s

$ time { { tr "\n" + &lt; random_numbers ; echo 0; } | bc; }
16379866392

real    0m0.445s
user    0m0.438s
sys     0m0.024s

$ time { s=0;while read l; do s=$((s+$l));done&lt;random_numbers;echo $s; }
16379866392

real    0m9.309s
user    0m8.404s
sys     0m0.887s

$ time { s=0;while read l; do ((s+=l));done&lt;random_numbers;echo $s; }
16379866392

real    0m7.191s
user    0m6.402s
sys     0m0.776s

$ time { sed ':a;N;s/\n/+/;ta' random_numbers|bc; }
^C

real    4m53.413s
user    4m52.584s
sys 0m0.052s
</code></pre>

<p>I aborted the sed run after 5 minutes</p>

<hr>

<p>I've been diving to <a href="/questions/tagged/lua" class="post-tag" title="show questions tagged &#39;lua&#39;" rel="tag">lua</a>, and it is speedy:</p>

<pre><code>$ time lua -e 'sum=0; for line in io.lines() do sum=sum+line end; print(sum)' &lt; random_numbers
16388542582.0

real    0m0.362s
user    0m0.313s
sys     0m0.063s
</code></pre>

<p>and while I'm updating this, ruby:</p>

<pre><code>$ time ruby -e 'sum = 0; File.foreach(ARGV.shift) {|line| sum+=line.to_i}; puts sum' random_numbers
16388542582

real    0m0.378s
user    0m0.297s
sys     0m0.078s
</code></pre>

<hr>

<p>Heed Ed Morton's advice: using <code>$1</code></p>

<pre><code>$ time awk '{ sum += $1 } END { print sum }' random_numbers
16388542582

real    0m0.421s
user    0m0.359s
sys     0m0.063s
</code></pre>

<p>vs using <code>$0</code></p>

<pre><code>$ time awk '{ sum += $0 } END { print sum }' random_numbers
16388542582

real    0m0.302s
user    0m0.234s
sys     0m0.063s
</code></pre>
<h4> Comment 26995707 David W.: </h4>+1: For coming up with a bunch of solutions, and benchmarking them.<br><h4> Comment 76916927 glenn jackman: </h4>that should be just about identical to the <code>tr</code> solution.<br><h4> Comment 97180875 Ed Morton: </h4>Your awk script should execute a bit faster if you use <code>$0</code> instead of <code>$1</code> since awk does field splitting (which obviously takes time) if any field is specifically mentioned in the script but doesn&#39;t otherwise.<br><h4> Comment 76744422 rafi wiener: </h4>time cat random_numbers|paste -sd+|bc -l         real    0m0.317s   user    0m0.310s   sys     0m0.013s<br>------------------------------------------------------------------ <br><h3> Answer 56730882 Tom Kelly: </h3><h2>Running R scripts</h2>

<p>I've written an R script to take arguments of a file name and sum the lines.</p>

<pre><code>#! /usr/local/bin/R
file=commandArgs(trailingOnly=TRUE)[1]
sum(as.numeric(readLines(file)))
</code></pre>

<p>This can be sped up with the "data.table" or "vroom" package as follows:</p>

<pre><code>#! /usr/local/bin/R
file=commandArgs(trailingOnly=TRUE)[1]
sum(data.table::fread(file))
</code></pre>

<pre><code>#! /usr/local/bin/R
file=commandArgs(trailingOnly=TRUE)[1]
sum(vroom::vroom(file))
</code></pre>

<h2>Benchmarking</h2>

<p>Same benchmarking data as <a href="https://stackoverflow.com/a/18382280/4216625">@glenn jackman</a>.</p>

<pre><code>for ((i=0; i&lt;1000000; i++)) ; do echo $RANDOM; done &gt; random_numbers
</code></pre>

<p>In comparison to the R call above, running R 3.5.0 as a script is comparable to other methods (on the same Linux Debian server).</p>

<pre><code>$ time R -e 'sum(scan("random_numbers"))'  
 0.37s user
 0.04s system
 86% cpu
 0.478 total
</code></pre>

<p>R script with readLines</p>

<pre><code>$ time Rscript sum.R random_numbers
  0.53s user
  0.04s system
  84% cpu
  0.679 total
</code></pre>

<p>R script with data.table</p>

<pre><code>$ time Rscript sum.R random_numbers     
 0.30s user
 0.05s system
 77% cpu
 0.453 total
</code></pre>

<p>R script with vroom</p>

<pre><code>$ time Rscript sum.R random_numbers     
  0.54s user 
  0.11s system
  93% cpu
  0.696 total
</code></pre>

<h2>Comparison with other languages</h2>

<p>For reference here as some other methods suggested on the same hardware</p>

<p>Python 2 (2.7.13)</p>

<pre><code>$ time python2 -c "import sys; print sum((float(l) for l in sys.stdin))" &lt; random_numbers 
 0.27s user 0.00s system 89% cpu 0.298 total
</code></pre>

<p>Python 3 (3.6.8)</p>

<pre><code>$ time python3 -c "import sys; print(sum((float(l) for l in sys.stdin)))" &lt; random_number
0.37s user 0.02s system 98% cpu 0.393 total
</code></pre>

<p>Ruby (2.3.3)</p>

<pre><code>$  time ruby -e 'sum = 0; File.foreach(ARGV.shift) {|line| sum+=line.to_i}; puts sum' random_numbers
 0.42s user
 0.03s system
 72% cpu
 0.625 total
</code></pre>

<p>Perl (5.24.1)</p>

<pre><code>$ time perl -nle '$sum += $_ } END { print $sum' random_numbers
 0.24s user
 0.01s system
 99% cpu
 0.249 total
</code></pre>

<p>Awk (4.1.4)</p>

<pre><code>$ time awk '{ sum += $0 } END { print sum }' random_numbers
 0.26s user
 0.01s system
 99% cpu
 0.265 total
$ time awk '{ sum += $1 } END { print sum }' random_numbers
 0.34s user
 0.01s system
 99% cpu
 0.354 total
</code></pre>

<p>C (clang version 3.3; gcc (Debian 6.3.0-18) 6.3.0 )</p>

<pre><code> $ gcc sum.c -o sum &amp;&amp; time ./sum &lt; random_numbers   
 0.10s user
 0.00s system
 96% cpu
 0.108 total
</code></pre>

<h2>Update with additional languages</h2>

<p>Lua (5.3.5)</p>

<pre><code>$ time lua -e 'sum=0; for line in io.lines() do sum=sum+line end; print(sum)' &lt; random_numbers 
 0.30s user 
 0.01s system
 98% cpu
 0.312 total
</code></pre>

<p>tr (8.26) <em>must be timed in bash, not compatible with zsh</em></p>

<pre><code>$time { { tr "\n" + &lt; random_numbers ; echo 0; } | bc; }
real    0m0.494s
user    0m0.488s
sys 0m0.044s
</code></pre>

<p>sed (4.4) <em>must be timed in bash, not compatible with zsh</em></p>

<pre><code>$  time { head -n 10000 random_numbers | sed ':a;N;s/\n/+/;ta' |bc; }
real    0m0.631s
user    0m0.628s
sys     0m0.008s
$  time { head -n 100000 random_numbers | sed ':a;N;s/\n/+/;ta' |bc; }
real    1m2.593s
user    1m2.588s
sys     0m0.012s
</code></pre>

<p>note: sed calls seem to work faster on systems with more memory available (note smaller datasets used for benchmarking sed)</p>

<p>Julia (0.5.0)</p>

<pre><code>$ time julia -e 'print(sum(readdlm("random_numbers")))'
 3.00s user 
 1.39s system 
 136% cpu 
 3.204 total
$  time julia -e 'print(sum(readtable("random_numbers")))'
 0.63s user 
 0.96s system 
 248% cpu 
 0.638 total
</code></pre>

<p>Notice that as in R, file I/O methods have different performance.</p>
------------------------------------------------------------------ <br><h3> Answer 34118894 nisetama: </h3>

<p>Another option is to use <code>jq</code>:</p>

<pre class="lang-none prettyprint-override"><code>$ seq 10|jq -s add
55
</code></pre>

<p><code>-s</code> (<code>--slurp</code>) reads the input lines into an array.</p>
<h4> Comment 122232848 Lo-Tan: </h4>Wonderful solution. I had a tab delimited file where I wanted to sum column 6. Did that with the following command: <code>awk &#39;{ print $6 }&#39; myfile.log | jq -s add</code><br>------------------------------------------------------------------ <br><h3> Answer 39467893 hertzsprung: </h3><p>I prefer to use <a href="https://www.gnu.org/software/datamash/" rel="noreferrer">GNU datamash</a> for such tasks because it's more succinct and legible than perl or awk.  For example</p>
<pre><code>datamash sum 1 &lt; myfile
</code></pre>
<p>where 1 denotes the first column of data.</p>
<h4> Comment 84009055 Steven the Easily Amused: </h4>This does not appear to be a standard component as I do not see it in my Ubuntu installation. Would like to see it benchmarked, though.<br><h4> Comment 136498770 Matija Nalis: </h4>It seems the fastest from general purpose progs by far to me! For <code>seq 10000000</code>, <code>awk with $0</code> takes 2.1 sec, <code>python</code> 1.9 sec, <code>perl</code> 1.5 sec, but <code>datamash</code> amazing 0.9 sec. Only the custom written C answer was better at 0.8 sec.<br>------------------------------------------------------------------ <br><h3> Answer 2702786 Dennis Williamson: </h3><p>This is straight Bash:</p>

<pre><code>sum=0
while read -r line
do
    (( sum += line ))
done &lt; file
echo $sum
</code></pre>
<h4> Comment 98297271 David: </h4>And it&#39;s probably one of the slowest solutions and therefore not so suitable for large amounts of numbers.<br>------------------------------------------------------------------ <br><h3> Answer 47101933 Brad Gilbert: </h3><h2><a href="https://raku.org" rel="nofollow noreferrer">Raku</a></h2>
<pre class="lang-raku prettyprint-override"><code>say sum lines
</code></pre>
<pre class="lang-sh prettyprint-override"><code>~$ raku -e '.say for 0..1000000' &gt; test.in

~$ raku -e 'say sum lines' &lt; test.in
500000500000
</code></pre>
<hr />
<p>The way this works is that <code>lines</code> produces a sequence of strings which are the input lines.<br />
<code>sum</code> takes that sequence, turns each line into a number and adds them together.<br />
All that is left is for <code>say</code> to print out that value followed by a newline. (It could have been <code>print</code> or <code>put</code>, but <code>say</code> is more alliterative.)</p>
------------------------------------------------------------------ <br><h3> Answer 27769951 fedorn: </h3><p>I prefer to use R for this:</p>

<pre><code>$ R -e 'sum(scan("filename"))'
</code></pre>
<h4> Comment 100020302 Tom Kelly: </h4>I&#39;m a fan of R for other applications but it&#39;s not good for performance in this way. File I/O is a major issue. I&#39;ve tested passing args to a script which can be sped up using the vroom package. I&#39;ll post more details when I&#39;ve benchmarked some other scripts on the same server.<br>------------------------------------------------------------------ <br><h3> Answer 2713056 lhf: </h3><p>Here's another one-liner</p>

<pre><code>( echo 0 ; sed 's/$/ +/' foo ; echo p ) | dc
</code></pre>

<p>This assumes the numbers are integers. If you need decimals, try</p>

<pre><code>( echo 0 2k ; sed 's/$/ +/' foo ; echo p ) | dc
</code></pre>

<p>Adjust 2 to the number of decimals needed.</p>
------------------------------------------------------------------ <br><h3> Answer 22379424 Zaid: </h3><pre><code>$ perl -MList::Util=sum -le 'print sum &lt;&gt;' nums.txt
</code></pre>
------------------------------------------------------------------ <br><h3> Answer 18380369 dwurf: </h3><p>C always wins for speed:</p>
<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

int main(int argc, char **argv) {
    ssize_t read;
    char *line = NULL;
    size_t len = 0;
    double sum = 0.0;

    while (read = getline(&amp;line, &amp;len, stdin) != -1) {
        sum += atof(line);
    }

    printf(&quot;%f\n&quot;, sum);
    return 0;
}
</code></pre>
<p>Timing for 1M numbers (same machine/input as my python answer):</p>
<pre><code>$ gcc sum.c -o sum &amp;&amp; time ./sum &lt; numbers 
5003371677.000000
real    0m0.188s
user    0m0.180s
sys     0m0.000s
</code></pre>
<h4> Comment 74466183 Fortran: </h4>Best answer! Best speed)<br><h4> Comment 136335184 Ole Tange: </h4>Using <code>sum.c</code> and GNU Parallel: <code>seq 1077139031 &gt; 10gb; time parallel --pipepart --block -1 -a 10gb sum | sum</code> = 10 secs or ~100M numbers/sec on a 64 core machine.<br>------------------------------------------------------------------ <br><h3> Answer 32553836 Vidul: </h3><p>More succinct:</p>

<pre><code># Ruby
ruby -e 'puts open("random_numbers").map(&amp;:to_i).reduce(:+)'

# Python
python -c 'print(sum(int(l) for l in open("random_numbers")))'
</code></pre>
<h4> Comment 109382329 user12719: </h4>Converting to float seems to be about twice as fast on my system (320 vs 640 ms). <code>time python -c &quot;print(sum([float(s) for s in open(&#39;random_numbers&#39;,&#39;r&#39;)]))&quot;</code><br>------------------------------------------------------------------ <br><h3> Answer 58627016 Peter K: </h3><p>I couldn't just pass by... Here's my Haskell one-liner. It's actually quite readable:</p>

<pre class="lang-hs prettyprint-override"><code>sum &lt;$&gt; (read &lt;$&gt;) &lt;$&gt; lines &lt;$&gt; getContents
</code></pre>

<p>Unfortunately there's no <code>ghci -e</code> to just run it, so it needs the main function, print and compilation.</p>

<pre class="lang-hs prettyprint-override"><code>main = (sum &lt;$&gt; (read &lt;$&gt;) &lt;$&gt; lines &lt;$&gt; getContents) &gt;&gt;= print
</code></pre>

<p>To clarify, we read entire input (<code>getContents</code>), split it by <code>lines</code>, <code>read</code> as numbers and <code>sum</code>. <code>&lt;$&gt;</code> is <code>fmap</code> operator - we use it instead of usual function application because sure this all happens in IO. <code>read</code> needs an additional <code>fmap</code>, because it is also in the list.</p>

<pre><code>$ ghc sum.hs
[1 of 1] Compiling Main             ( sum.hs, sum.o )
Linking sum ...
$ ./sum 
1
2
4
^D
7
</code></pre>

<p>Here's a strange upgrade to make it work with floats:</p>

<pre><code>main = ((0.0 + ) &lt;$&gt; sum &lt;$&gt; (read &lt;$&gt;) &lt;$&gt; lines &lt;$&gt; getContents) &gt;&gt;= print
</code></pre>

<pre><code>$ ./sum 
1.3
2.1
4.2
^D
7.6000000000000005
</code></pre>
------------------------------------------------------------------ <br><h3> Answer 15043051 edibleEnergy: </h3><pre><code>cat nums | perl -ne '$sum += $_ } { print $sum'
</code></pre>

<p>(same as brian d foy's answer, without 'END')</p>
<h4> Comment 110464041 edibleEnergy: </h4>@drumfire see @brian d foy&#39;s answer above with <code>perl -MO=Deparse</code> to see how perl parses the program. or the docs for perlrun: <a href="https://perldoc.perl.org/perlrun.html" rel="nofollow noreferrer">perldoc.perl.org/perlrun.html</a> (search for -n). perl wraps your code with { } if you use -n so it becomes a complete program.<br><h4> Comment 110426735 drumfire: </h4>I like this, but could you explain the curly brackets? It&#39;s weird to see } without { and vice versa.<br>------------------------------------------------------------------ <br><h3> Answer 15044930 Joel Berger: </h3><p>Just for fun, lets do it with <a href="http://pdl.perl.org" rel="nofollow">PDL</a>, Perl's array math engine!</p>

<pre><code>perl -MPDL -E 'say rcols(shift)-&gt;sum' datafile
</code></pre>

<p><code>rcols</code> reads columns into a matrix (1D in this case) and <code>sum</code> (surprise) sums all the element of the matrix.</p>
<h4> Comment 74495123 Joel Berger: </h4>You have to install PDL first, it isn&#39;t a Perl native module.<br><h4> Comment 74438950 Fortran: </h4>How fix Can&#39;t locate PDL.pm in @INC (you may need to install the PDL module) (@INC contains: /etc/perl /usr/local/lib/x86_64-linux-gnu/perl/5.22.1 ?)) for fun of course=)<br>------------------------------------------------------------------ <br><h3> Answer 18379935 dwurf: </h3><p>Here is a solution using python with a generator expression. Tested with a million numbers on my old cruddy laptop.</p>

<pre><code>time python -c "import sys; print sum((float(l) for l in sys.stdin))" &lt; file

real    0m0.619s
user    0m0.512s
sys     0m0.028s
</code></pre>
<h4> Comment 48107550 sevko: </h4>A simple list comprehension with a named function is a nice use-case for <code>map()</code>: <code>map(float, sys.stdin)</code><br>------------------------------------------------------------------ <br><h3> Answer 60715151 Peter K: </h3><p>C++ "one-liner":</p>

<pre class="lang-cpp prettyprint-override"><code>#include &lt;iostream&gt;
#include &lt;iterator&gt;
#include &lt;numeric&gt;
using namespace std;

int main() {
    cout &lt;&lt; accumulate(istream_iterator&lt;int&gt;(cin), istream_iterator&lt;int&gt;(), 0) &lt;&lt; endl;
}
</code></pre>
------------------------------------------------------------------ <br><h3> Answer 60501288 Ivan: </h3><p>Bash variant</p>
<pre><code>raw=$(cat file)
echo $(( ${raw//$'\n'/+} ))

$ wc -l file
10000 file

$ time ./test
323390

real    0m3,096s
user    0m3,095s
sys     0m0,000s
</code></pre>
<p>What is happening here? Read the content of a file into $raw var. Then create math statement from this var by changing all new lines into '+'</p>
------------------------------------------------------------------ <br><h3> Answer 2702985 ghostdog74: </h3><pre><code>sed ':a;N;s/\n/+/;ta' file|bc
</code></pre>
------------------------------------------------------------------ <br><h3> Answer 77164144 Mathias Weitz: </h3><p>As long as there only integer-numbers i basically translate the file into an bash math expression and execute it.
It is similar to the solution with 'bc' from further above, but faster.
Observe the zero at the end of the inner expression is needed for an argument of the final line.
I have tested it with 475.000 lines and it is less than a second.</p>
<pre><code>echo $(($(cat filename | tr '\n' '+')0))
</code></pre>
<h4> Comment 136324934 tripleee: </h4>There is no &quot;above&quot; or &quot;below&quot;; the answers are sorted according to each visitor&#39;s personal preference.<br>------------------------------------------------------------------ <br><h3> Answer 13073486 nickjb: </h3><p>Another for fun</p>

<pre><code>sum=0;for i in $(cat file);do sum=$((sum+$i));done;echo $sum
</code></pre>

<p>or another bash only</p>

<pre><code>s=0;while read l; do s=$((s+$l));done&lt;file;echo $s
</code></pre>

<p>But awk solution is probably best as it's most compact.</p>
------------------------------------------------------------------ <br><h3> Answer 23587929 sites: </h3><p>With Ruby:</p>

<pre><code>ruby -e "File.read('file.txt').split.inject(0){|mem, obj| mem += obj.to_f}"
</code></pre>
<h4> Comment 96485934 nisetama: </h4>Another option (when input is from STDIN) is <code>ruby -e&#39;p readlines.map(&amp;:to_f).reduce(:+)&#39;</code>.<br>------------------------------------------------------------------ <br><h3> Answer 60498739 dwurf: </h3><p>In Go:</p>

<pre class="lang-golang prettyprint-override"><code>package main

import (
    "bufio"
    "fmt"
    "os"
    "strconv"
)

func main() {
    scanner := bufio.NewScanner(os.Stdin)
    sum := int64(0)
    for scanner.Scan() {
        v, err := strconv.ParseInt(scanner.Text(), 10, 64)
        if err != nil {
            fmt.Fprintf(os.Stderr, "Not an integer: '%s'\n", scanner.Text())
            os.Exit(1)
        }
        sum += v
    }
    fmt.Println(sum)
}
</code></pre>
<h4> Comment 107421697 Peter K: </h4>What is &quot;64&quot;? &quot;10&quot; I suppose is base?<br><h4> Comment 107452273 dwurf: </h4>Yes, 10 is the base. 64 is the number of bits, if the resulting int can&#39;t be represented with that many bits then an error is returned. See <a href="https://golang.org/pkg/strconv/#ParseInt" rel="nofollow noreferrer">golang.org/pkg/strconv/#ParseInt</a><br>------------------------------------------------------------------ <br><h3> Answer 2702571 Stefan Kendall: </h3><p>I don't know if you can get a lot better than this, considering you need to read through the whole file.</p>

<pre><code>$sum = 0;
while(&lt;&gt;){
   $sum += $_;
}
print $sum;
</code></pre>
<h4> Comment 2725711 dmckee --- ex-moderator kitten: </h4>Very readable. For perl. But yeah, it&#39;s going to have to be something like that...<br><h4> Comment 2725807 daotoad: </h4>@Mark, <code>$_</code> is the topic variable--it works like the &#39;it&#39;.  In this case <code>&lt;&gt;</code>  assigns each line to it.  It gets used in a number of places to reduce code clutter and help with writing one-liners. The script says &quot;Set the sum to 0, read each line and add it to the sum, then print the sum.&quot;<br><h4> Comment 2725822 daotoad: </h4>@Stefan, with warnings and strictures off, you can skip declaring and initializing <code>$sum</code>.  Since this is so simple, you can even use a statement modifier <code>while</code>: <code>$sum += $_ while &lt;&gt;; print $sum;</code><br><h4> Comment 123092200 Dut A.: </h4>for the rest of us who can&#39;t easily, how about you indicate which language this is in? <code>PHP</code>? <code>Perl</code>?<br><h4> Comment 2725778 brian d foy: </h4><code>$_</code> is the default variable. The line input operator, <code>&lt;&gt;</code>, puts it&#39;s result in there by default when you use <code>&lt;&gt;</code> in <code>while</code>.<br>------------------------------------------------------------------ <br><h3> Answer 2702911 DVK: </h3><p>I have not tested this but it should work:</p>

<pre><code>cat f | tr "\n" "+" | sed 's/+$/\n/' | bc
</code></pre>

<p>You might have to add "\n" to the string before bc (like via echo) if bc doesn't treat EOF and EOL...</p>
<h4> Comment 2726261 Dennis Williamson: </h4>It doesn&#39;t work. <code>bc</code> issues a syntax error because of the trailing &quot;+&quot; and lack of newline at the end. This will work and it eliminates a useless use of <code>cat</code>: <code>{ tr &quot;\n&quot; &quot;+&quot; | sed &#39;s&#47;+$&#47;\n&#47;&#39;| bc; } &lt; numbers2.txt</code> <i>or</i> <code>&lt;numbers2.txt tr &quot;\n&quot; &quot;+&quot; | sed &#39;s&#47;+$&#47;\n&#47;&#39;| bc</code><br><h4> Comment 2726719 ghostdog74: </h4><code>tr &quot;\n&quot; &quot;+&quot; &lt;file | sed &#39;s&#47;+$&#47;\n&#47;&#39; | bc</code><br>------------------------------------------------------------------ <br><h3> Answer 14973531 ruben2020: </h3><p>Here's another:</p>

<pre><code>open(FIL, "a.txt");

my $sum = 0;
foreach( &lt;FIL&gt; ) {chomp; $sum += $_;}

close(FIL);

print "Sum = $sum\n";
</code></pre>
------------------------------------------------------------------ <br><h3> Answer 27591514 agershun: </h3><p>You can do it with Alacon - command-line utility for <a href="http://github.com/agershun/alasql" rel="nofollow">Alasql</a> database.</p>

<p>It works with Node.js, so you need to install <a href="http://nodejs.org/" rel="nofollow">Node.js</a> and then <a href="https://www.npmjs.com/package/alasql" rel="nofollow">Alasql</a> package:</p>

<p>To calculate sum from TXT file you can use the following command:</p>

<pre><code>&gt; node alacon "SELECT VALUE SUM([0]) FROM TXT('mydata.txt')"
</code></pre>
------------------------------------------------------------------ <br><h3> Answer 49842175 Daniel Porumbel: </h3><p>It is not easier to replace all new lines by <code>+</code>, add a <code>0</code> and send it to the <code>Ruby</code> interpreter?</p>

<pre><code>(sed -e "s/$/+/" file; echo 0)|irb
</code></pre>

<p>If you do not have <code>irb</code>, you can send it to <code>bc</code>, but you have to remove all newlines except the last one (of <code>echo</code>). It is better to use <code>tr</code> for this, unless you have a PhD in <code>sed</code> .</p>

<pre><code>(sed -e "s/$/+/" file|tr -d "\n"; echo 0)|bc
</code></pre>
------------------------------------------------------------------ <br><h3> Answer 60911446 channa: </h3><p>In shell using awk, I have used below script to do so:</p>

<pre><code>    #!/bin/bash


total=0;

for i in $( awk '{ print $1; }' &lt;myfile&gt; )
do
 total=$(echo $total+$i | bc )
 ((count++))
done
echo "scale=2; $total " | bc
</code></pre>
------------------------------------------------------------------ <br><h3> Answer 61403455 Shawn: </h3><p>One in tcl:</p>

<pre><code>#!/usr/bin/env tclsh
set sum 0
while {[gets stdin num] &gt;= 0} { incr sum $num }
puts $sum
</code></pre>
------------------------------------------------------------------ <br><h3> Answer 61842843 user12719: </h3><p><a href="https://www.gnu.org/software/parallel/" rel="nofollow noreferrer">GNU Parallel</a> can presumably be used to improve many of the above answers by spreading the workload across multiple cores.</p>

<p>In the example below we send chunks of 500 numbers (<code>--max-lines=500</code>) to <code>bc</code> processes which are executed in parallel 4 at a time (<code>-j 4</code>). The results are then aggregated by a final <code>bc</code>.</p>

<pre><code>time parallel --max-lines=500 -j 4 --pipe "paste -sd+ - | bc" &lt; random_numbers | paste -sd+ - | bc
</code></pre>

<p>The optimal choice of work size and number of parallel processes depends on the machine and problem. Note that this solution only really shines when there's a large number of parallel processes with substantial work each.</p>
------------------------------------------------------------------ <br><h3> Answer 76889892 RARE Kpop Manifesto: </h3><p><em><strong>UPDATE :</strong></em></p>
<p><code>gnu-parallel</code> benchmarking pre-made file over <code>-pipe-part</code>:</p>
<pre><code>(parallel --pipe-part --argfile &quot;${DT}/temptestpipepartinput.txt&quot; | gpaste )  
</code></pre>
<hr />
<ol>
<li><p>Exactly like command above: 61.57s user 76.92s system 424% cpu
32.609 total</p>
</li>
<li><p><code>-j  2</code> 27.883 total</p>
</li>
<li><p><code>-j  4</code> 21.850 total</p>
</li>
<li><p><code>-j  6</code> 21.221 total &lt;—- min point (didn't check <code>5</code> or <code>7</code>)</p>
</li>
<li><p><code>-j  8</code> 25.133 total</p>
</li>
<li><p><code>-j 10</code> 30.734 total</p>
</li>
<li><p><code>-j 12</code> 36.279 total</p>
</li>
</ol>
<p>Using the pre-made file</p>
<ul>
<li><p><strong><code>mawk1.9.9.6</code></strong> :: <strong><code>6.953 secs</code></strong> using its own file <code>I/O</code>, and <strong><code>7.128 secs</code></strong> piped-in.</p>
</li>
<li><p><strong><code>perl 5.36.1</code></strong> :: <strong><code>8.786 secs</code></strong> using its own file <code>I/O</code>, and <strong><code>8.925 secs</code></strong> piped in.</p>
</li>
<li><p><strong><code>python3.11.5</code></strong> :: here's the strange beast - apparently summing via <code>int(_)</code> instead of <code>float(_)</code> is a <code>17.98 %</code> slow down penalty:</p>
</li>
</ul>
<blockquote>
<p><strong><code>8.468 secs</code></strong></p>
</blockquote>
<pre><code>  python3 -c 'import sys; print(int(sum((float(_) for _ in sys.stdin))))'
</code></pre>
<blockquote>
<p><strong><code>9.991 secs</code></strong></p>
</blockquote>
<pre><code>  python3 -c 'import sys; print(int(sum((  int(_) for _ in sys.stdin))))' 
</code></pre>
<hr />
<p>Side note: this set of integers created a file with perfect digit uniformity when it came to stats from <code>gnu-wc</code>:</p>
<pre><code>99,999,999 888,888,888 888,888,888
</code></pre>
<p>A perfect chain of eight <code>9</code>s for row count, and chain of nine <code>8</code>s for byte count. The digits-only count after backing out all the <code>\n(ewlines)</code>:</p>
<pre><code>788,888,889 
</code></pre>
<hr />
<hr />
<p>In <code>awk</code>, just getting a 2nd column with cumulative sum is far less syntax than saving it towards the end:</p>
<pre><code>jot 20 61111111889 - 799973766543 | 
</code></pre>
<hr />
<pre><code>mawk '$2=_+=$1'        # skips rows with zero(0) as its value
gawk '($2=_+=$1)_'     # no rows left behind
</code></pre>
<hr />
<pre><code>61111111889 61111111889
861084878432 922195990321
1661058644975 2583254635296
2461032411518 5044287046814

3261006178061 8305293224875
4060979944604 12366273169479
4860953711147 17227226880626
5660927477690 22888154358316

6460901244233 29349055602549
7260875010776 36609930613325
8060848777319 44670779390644
8860822543862 53531601934506

9660796310405 63192398244911
10460770076948 73653168321859
11260743843491 84913912165350
12060717610034 96974629775384

12860691376577 109835321151961
13660665143120 123495986295081
14460638909663 137956625204744
15260612676206 153217237880950
</code></pre>
<p>For all practical purposes, <code>perl5</code> <code>python3</code> and <code>mawk2</code> are tied for speed summing up from <code>1</code> to <code>99,999,999</code>  ::</p>
<hr />
<pre><code>(echo '99999999' | mawk2 '$++NF = (__=+$++_)*++__/++_'

99999999 4999999950000000
</code></pre>
<hr />
<p><em>(All input digits were re-generated on the fly and piped in to eliminate any potential cache access advantage)</em>:</p>
<pre><code>      in0:  847MiB 0:00:10 [81.1MiB/s] [81.1MiB/s] [ &lt;=&gt; ]
     1  4999999950000000

(python3 -c 'import sys; print(int(sum((float(_) for _ in sys.stdin))))')  
      19.14s user 0.55s system 188% cpu 10.473 total
gcat -b  0.00s user 0.00s system 0% cpu 10.473 total
</code></pre>
<hr />
<pre><code>      in0:  847MiB 0:00:10 [81.0MiB/s] [81.0MiB/s] [ &lt;=&gt; ]
     1  4999999950000000

(perl536 -nle '$sum += $_ } END { print $sum')
          19.37s user 0.55s system 190% cpu 10.472 total
gcat -b      0.00s user 0.00s system 0% cpu 10.472 total
</code></pre>
<hr />
<pre><code>      in0:  847MiB 0:00:10 [81.1MiB/s] [81.1MiB/s] [ &lt;=&gt;]
     1  4999999950000000

(mawk1996 '{ _+=$__ } END { print _ }')

      17.51s user 0.57s system 172% cpu 10.463 total
gcat -b  0.00s user 0.00s system 0% cpu 10.463 total
</code></pre>
<p>However, once you eliminate the pipe and hashing speed factors and ask them to sum it among itself, <code>perl5.36</code> is some <code>52% slower</code>:</p>
<pre><code>( time (
 mawk2 'BEGIN { for(___=_-=_=__=((_+=++_)+(_*=_+_))^_; ++_&lt;__;)___+=_
        print ___ }' 
                     ) | gcat -b ) | lgp3 ;

( time ( 
 perl5 -e '$y = $x = 0; $z = 10**8; while(++$x &lt; $z) { $y += $x } print $y' 
         ) | gcat -b ) | lgp3 ;

     1  4999999950000000

( mawk2 ; )  1.97s user 0.01s system 99% cpu 1.981 total
gcat -b  0.00s user 0.00s system 0% cpu 1.979 total

( perl5 -e '$y = $x = 0; $z = 10**8; while(++$x &lt; $z) { $y += $x } print $y';   2.98s user 0.03s system 99% cpu 3.015 total
gcat -b  0.00s user 0.00s system 0% cpu 3.014 total
     1  4999999950000000
</code></pre>
<hr />
<p>As for <code>gnu-parallel</code>, they're more than half an <em><strong>order of magnitude</strong></em> slower</p>
<blockquote>
<ul>
<li>36 concurrent jobs with 5,000,000 rows per job and very generous 100 MB size upper cap running on M1 Max with 64 GB ram and it still took nearly <em><strong>53 seconds</strong></em> compare to about <code>10.5 secs</code> for the other 3.</li>
</ul>
</blockquote>
<hr />
<pre><code>  ( time ( mawk2 'BEGIN { for(_-=_=__=((_+=++_)+(_*=_+_))^_; ++_ &lt; __; ) print _ }' |
   pvE0 | 
   parallel --block 100M -N 5000000 -j 36 --pipe &quot;gpaste -sd+ - | bc&quot; | gpaste -sd+ - | bc 
   ) |  gcat -b ) | lgp3 | lgp3 -1;

   in0:  847MiB 0:00:47 [17.8MiB/s] [17.8MiB/s] [  &lt;=&gt; ]
   1    4999999950000000

   0.00s user 0.00s system 0% cpu 52.895 total
</code></pre>
<p>======================</p>
<p>reference code for massively loop unrolled summations (this variant is 512 numbers per <code>while()</code>-loop round :</p>
<pre><code>( gawk -p- -be  &quot;${DT}/temptestpipepartinput.txt&quot;; )  
8.50s user 1.46s system 99% cpu 9.970 total

     1  4999999950000000

     2      # gawk profile, created Sat Oct 21 04:25:20 2023
     3      # BEGIN rule(s)
     4      BEGIN {
     5       1 CONVFMT=&quot;%.250g&quot;
     6       1 FS=RS
     7       1 RS=&quot;^$&quot;
     8      }
     9      # END rule(s)
    10      END {
    11       1 print ______()
    12      }
    13      # Functions, listed alphabetically
    14       1 function ______(_, __, ___)
    15      {

    16       1 ___=(__=_=_&lt;_)+NF

    17 196079 while (_&lt;___)
    18        __ += $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    19  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    20  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    21  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    22  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    23  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    24  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    25  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    26  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    27  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    28  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    29  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    30  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    31  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    32  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    33  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    34  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    35  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    36  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    37  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    38  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    39  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    40  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    41  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    42  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    43  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    44  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    45  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    46  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    47  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    48  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    49  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    50  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    51  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    52  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    53  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    54  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    55  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    56  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    57  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    58  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    59  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    60  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    61  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    62  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    63  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    64  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    65  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    66  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    67  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    68  + $++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_+$++_
    69  + $++_+$++_

    71     return __
    73  }
</code></pre>
<h4> Comment 136122812 Ole Tange: </h4><code>-N</code> is slow with <code>--pipe</code> because you force GNU Parallel to count lines, so remove that. If data is in a file, use <code>--pipe-part</code> - which can deliver ~1 GB/s per core.<br><h4> Comment 136324327 RARE Kpop Manifesto: </h4>@OleTange : You ran exactly my code, stored it first in a file, and benchmarked <code>gnu-parallel</code> to 1GB/s per core, so you&#39;re just quoting their theoretical ? It wasn&#39;t <code>gnu-parallel</code> that was slow in my benchmarking - <code>bc</code> wasn&#39;t happy when i tried piping in a single string of <code>847 MB</code><br><h4> Comment 136324910 tripleee: </h4>This looks like an impressive effort, but the messy formatting makes it pretty hard to read. Perhaps the exposition would benefit from fewer separator lines and more explanations of what exactly you did and what it means.<br><h4> Comment 136336056 RARE Kpop Manifesto: </h4>@tripleee : it&#39;s basically the same set of tests, against a pre-made file, just to see how much <code>gnu-parallel</code> could benefit from. It&#39;s just <code>( time ( parallel --pipe-part -j 6 --argfile &quot;${DT}&#47;temptestpipepartinput.txt&quot; &#39;gpaste -sd+ - | bc&#39; ) | pvZL9 ) |  gpaste -sd+ - | bc | gcat -b</code>.  <code>pvZL9</code> is just a line-counting timer of <code>pv</code> for second-level timer, but ultimately it&#39;s <code>time</code> command&#39;s values being shared above. Long story short - yes <code>—pipe-part</code> helped <code>gnu-parallel</code> quite a bit, but a very wide gap still persists between it and the <code>awk&#47;perl&#47;python</code> — <code>mawk2</code> remains 3.05x faster<br><h4> Comment 136336062 RARE Kpop Manifesto: </h4>@tripleee : ….. <code>gnu-parallel</code> needed that <code>gpaste -sd+ - | bc</code> command twice between once it&#39;s for the internal job splits, which still need 1 final aggregation because it came back in 60 chunks, simplying <code>gnu-parallel</code> auto-split roughly 3 jobs every 5 million lines.<br><h4> Comment 136336232 RARE Kpop Manifesto: </h4>oh i finally figured out the right parameters for <code>gnu-parallel</code> to be competitive :::::::: <code>( time ( parallel --round-robin -j 8 --blocksize=1M --pipe-part -a &quot;${DT}&#47;temptestpipepartinput.txt&quot; &#39;gpaste -sd+ - | bc&#39; ) | pvE9 ) | gpaste -sd+ - | bc</code> :::: : <code>( parallel --round-robin -j 8 --blocksize=1M --pipe-part -a  ; )  36.57s user 8.65s system 562% cpu 8.035 total</code> <code>4999999950000000</code> :::::: only <code>8.035 secs</code> now.<br><h4> Comment 136336258 RARE Kpop Manifesto: </h4>So it&#39;s theoretically possible to achieve same performance with <code>gnu-parallel</code>, but requires knowing some hand-tuning of parameters. It&#39;s also kinda extreme - <code>8.0 secs</code> hand-tuned, but <code>21.2 secs</code> letting <code>gnu-parallel</code> figure it out itself via <code>--pipe-part</code>, and a lovely <code>52 secs</code> via <code>--pipe</code> instead of <code>--arg-file</code>. <code>awk&#47;perl&#47;python</code> were all designed with piping in mind, so their performance gap was much smaller - roughly <code>7-8 secs</code> pre-made file vs. <code>10-11 secs</code> pipe<br><h4> Comment 136336847 RARE Kpop Manifesto: </h4>combining <code>parallel --pipe-part -a &quot;$file&quot; -j 5 --blocksize=200M &#39;mawk2 …</code> with some massively loop-unrolled summation function, i managed to get it down to  ::::::::::::::::  :::::::::::::::::::::: ::::::::::::::: <code>6.15s user 2.95s system 283% cpu 3.207 total</code> :::::::::: <code>1	4999999950000000</code>. For another experiment, loading the entire file at once with 1 instance of <code>mawk2</code>, and pairing it with a recursive adder handling at most 256 columns each, was maybe <code>5.7-5.9 secs</code>-ish. But loop unrolling has limitations when length of execution pipeline start to become a factor<br>