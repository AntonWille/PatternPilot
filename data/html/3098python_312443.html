 <h2> Title: How do I split a list into equally-sized chunks? </h2> <h4> jespern, question_id: 312443 </h4>Score: 3098, Tags: {python,list,split,chunks} <br><p>How do I split a list of arbitrary length into equal sized chunks?</p>
<hr />
<p><sub>See also: <a href="https://stackoverflow.com/q/434287">How to iterate over a list in chunks</a>.<br />
To chunk strings, see <a href="https://stackoverflow.com/questions/9475241">Split string every nth character?</a>.</sub></p>
<h4> traal, Id: 134072608 Score: 0: </h4>This question has a pretty official answer from Python core developer Raymond Hettinger, which refers to the official docs: <a href="https://stackoverflow.com/a/74120449">stackoverflow.com/a/74120449</a><br>------------------------------------------------------------------ <br><h3> Ned Batchelder, Id: 312464, Score: 4392: </h3><p>Here's a generator that yields evenly-sized chunks:</p>
<pre><code>def chunks(lst, n):
    &quot;&quot;&quot;Yield successive n-sized chunks from lst.&quot;&quot;&quot;
    for i in range(0, len(lst), n):
        yield lst[i:i + n]
</code></pre>
<pre><code>import pprint
pprint.pprint(list(chunks(range(10, 75), 10)))
[[10, 11, 12, 13, 14, 15, 16, 17, 18, 19],
 [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],
 [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],
 [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],
 [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],
 [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],
 [70, 71, 72, 73, 74]]
</code></pre>
<p>For Python 2, using <code>xrange</code> instead of <code>range</code>:</p>
<pre><code>def chunks(lst, n):
    &quot;&quot;&quot;Yield successive n-sized chunks from lst.&quot;&quot;&quot;
    for i in xrange(0, len(lst), n):
        yield lst[i:i + n]
</code></pre>
<hr />
<p>Below is a list comprehension one-liner. The method above is preferable, though, since using named functions makes code easier to understand. For Python 3:</p>
<pre><code>[lst[i:i + n] for i in range(0, len(lst), n)]
</code></pre>
<p>For Python 2:</p>
<pre><code>[lst[i:i + n] for i in xrange(0, len(lst), n)]
</code></pre>
<h4> Wayne, Comment 136140770 Score: 15: </h4>Chunking has been added as <code>itertools.batched(iterable, chunk_size)</code> now in Python 3.12, see more <a href="https://docs.python.org/3.12/library/itertools.html#itertools.batched" rel="nofollow noreferrer">here</a>.<br><h4> selle, Comment 133136665 Score: 4: </h4>Your chunks method should be added to stdlib imho<br><h4> ankostis, Comment 133732961 Score: 0: </h4>@selle It&#39;s already in stdlib, it&#39;s called <code>itertools.islice(iterator, chunk_size)</code>.<br><h4> Ned Batchelder, Comment 133736435 Score: 0: </h4>@ankostis <code>islice</code> does something different: it produces one slice of the iterator.<br><h4> ankostis, Comment 133763745 Score: 0: </h4>@NedBatchelder <code>islice()</code> needs a bit of boilerplate to setup a generator out of an iterator, but look how simple <a href="https://stackoverflow.com/a/22045226/548792">this solution</a> is.<br>------------------------------------------------------------------ <br><h3> oremj, Id: 1751478, Score: 658: </h3><p>Something super simple:</p>
<pre><code>def chunks(xs, n):
    n = max(1, n)
    return (xs[i:i+n] for i in range(0, len(xs), n))
</code></pre>
<p>For Python 2, use <code>xrange()</code> instead of <code>range()</code>.</p>
<h4> keepAlive, Comment 121518885 Score: 0: </h4>Using short circuiting, <code>len(l) or 1</code> to deal with empty lists.<br><h4> ankostis, Comment 133733022 Score: 0: </h4>Slow! Prefer <a href="https://docs.python.org/3/library/itertools.html" rel="nofollow noreferrer"><code>itertools.islice()</code></a> instead.<br>------------------------------------------------------------------ <br><h3> Moj, Id: 16935535, Score: 429: </h3><p>I know this is kind of old but nobody yet mentioned <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.array_split.html" rel="noreferrer"><code>numpy.array_split</code></a>:</p>
<pre><code>import numpy as np

lst = range(50)
np.array_split(lst, 5)
</code></pre>
<p>Result:</p>
<pre><code>[array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),
 array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19]),
 array([20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),
 array([30, 31, 32, 33, 34, 35, 36, 37, 38, 39]),
 array([40, 41, 42, 43, 44, 45, 46, 47, 48, 49])]
</code></pre>
<h4> FizxMike, Comment 52802258 Score: 76: </h4>This allows you to set the total number of chunks, not the number of elements per chunk.<br><h4> Galigator, Comment 129310293 Score: 0: </h4>This method change the type of the elements [ [&#39;a&#39;, 1] , [&#39;b&#39;, 2] ] with chunk one may become [ [&#39;a&#39;, &#39;1&#39;] , [&#39;b&#39;, &#39;2&#39;] ]. If type of first element is str then all element become numpy.str_  ...<br><h4> ankostis, Comment 133733055 Score: 0: </h4>It also breaks the lazyness of the iterable and needs O[2x] memory.<br><h4> The_spider, Comment 134173063 Score: 0: </h4>@FizxMike That problem can be solved using <code>np.split(lst, np.arange(0, len(l), chunk_size))</code>, althoug that requires even more memory and time.<br><h4> meferne, Comment 136102053 Score: 0: </h4>The benefit of this solution is that all arrays will be at most different by 1 in size. The accepted answer could have the last chunk a lot shorter.  From the docs: &quot;for an array of length l that should be split into n sections, it returns l % n sub-arrays of size l//n + 1 and the rest of size l//n.&quot;  This approach calculates how many elements would be extra in the last chunk (l % n), and then increases (l % n) arrays by 1 to compensate for that. That&#39;s rather neat, and probably some answer here already coded it like a generator.<br>------------------------------------------------------------------ <br><h3> tzot, Id: 312644, Score: 355: </h3><p>Directly from the (old) Python documentation (recipes for itertools):</p>
<pre><code>from itertools import izip, chain, repeat

def grouper(n, iterable, padvalue=None):
    &quot;grouper(3, 'abcdefg', 'x') --&gt; ('a','b','c'), ('d','e','f'), ('g','x','x')&quot;
    return izip(*[chain(iterable, repeat(padvalue, n-1))]*n)
</code></pre>
<p>The current version, as suggested by J.F.Sebastian:</p>
<pre><code>#from itertools import izip_longest as zip_longest # for Python 2.x
from itertools import zip_longest # for Python 3.x
#from six.moves import zip_longest # for both (uses the six compat library)

def grouper(n, iterable, padvalue=None):
    &quot;grouper(3, 'abcdefg', 'x') --&gt; ('a','b','c'), ('d','e','f'), ('g','x','x')&quot;
    return zip_longest(*[iter(iterable)]*n, fillvalue=padvalue)
</code></pre>
<p>I guess Guido's time machine works‚Äîworked‚Äîwill work‚Äîwill have worked‚Äîwas working again.</p>
<p>These solutions work because <code>[iter(iterable)]*n</code> (or the equivalent in the earlier version) creates <em>one</em> iterator, repeated <code>n</code> times in the list. <code>izip_longest</code> then effectively performs a round-robin of &quot;each&quot; iterator; because this is the same iterator, it is advanced by each such call, resulting in each such zip-roundrobin generating one tuple of <code>n</code> items.</p>
<h3>Python ‚â•3.12</h3>
<p><a href="https://docs.python.org/3/library/itertools.html#itertools.batched" rel="noreferrer">itertools.batched</a> is available.</p>
------------------------------------------------------------------ <br><h3> senderle, Id: 22045226, Score: 304: </h3><p>I'm surprised nobody has thought of using <code>iter</code>'s <a href="http://docs.python.org/2/library/functions.html#iter" rel="noreferrer">two-argument form</a>:</p>

<pre><code>from itertools import islice

def chunk(it, size):
    it = iter(it)
    return iter(lambda: tuple(islice(it, size)), ())
</code></pre>

<p>Demo:</p>

<pre><code>&gt;&gt;&gt; list(chunk(range(14), 3))
[(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, 11), (12, 13)]
</code></pre>

<p>This works with any iterable and produces output lazily. It returns tuples rather than iterators, but I think it has a certain elegance nonetheless. It also doesn't pad; if you want padding, a simple variation on the above will suffice:</p>

<pre><code>from itertools import islice, chain, repeat

def chunk_pad(it, size, padval=None):
    it = chain(iter(it), repeat(padval))
    return iter(lambda: tuple(islice(it, size)), (padval,) * size)
</code></pre>

<p>Demo:</p>

<pre><code>&gt;&gt;&gt; list(chunk_pad(range(14), 3))
[(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, 11), (12, 13, None)]
&gt;&gt;&gt; list(chunk_pad(range(14), 3, 'a'))
[(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, 11), (12, 13, 'a')]
</code></pre>

<p>Like the <code>izip_longest</code>-based solutions, the above <em>always</em> pads. As far as I know, there's no one- or two-line itertools recipe for a function that <em>optionally</em> pads. By combining the above two approaches, this one comes pretty close:</p>

<pre><code>_no_padding = object()

def chunk(it, size, padval=_no_padding):
    if padval == _no_padding:
        it = iter(it)
        sentinel = ()
    else:
        it = chain(iter(it), repeat(padval))
        sentinel = (padval,) * size
    return iter(lambda: tuple(islice(it, size)), sentinel)
</code></pre>

<p>Demo:</p>

<pre><code>&gt;&gt;&gt; list(chunk(range(14), 3))
[(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, 11), (12, 13)]
&gt;&gt;&gt; list(chunk(range(14), 3, None))
[(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, 11), (12, 13, None)]
&gt;&gt;&gt; list(chunk(range(14), 3, 'a'))
[(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, 11), (12, 13, 'a')]
</code></pre>

<p>I believe this is the shortest chunker proposed that offers optional padding.</p>

<p>As Tomasz Gandor <a href="https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks/22045226?noredirect=1#comment93566337_22045226">observed</a>, the two padding chunkers will stop unexpectedly if they encounter a long sequence of pad values. Here's a final variation that works around that problem in a reasonable way:</p>

<pre><code>_no_padding = object()
def chunk(it, size, padval=_no_padding):
    it = iter(it)
    chunker = iter(lambda: tuple(islice(it, size)), ())
    if padval == _no_padding:
        yield from chunker
    else:
        for ch in chunker:
            yield ch if len(ch) == size else ch + (padval,) * (size - len(ch))
</code></pre>

<p>Demo:</p>

<pre><code>&gt;&gt;&gt; list(chunk([1, 2, (), (), 5], 2))
[(1, 2), ((), ()), (5,)]
&gt;&gt;&gt; list(chunk([1, 2, None, None, 5], 2, None))
[(1, 2), (None, None), (5, None)]
</code></pre>
<h4> nikicat, Comment 124722445 Score: 3: </h4>One-liner version:  ``` from itertools import islice from functools import partial  seq = [1,2,3,4,5,6,7] size = 3 result = list(iter(partial(lambda it: tuple(islice(it, size)), iter(seq)), ())) assert result == [(1, 2, 3), (4, 5, 6), (7,)] ```<br>------------------------------------------------------------------ <br><h3> Markus Jarderot, Id: 312467, Score: 125: </h3><p>Here is a generator that work on arbitrary iterables:</p>

<pre><code>def split_seq(iterable, size):
    it = iter(iterable)
    item = list(itertools.islice(it, size))
    while item:
        yield item
        item = list(itertools.islice(it, size))
</code></pre>

<p>Example:</p>

<pre><code>&gt;&gt;&gt; import pprint
&gt;&gt;&gt; pprint.pprint(list(split_seq(xrange(75), 10)))
[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],
 [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],
 [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],
 [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],
 [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],
 [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],
 [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],
 [70, 71, 72, 73, 74]]
</code></pre>
------------------------------------------------------------------ <br><h3> pylang, Id: 52022535, Score: 116: </h3><p><strong>Don't reinvent the wheel.</strong></p>
<p><strong>UPDATE</strong>: A complete solution is found in Python 3.12+ <a href="https://docs.python.org/3.12/library/itertools.html?highlight=batched#itertools.batched" rel="noreferrer"><code>itertools.batched</code></a>.</p>
<p><strong>Given</strong></p>
<pre><code>import itertools as it
import collections as ct

import more_itertools as mit


iterable = range(11)
n = 3
</code></pre>
<p><strong>Code</strong></p>
<p><a href="https://github.com/python/cpython/issues/98363" rel="noreferrer"><em><code>itertools.batched</code></em></a><sup>++</sup></p>
<pre><code>list(it.batched(iterable, n))
# [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10]]
</code></pre>
<hr />
<p><strong>Details</strong></p>
<p>The following non-native approaches were suggested prior to Python 3.12:</p>
<p><a href="https://github.com/more-itertools/more-itertools" rel="noreferrer"><em><code>more_itertools</code></em></a><sup>+</sup></p>
<pre><code>list(mit.chunked(iterable, n))
# [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10]]

list(mit.sliced(iterable, n))
# [range(0, 3), range(3, 6), range(6, 9), range(9, 11)]

list(mit.grouper(n, iterable))
# [(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, None)]

list(mit.windowed(iterable, len(iterable)//n, step=n))
# [(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, None)]

list(mit.chunked_even(iterable, n))
# [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10]]
</code></pre>
<p>(or DIY, if you want)</p>
<p><em>The Standard Library</em></p>
<pre><code>list(it.zip_longest(*[iter(iterable)] * n))
# [(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, None)]
</code></pre>

<pre><code>d = {}
for i, x in enumerate(iterable):
    d.setdefault(i//n, []).append(x)
    

list(d.values())
# [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10]]
</code></pre>

<pre><code>dd = ct.defaultdict(list)
for i, x in enumerate(iterable):
    dd[i//n].append(x)
    

list(dd.values())
# [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10]]
</code></pre>
<p><strong>References</strong></p>
<ul>
<li><a href="https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.chunked" rel="noreferrer"><code>more_itertools.chunked</code></a> (<a href="https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks/16315158#16315158">related posted</a>)</li>
<li><a href="https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.sliced" rel="noreferrer"><code>more_itertools.sliced</code></a></li>
<li><a href="https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.grouper" rel="noreferrer"><code>more_itertools.grouper</code></a> (<a href="https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks/312644#312644">related post</a>)</li>
<li><a href="https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.windowed" rel="noreferrer"><code>more_itertools.windowed</code></a> (see also <a href="https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.stagger" rel="noreferrer"><code>stagger</code></a>, <a href="https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.zip_offset" rel="noreferrer"><code>zip_offset</code></a>)</li>
<li><a href="https://more-itertools.readthedocs.io/en/latest/api.html#more_itertools.chunked_even" rel="noreferrer"><code>more_itertools.chunked_even</code></a></li>
<li><a href="https://docs.python.org/3/library/itertools.html#itertools.zip_longest" rel="noreferrer"><code>zip_longest</code></a> (<a href="https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks/3125186#3125186">related post</a>, <a href="https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks/29009933#29009933">related post</a>)</li>
<li><a href="https://docs.python.org/3/library/stdtypes.html#dict.setdefault" rel="noreferrer"><code>setdefault</code></a> (ordered results requires Python 3.6+)</li>
<li><a href="https://docs.python.org/3/library/collections.html#collections.defaultdict" rel="noreferrer"><code>collections.defaultdict</code></a>  (ordered results requires Python 3.6+)</li>
</ul>
<p><sub><sup>+</sup> A third-party library that implements <a href="https://docs.python.org/3/library/itertools.html#itertools-recipes" rel="noreferrer">itertools recipes</a> and more. <code>&gt; pip install more_itertools</code> </sub></p>
<p><sub><sup>++</sup>Included in Python Standard Library 3.12+.  <code>batched</code> is similar to <code>more_itertools.chunked</code>.</sub></p>
------------------------------------------------------------------ <br><h3> lebenf, Id: 3226719, Score: 91: </h3><p>Simple yet elegant</p>
<pre><code>L = range(1, 1000)
print [L[x:x+10] for x in xrange(0, len(L), 10)]
</code></pre>
<p>or if you prefer:</p>
<pre><code>def chunks(L, n): return [L[x: x+n] for x in xrange(0, len(L), n)]
chunks(L, 10)
</code></pre>
------------------------------------------------------------------ <br><h3> Russia Must Remove Putin, Id: 21767522, Score: 69: </h3><h2>How do you split a list into evenly sized chunks?</h2>
<p>&quot;Evenly sized chunks&quot;, to me, implies that they are all the same length, or barring that option, at <strong>minimal variance</strong> in length. E.g. 5 baskets for 21 items could have the following results:</p>
<pre><code>&gt;&gt;&gt; import statistics
&gt;&gt;&gt; statistics.variance([5,5,5,5,1]) 
3.2
&gt;&gt;&gt; statistics.variance([5,4,4,4,4]) 
0.19999999999999998
</code></pre>
<p>A practical reason to prefer the latter result: if you were using these functions to distribute work, you've built-in the prospect of one likely finishing well before the others, so it would sit around doing nothing while the others continued working hard.</p>
<h3>Critique of other answers here</h3>
<p>When I originally wrote this answer, none of the other answers were evenly sized chunks - they all leave a runt chunk at the end, so they're not well balanced, and have a higher than necessary variance of lengths.</p>
<p>For example, the current top answer ends with:</p>
<pre><code>[60, 61, 62, 63, 64, 65, 66, 67, 68, 69],
[70, 71, 72, 73, 74]]
</code></pre>
<p>Others, like <code>list(grouper(3, range(7)))</code>, and <code>chunk(range(7), 3)</code> both return: <code>[(0, 1, 2), (3, 4, 5), (6, None, None)]</code>. The <code>None</code>'s are just padding, and rather inelegant in my opinion. They are NOT evenly chunking the iterables.</p>
<p>Why can't we divide these better?</p>
<h3>Cycle Solution</h3>
<p>A high-level balanced solution using <code>itertools.cycle</code>, which is the way I might do it today. Here's the setup:</p>
<pre class="lang-py prettyprint-override"><code>from itertools import cycle
items = range(10, 75)
number_of_baskets = 10
</code></pre>
<p>Now we need our lists into which to populate the elements:</p>
<pre><code>baskets = [[] for _ in range(number_of_baskets)]
</code></pre>
<p>Finally, we zip the elements we're going to allocate together with a cycle of the baskets until we run out of elements, which, semantically, it exactly what we want:</p>
<pre><code>for element, basket in zip(items, cycle(baskets)):
    basket.append(element)
</code></pre>
<p>Here's the result:</p>
<pre><code>&gt;&gt;&gt; from pprint import pprint
&gt;&gt;&gt; pprint(baskets)
[[10, 20, 30, 40, 50, 60, 70],
 [11, 21, 31, 41, 51, 61, 71],
 [12, 22, 32, 42, 52, 62, 72],
 [13, 23, 33, 43, 53, 63, 73],
 [14, 24, 34, 44, 54, 64, 74],
 [15, 25, 35, 45, 55, 65],
 [16, 26, 36, 46, 56, 66],
 [17, 27, 37, 47, 57, 67],
 [18, 28, 38, 48, 58, 68],
 [19, 29, 39, 49, 59, 69]]
</code></pre>
<p>To productionize this solution, we write a function, and provide the type annotations:</p>
<pre><code>from itertools import cycle
from typing import List, Any

def cycle_baskets(items: List[Any], maxbaskets: int) -&gt; List[List[Any]]:
    baskets = [[] for _ in range(min(maxbaskets, len(items)))]
    for item, basket in zip(items, cycle(baskets)):
        basket.append(item)
    return baskets
</code></pre>
<p>In the above, we take our list of items, and the max number of baskets. We create a list of empty lists, in which to append each element, in a round-robin style.</p>
<h3>Slices</h3>
<p>Another elegant solution is to use slices - specifically the less-commonly used <strong>step</strong> argument to slices. i.e.:</p>
<pre><code>start = 0
stop = None
step = number_of_baskets

first_basket = items[start:stop:step]
</code></pre>
<p>This is especially elegant in that slices don't care how long the data are - the result, our first basket, is only as long as it needs to be. We'll only need to increment the starting point for each basket.</p>
<p>In fact this could be a one-liner, but we'll go multiline for readability and to avoid an overlong line of code:</p>
<pre><code>from typing import List, Any

def slice_baskets(items: List[Any], maxbaskets: int) -&gt; List[List[Any]]:
    n_baskets = min(maxbaskets, len(items))
    return [items[i::n_baskets] for i in range(n_baskets)]
</code></pre>
<p>And <code>islice</code> from the itertools module will provide a lazily iterating approach, like that which was originally asked for in the question.</p>
<p>I don't expect most use-cases to benefit very much, as the original data is already fully materialized in a list, but for large datasets, it could save nearly half the memory usage.</p>
<pre class="lang-py prettyprint-override"><code>from itertools import islice
from typing import List, Any, Generator
    
def yield_islice_baskets(items: List[Any], maxbaskets: int) -&gt; Generator[List[Any], None, None]:
    n_baskets = min(maxbaskets, len(items))
    for i in range(n_baskets):
        yield islice(items, i, None, n_baskets)
</code></pre>
<p>View results with:</p>
<pre><code>from pprint import pprint

items = list(range(10, 75))
pprint(cycle_baskets(items, 10))
pprint(slice_baskets(items, 10))
pprint([list(s) for s in yield_islice_baskets(items, 10)])
</code></pre>
<h3>Updated prior solutions</h3>
<p>Here's another balanced solution, adapted from a function I've used in production in the past, that uses the modulo operator:</p>
<pre><code>def baskets_from(items, maxbaskets=25):
    baskets = [[] for _ in range(maxbaskets)]
    for i, item in enumerate(items):
        baskets[i % maxbaskets].append(item)
    return filter(None, baskets) 
</code></pre>
<p>And I created a generator that does the same if you put it into a list:</p>
<pre><code>def iter_baskets_from(items, maxbaskets=3):
    '''generates evenly balanced baskets from indexable iterable'''
    item_count = len(items)
    baskets = min(item_count, maxbaskets)
    for x_i in range(baskets):
        yield [items[y_i] for y_i in range(x_i, item_count, baskets)]
    
</code></pre>
<p>And finally, since I see that all of the above functions return elements in a contiguous order (as they were given):</p>
<pre><code>def iter_baskets_contiguous(items, maxbaskets=3, item_count=None):
    '''
    generates balanced baskets from iterable, contiguous contents
    provide item_count if providing a iterator that doesn't support len()
    '''
    item_count = item_count or len(items)
    baskets = min(item_count, maxbaskets)
    items = iter(items)
    floor = item_count // baskets 
    ceiling = floor + 1
    stepdown = item_count % baskets
    for x_i in range(baskets):
        length = ceiling if x_i &lt; stepdown else floor
        yield [items.next() for _ in range(length)]
</code></pre>
<h2>Output</h2>
<p>To test them out:</p>
<pre><code>print(baskets_from(range(6), 8))
print(list(iter_baskets_from(range(6), 8)))
print(list(iter_baskets_contiguous(range(6), 8)))
print(baskets_from(range(22), 8))
print(list(iter_baskets_from(range(22), 8)))
print(list(iter_baskets_contiguous(range(22), 8)))
print(baskets_from('ABCDEFG', 3))
print(list(iter_baskets_from('ABCDEFG', 3)))
print(list(iter_baskets_contiguous('ABCDEFG', 3)))
print(baskets_from(range(26), 5))
print(list(iter_baskets_from(range(26), 5)))
print(list(iter_baskets_contiguous(range(26), 5)))
</code></pre>
<p>Which prints out:</p>
<pre><code>[[0], [1], [2], [3], [4], [5]]
[[0], [1], [2], [3], [4], [5]]
[[0], [1], [2], [3], [4], [5]]
[[0, 8, 16], [1, 9, 17], [2, 10, 18], [3, 11, 19], [4, 12, 20], [5, 13, 21], [6, 14], [7, 15]]
[[0, 8, 16], [1, 9, 17], [2, 10, 18], [3, 11, 19], [4, 12, 20], [5, 13, 21], [6, 14], [7, 15]]
[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11], [12, 13, 14], [15, 16, 17], [18, 19], [20, 21]]
[['A', 'D', 'G'], ['B', 'E'], ['C', 'F']]
[['A', 'D', 'G'], ['B', 'E'], ['C', 'F']]
[['A', 'B', 'C'], ['D', 'E'], ['F', 'G']]
[[0, 5, 10, 15, 20, 25], [1, 6, 11, 16, 21], [2, 7, 12, 17, 22], [3, 8, 13, 18, 23], [4, 9, 14, 19, 24]]
[[0, 5, 10, 15, 20, 25], [1, 6, 11, 16, 21], [2, 7, 12, 17, 22], [3, 8, 13, 18, 23], [4, 9, 14, 19, 24]]
[[0, 1, 2, 3, 4, 5], [6, 7, 8, 9, 10], [11, 12, 13, 14, 15], [16, 17, 18, 19, 20], [21, 22, 23, 24, 25]]
</code></pre>
<p>Notice that the contiguous generator provide chunks in the same length patterns as the other two, but the items are all in order, and they are as evenly divided as one may divide a list of discrete elements.</p>
------------------------------------------------------------------ <br><h3> Tomasz Wysocki, Id: 3125186, Score: 65: </h3><pre><code>def chunk(input, size):
    return map(None, *([iter(input)] * size))
</code></pre>
<h4> Sergey Nudnov, Comment 123652445 Score: 1: </h4>For Python 3.x: <code>return map(lambda *x: x, *([iter(input)] * size))</code>. Yet it drops tail of the list if it cannot be divided in the equal chunks<br><h4> Sergey Nudnov, Comment 123652393 Score: 0: </h4>Doesn&#39;t work in Python 3.8, is that for 2.x?<br>------------------------------------------------------------------ <br><h3> atzz, Id: 312466, Score: 59: </h3><p>If you know list size:</p>

<pre><code>def SplitList(mylist, chunk_size):
    return [mylist[offs:offs+chunk_size] for offs in range(0, len(mylist), chunk_size)]
</code></pre>

<p>If you don't (an iterator):</p>

<pre><code>def IterChunks(sequence, chunk_size):
    res = []
    for item in sequence:
        res.append(item)
        if len(res) &gt;= chunk_size:
            yield res
            res = []
    if res:
        yield res  # yield the last, incomplete, portion
</code></pre>

<p>In the latter case, it can be rephrased in a more beautiful way if you can be sure that the sequence always contains a whole number of chunks of given size (i.e. there is no incomplete last chunk).</p>
------------------------------------------------------------------ <br><h3> Noich, Id: 29009933, Score: 53: </h3><p>I saw the most awesome Python-ish answer in a <a href="https://stackoverflow.com/questions/23286254/convert-list-to-a-list-of-tuples-python">duplicate</a> of this question:</p>

<pre><code>from itertools import zip_longest

a = range(1, 16)
i = iter(a)
r = list(zip_longest(i, i, i))
&gt;&gt;&gt; print(r)
[(1, 2, 3), (4, 5, 6), (7, 8, 9), (10, 11, 12), (13, 14, 15)]
</code></pre>

<p>You can create n-tuple for any n. If <code>a = range(1, 15)</code>, then the result will be:</p>

<pre><code>[(1, 2, 3), (4, 5, 6), (7, 8, 9), (10, 11, 12), (13, 14, None)]
</code></pre>

<p>If the list is divided evenly, then you can replace <code>zip_longest</code> with <code>zip</code>, otherwise the triplet <code>(13, 14, None)</code> would be lost. Python 3 is used above. For Python 2, use <code>izip_longest</code>.</p>
------------------------------------------------------------------ <br><h3> Rian Rizvi, Id: 34322647, Score: 45: </h3><p>Here's the one liner:</p>
<pre><code>[AA[i:i+SS] for i in range(len(AA))[::SS]]
</code></pre>
<p>Details. AA is array, SS is chunk size. For example:</p>
<pre><code>&gt;&gt;&gt; AA=range(10,21);SS=3
&gt;&gt;&gt; [AA[i:i+SS] for i in range(len(AA))[::SS]]
[[10, 11, 12], [13, 14, 15], [16, 17, 18], [19, 20]]
# or [range(10, 13), range(13, 16), range(16, 19), range(19, 21)] in py3
</code></pre>
<p>To expand the ranges in py3 do</p>
<pre><code>(py3) &gt;&gt;&gt; [list(AA[i:i+SS]) for i in range(len(AA))[::SS]]
[[10, 11, 12], [13, 14, 15], [16, 17, 18], [19, 20]]
</code></pre>
------------------------------------------------------------------ <br><h3> nirvana-msu, Id: 59266741, Score: 36: </h3><p>With <a href="https://www.python.org/dev/peps/pep-0572/" rel="noreferrer">Assignment Expressions</a> in Python 3.8 it becomes quite nice:</p>
<pre class="lang-py prettyprint-override"><code>import itertools

def batch(iterable, size):
    it = iter(iterable)
    while item := list(itertools.islice(it, size)):
        yield item
</code></pre>
<p>This works on an arbitrary iterable, not just a list.</p>
<pre class="lang-py prettyprint-override"><code>&gt;&gt;&gt; import pprint
&gt;&gt;&gt; pprint.pprint(list(batch(range(75), 10)))
[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],
 [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],
 [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],
 [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],
 [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],
 [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],
 [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],
 [70, 71, 72, 73, 74]]
</code></pre>
<p><strong>UPDATE</strong></p>
<p>Starting with Python 3.12, this exact implementation is available as <a href="https://docs.python.org/3.12/library/itertools.html#itertools.batched" rel="noreferrer">itertools.batched</a></p>
------------------------------------------------------------------ <br><h3> ninjagecko, Id: 5711993, Score: 30: </h3><p>If you had a chunk size of 3 for example, you could do:</p>

<pre><code>zip(*[iterable[i::3] for i in range(3)]) 
</code></pre>

<p>source:
<a href="http://code.activestate.com/recipes/303060-group-a-list-into-sequential-n-tuples/">http://code.activestate.com/recipes/303060-group-a-list-into-sequential-n-tuples/</a></p>

<p>I would use this when my chunk size is fixed number I can type, e.g. '3', and would never change.</p>
<h4> sherbang, Comment 14896419 Score: 16: </h4>This doesn&#39;t work if len(iterable)%3 != 0.  The last (short) group of numbers won&#39;t be returned.<br><h4> xuiqzy, Comment 125031007 Score: 1: </h4>@sherbang There is <code>zip_longest</code> from <code>itertools</code>: <a href="https://docs.python.org/3/library/itertools.html#itertools.zip_longest" rel="nofollow noreferrer">docs.python.org/3/library/itertools.html#itertools.zip_longe&zwnj;&#8203;st</a><br><h4> Karl Knechtel, Comment 134521807 Score: 0: </h4>See <a href="https://stackoverflow.com/questions/2233204">this other Stack Overflow question</a> for a detailed explanation of this technique.<br>------------------------------------------------------------------ <br><h3> zach, Id: 20106816, Score: 27: </h3><p>The <a href="https://github.com/pytoolz/toolz">toolz</a> library has the <code>partition</code> function for this:</p>

<pre><code>from toolz.itertoolz.core import partition

list(partition(2, [1, 2, 3, 4]))
[(1, 2), (3, 4)]
</code></pre>
------------------------------------------------------------------ <br><h3> Alex T, Id: 48135727, Score: 24: </h3><p>I was curious about the performance of different approaches and here it is:</p>

<p>Tested on Python 3.5.1</p>

<pre><code>import time
batch_size = 7
arr_len = 298937

#---------slice-------------

print("\r\nslice")
start = time.time()
arr = [i for i in range(0, arr_len)]
while True:
    if not arr:
        break

    tmp = arr[0:batch_size]
    arr = arr[batch_size:-1]
print(time.time() - start)

#-----------index-----------

print("\r\nindex")
arr = [i for i in range(0, arr_len)]
start = time.time()
for i in range(0, round(len(arr) / batch_size + 1)):
    tmp = arr[batch_size * i : batch_size * (i + 1)]
print(time.time() - start)

#----------batches 1------------

def batch(iterable, n=1):
    l = len(iterable)
    for ndx in range(0, l, n):
        yield iterable[ndx:min(ndx + n, l)]

print("\r\nbatches 1")
arr = [i for i in range(0, arr_len)]
start = time.time()
for x in batch(arr, batch_size):
    tmp = x
print(time.time() - start)

#----------batches 2------------

from itertools import islice, chain

def batch(iterable, size):
    sourceiter = iter(iterable)
    while True:
        batchiter = islice(sourceiter, size)
        yield chain([next(batchiter)], batchiter)


print("\r\nbatches 2")
arr = [i for i in range(0, arr_len)]
start = time.time()
for x in batch(arr, batch_size):
    tmp = x
print(time.time() - start)

#---------chunks-------------
def chunks(l, n):
    """Yield successive n-sized chunks from l."""
    for i in range(0, len(l), n):
        yield l[i:i + n]
print("\r\nchunks")
arr = [i for i in range(0, arr_len)]
start = time.time()
for x in chunks(arr, batch_size):
    tmp = x
print(time.time() - start)

#-----------grouper-----------

from itertools import zip_longest # for Python 3.x
#from six.moves import zip_longest # for both (uses the six compat library)

def grouper(iterable, n, padvalue=None):
    "grouper(3, 'abcdefg', 'x') --&gt; ('a','b','c'), ('d','e','f'), ('g','x','x')"
    return zip_longest(*[iter(iterable)]*n, fillvalue=padvalue)

arr = [i for i in range(0, arr_len)]
print("\r\ngrouper")
start = time.time()
for x in grouper(arr, batch_size):
    tmp = x
print(time.time() - start)
</code></pre>

<p><strong>Results:</strong></p>

<pre><code>slice
31.18285083770752

index
0.02184295654296875

batches 1
0.03503894805908203

batches 2
0.22681021690368652

chunks
0.019841909408569336

grouper
0.006506919860839844
</code></pre>
------------------------------------------------------------------ <br><h3> Moinuddin Quadri, Id: 41904532, Score: 21: </h3><p>You may also use <a href="http://utilspie.readthedocs.io/en/latest/#get-chunks" rel="noreferrer"><code>get_chunks</code></a> function of <a href="http://utilspie.readthedocs.io" rel="noreferrer"><code>utilspie</code></a> library as:</p>

<pre><code>&gt;&gt;&gt; from utilspie import iterutils
&gt;&gt;&gt; a = [1, 2, 3, 4, 5, 6, 7, 8, 9]

&gt;&gt;&gt; list(iterutils.get_chunks(a, 5))
[[1, 2, 3, 4, 5], [6, 7, 8, 9]]
</code></pre>

<p>You can install <a href="https://pypi.python.org/pypi/utilspie" rel="noreferrer"><code>utilspie</code></a> via pip:</p>

<pre><code>sudo pip install utilspie
</code></pre>

<p><em>Disclaimer: I am the creator of <a href="https://github.com/moin18/utilspie" rel="noreferrer">utilspie</a> library</em>.</p>
------------------------------------------------------------------ <br><h3> nikipore, Id: 19264525, Score: 19: </h3><p>I like the Python doc's version proposed by tzot and J.F.Sebastian a lot,
 but it has two shortcomings:</p>

<ul>
<li>it is not very explicit</li>
<li>I usually don't want a fill value in the last chunk</li>
</ul>

<p>I'm using this one a lot in my code:</p>

<pre><code>from itertools import islice

def chunks(n, iterable):
    iterable = iter(iterable)
    while True:
        yield tuple(islice(iterable, n)) or iterable.next()
</code></pre>

<p>UPDATE: A lazy chunks version:</p>

<pre><code>from itertools import chain, islice

def chunks(n, iterable):
   iterable = iter(iterable)
   while True:
       yield chain([next(iterable)], islice(iterable, n-1))
</code></pre>
------------------------------------------------------------------ <br><h3> Art B, Id: 31178232, Score: 17: </h3><p>code:</p>

<pre><code>def split_list(the_list, chunk_size):
    result_list = []
    while the_list:
        result_list.append(the_list[:chunk_size])
        the_list = the_list[chunk_size:]
    return result_list

a_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]

print split_list(a_list, 3)
</code></pre>

<p>result:</p>

<pre><code>[[1, 2, 3], [4, 5, 6], [7, 8, 9], [10]]
</code></pre>
------------------------------------------------------------------ <br><h3> slav0nic, Id: 312472, Score: 13: </h3><p>heh, one line version</p>

<pre><code>In [48]: chunk = lambda ulist, step:  map(lambda i: ulist[i:i+step],  xrange(0, len(ulist), step))

In [49]: chunk(range(1,100), 10)
Out[49]: 
[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
 [11, 12, 13, 14, 15, 16, 17, 18, 19, 20],
 [21, 22, 23, 24, 25, 26, 27, 28, 29, 30],
 [31, 32, 33, 34, 35, 36, 37, 38, 39, 40],
 [41, 42, 43, 44, 45, 46, 47, 48, 49, 50],
 [51, 52, 53, 54, 55, 56, 57, 58, 59, 60],
 [61, 62, 63, 64, 65, 66, 67, 68, 69, 70],
 [71, 72, 73, 74, 75, 76, 77, 78, 79, 80],
 [81, 82, 83, 84, 85, 86, 87, 88, 89, 90],
 [91, 92, 93, 94, 95, 96, 97, 98, 99]]
</code></pre>
<h4> S.Lott, Comment 155125 Score: 38: </h4>Please, use &quot;def chunk&quot; instead of &quot;chunk = lambda&quot;.  It works the same.  One line.  Same features.  MUCH easier to the n00bz to read and understand.<br><h4> Terry Jan Reedy, Comment 14734130 Score: 21: </h4>The function object resulting from <code>def chunk</code> instead of <code>chunk=lambda</code> has .__name__ attribute &#39;chunk&#39; instead of &#39;&lt;lambda&gt;&#39;. The specific name is more useful in tracebacks.<br>------------------------------------------------------------------ <br><h3> Ranaivo, Id: 28786255, Score: 13: </h3><p>Another more explicit version.</p>

<pre><code>def chunkList(initialList, chunkSize):
    """
    This function chunks a list into sub lists 
    that have a length equals to chunkSize.

    Example:
    lst = [3, 4, 9, 7, 1, 1, 2, 3]
    print(chunkList(lst, 3)) 
    returns
    [[3, 4, 9], [7, 1, 1], [2, 3]]
    """
    finalList = []
    for i in range(0, len(initialList), chunkSize):
        finalList.append(initialList[i:i+chunkSize])
    return finalList
</code></pre>
------------------------------------------------------------------ <br><h3> sereizam, Id: 33510840, Score: 13: </h3><p>At this point, I think we need a <strong>recursive generator</strong>, just in case...</p>

<p>In python 2:</p>

<pre><code>def chunks(li, n):
    if li == []:
        return
    yield li[:n]
    for e in chunks(li[n:], n):
        yield e
</code></pre>

<p>In python 3:</p>

<pre><code>def chunks(li, n):
    if li == []:
        return
    yield li[:n]
    yield from chunks(li[n:], n)
</code></pre>

<p>Also, in case of massive Alien invasion, a <strong>decorated recursive generator</strong> might become handy:</p>

<pre><code>def dec(gen):
    def new_gen(li, n):
        for e in gen(li, n):
            if e == []:
                return
            yield e
    return new_gen

@dec
def chunks(li, n):
    yield li[:n]
    for e in chunks(li[n:], n):
        yield e
</code></pre>
------------------------------------------------------------------ <br><h3> Mars, Id: 2270932, Score: 12: </h3><p>Without calling len() which is good for large lists:</p>

<pre><code>def splitter(l, n):
    i = 0
    chunk = l[:n]
    while chunk:
        yield chunk
        i += n
        chunk = l[i:i+n]
</code></pre>

<p>And this is for iterables:</p>

<pre><code>def isplitter(l, n):
    l = iter(l)
    chunk = list(islice(l, n))
    while chunk:
        yield chunk
        chunk = list(islice(l, n))
</code></pre>

<p>The functional flavour of the above:</p>

<pre><code>def isplitter2(l, n):
    return takewhile(bool,
                     (tuple(islice(start, n))
                            for start in repeat(iter(l))))
</code></pre>

<p>OR:</p>

<pre><code>def chunks_gen_sentinel(n, seq):
    continuous_slices = imap(islice, repeat(iter(seq)), repeat(0), repeat(n))
    return iter(imap(tuple, continuous_slices).next,())
</code></pre>

<p>OR:</p>

<pre><code>def chunks_gen_filter(n, seq):
    continuous_slices = imap(islice, repeat(iter(seq)), repeat(0), repeat(n))
    return takewhile(bool,imap(tuple, continuous_slices))
</code></pre>
<h4> Thomas Wouters, Comment 7179177 Score: 18: </h4>There is no reason to avoid <code>len()</code> on large lists; it&#39;s a constant-time operation.<br>------------------------------------------------------------------ <br><h3> Corey Goldberg, Id: 314771, Score: 11: </h3><pre><code>def split_seq(seq, num_pieces):
    start = 0
    for i in xrange(num_pieces):
        stop = start + len(seq[i::num_pieces])
        yield seq[start:stop]
        start = stop
</code></pre>

<p>usage:</p>

<pre><code>seq = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]

for seq in split_seq(seq, 3):
    print seq
</code></pre>
------------------------------------------------------------------ <br><h3> macm, Id: 14937534, Score: 11: </h3><p>See <a href="http://docs.python.org/3.3/library/functions.html?highlight=zip#zip" rel="noreferrer">this reference</a></p>

<pre><code>&gt;&gt;&gt; orange = range(1, 1001)
&gt;&gt;&gt; otuples = list( zip(*[iter(orange)]*10))
&gt;&gt;&gt; print(otuples)
[(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), ... (991, 992, 993, 994, 995, 996, 997, 998, 999, 1000)]
&gt;&gt;&gt; olist = [list(i) for i in otuples]
&gt;&gt;&gt; print(olist)
[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], ..., [991, 992, 993, 994, 995, 996, 997, 998, 999, 1000]]
&gt;&gt;&gt; 
</code></pre>

<p>Python3</p>
<h4> Alfe, Comment 26750302 Score: 4: </h4>Nice, but drops elements at the end if the size does not match whole numbers of chunks, e. g. <code>zip(*[iter(range(7))]*3)</code> only returns <code>[(0, 1, 2), (3, 4, 5)]</code> and forgets the <code>6</code> from the input.<br><h4> Karl Knechtel, Comment 134521823 Score: 0: </h4>See <a href="https://stackoverflow.com/questions/2233204">this other Stack Overflow question</a> for a detailed explanation of this technique.<br>------------------------------------------------------------------ <br><h3> Rusty Rob, Id: 9255750, Score: 8: </h3><pre><code>def chunks(iterable,n):
    """assumes n is an integer&gt;0
    """
    iterable=iter(iterable)
    while True:
        result=[]
        for i in range(n):
            try:
                a=next(iterable)
            except StopIteration:
                break
            else:
                result.append(a)
        if result:
            yield result
        else:
            break

g1=(i*i for i in range(10))
g2=chunks(g1,3)
print g2
'&lt;generator object chunks at 0x0337B9B8&gt;'
print list(g2)
'[[0, 1, 4], [9, 16, 25], [36, 49, 64], [81]]'
</code></pre>
------------------------------------------------------------------ <br><h3> vishes_shell, Id: 40409475, Score: 8: </h3><p>Since everybody here talking about iterators. <a href="https://boltons.readthedocs.io/" rel="noreferrer"><code>boltons</code></a> has perfect method for that, called <a href="https://boltons.readthedocs.io/en/latest/iterutils.html#boltons.iterutils.chunked_iter" rel="noreferrer"><code>iterutils.chunked_iter</code></a>.</p>

<pre><code>from boltons import iterutils

list(iterutils.chunked_iter(list(range(50)), 11))
</code></pre>

<p>Output:</p>

<pre><code>[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
 [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21],
 [22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32],
 [33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43],
 [44, 45, 46, 47, 48, 49]]
</code></pre>

<p>But if you don't want to be mercy on memory, you can use old-way and store the full <code>list</code> in the first place with <a href="https://boltons.readthedocs.io/en/latest/iterutils.html#boltons.iterutils.chunked" rel="noreferrer"><code>iterutils.chunked</code></a>.</p>
------------------------------------------------------------------ <br><h3> schwater, Id: 5872632, Score: 7: </h3><p>Consider using <a href="http://matplotlib.sourceforge.net/" rel="noreferrer">matplotlib.cbook</a> pieces</p>

<p>for example:</p>

<pre><code>import matplotlib.cbook as cbook
segments = cbook.pieces(np.arange(20), 3)
for s in segments:
     print s
</code></pre>
------------------------------------------------------------------ <br><h3> AdvilUser, Id: 31442939, Score: 6: </h3><pre><code>a = [1, 2, 3, 4, 5, 6, 7, 8, 9]
CHUNK = 4
[a[i*CHUNK:(i+1)*CHUNK] for i in xrange((len(a) + CHUNK - 1) / CHUNK )]
</code></pre>
<h4> Zulu, Comment 50855622 Score: 0: </h4>Can you explain more your answer please ?<br><h4> AdvilUser, Comment 51320329 Score: 0: </h4>Working from backwards:      (len(a) + CHUNK -1) / CHUNK  Gives you the number of chunks that you will end up with.  Then, for each chunk at index i, we are generating a sub-array of the original array like this:      a[ i * CHUNK : (i + 1) * CHUNK ]  where,      i * CHUNK is the index of the first element to put into the subarray, and,     (i + 1) * CHUNK is 1 past the last element to put into the subarray.  This solution uses list comprehension, so it might be faster for large arrays.<br>------------------------------------------------------------------ <br><h3> hcvst, Id: 1668586, Score: 5: </h3><pre><code>&gt;&gt;&gt; def f(x, n, acc=[]): return f(x[n:], n, acc+[(x[:n])]) if x else acc
&gt;&gt;&gt; f("Hallo Welt", 3)
['Hal', 'lo ', 'Wel', 't']
&gt;&gt;&gt; 
</code></pre>

<p>If you are into brackets - I picked up a book on Erlang :)</p>
------------------------------------------------------------------ <br><h3> user1628890, Id: 12150728, Score: 5: </h3><p>I realise this question is old (stumbled over it on Google), but surely something like the following is far simpler and clearer than any of the huge complex suggestions and only uses slicing:</p>

<pre><code>def chunker(iterable, chunksize):
    for i,c in enumerate(iterable[::chunksize]):
        yield iterable[i*chunksize:(i+1)*chunksize]

&gt;&gt;&gt; for chunk in chunker(range(0,100), 10):
...     print list(chunk)
... 
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[20, 21, 22, 23, 24, 25, 26, 27, 28, 29]
... etc ...
</code></pre>
------------------------------------------------------------------ <br><h3> Saksham Varma, Id: 28756559, Score: 5: </h3><p>Use list comprehensions:</p>

<pre><code>l = [1,2,3,4,5,6,7,8,9,10,11,12]
k = 5 #chunk size
print [tuple(l[x:y]) for (x, y) in [(x, x+k) for x in range(0, len(l), k)]]
</code></pre>
------------------------------------------------------------------ <br><h3> Alex, Id: 40700737, Score: 5: </h3><p>You could use numpy's array_split function e.g., <code>np.array_split(np.array(data), 20)</code> to split into 20 nearly equal size chunks.</p>

<p>To make sure chunks are exactly equal in size use <code>np.split</code>.</p>
------------------------------------------------------------------ <br><h3> –ê–Ω–∞—Ç–æ–ª–∏–π –ü–∞–Ω–∏–Ω, Id: 43454601, Score: 5: </h3><p>One more solution</p>

<pre><code>def make_chunks(data, chunk_size): 
    while data:
        chunk, data = data[:chunk_size], data[chunk_size:]
        yield chunk

&gt;&gt;&gt; for chunk in make_chunks([1, 2, 3, 4, 5, 6, 7], 2):
...     print chunk
... 
[1, 2]
[3, 4]
[5, 6]
[7]
&gt;&gt;&gt; 
</code></pre>
------------------------------------------------------------------ <br><h3> George B, Id: 47096024, Score: 5: </h3><p>I don't think I saw this option, so just to add another one :)) :</p>

<pre><code>def chunks(iterable, chunk_size):
  i = 0;
  while i &lt; len(iterable):
    yield iterable[i:i+chunk_size]
    i += chunk_size
</code></pre>
------------------------------------------------------------------ <br><h3> Ravi Anand, Id: 56954384, Score: 5: </h3><p>python <code>pydash</code> package could be a good choice. </p>

<pre><code>from pydash.arrays import chunk
ids = ['22', '89', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '1']
chunk_ids = chunk(ids,5)
print(chunk_ids)
# output: [['22', '89', '2', '3', '4'], ['5', '6', '7', '8', '9'], ['10', '11', '1']]
</code></pre>

<p>for more checkout <a href="https://pydash.readthedocs.io/en/latest/api.html?highlight=chunk%20list" rel="noreferrer">pydash chunk list</a></p>
<h4> Dariusz Krynicki, Comment 107725845 Score: 0: </h4>neat! and this is what actualy sits under the hood of pydash.arrays.chunk: chunks = int(ceil(len(array) / float(size))) return [array[i * size:(i + 1) * size] for i in range(chunks)]<br>------------------------------------------------------------------ <br><h3> Raymond Hettinger, Id: 74120449, Score: 5: </h3><p>The <a href="https://docs.python.org/3/library/itertools.html#itertools-recipes" rel="nofollow noreferrer">recipes in the itertools module</a> provide two ways to do this depending on how you want to handle a final odd-sized lot (keep it, pad it with a fillvalue, ignore it, or raise an exception):</p>
<pre><code>from itertools import islice, izip_longest

def batched(iterable, n):
    &quot;Batch data into tuples of length n. The last batch may be shorter.&quot;
    # batched('ABCDEFG', 3) --&gt; ABC DEF G
    it = iter(iterable)
    while True:
        batch = tuple(islice(it, n))
        if not batch:
            return
        yield batch

def grouper(iterable, n, *, incomplete='fill', fillvalue=None):
    &quot;Collect data into non-overlapping fixed-length chunks or blocks&quot;
    # grouper('ABCDEFG', 3, fillvalue='x') --&gt; ABC DEF Gxx
    # grouper('ABCDEFG', 3, incomplete='strict') --&gt; ABC DEF ValueError
    # grouper('ABCDEFG', 3, incomplete='ignore') --&gt; ABC DEF
    args = [iter(iterable)] * n
    if incomplete == 'fill':
        return zip_longest(*args, fillvalue=fillvalue)
    if incomplete == 'strict':
        return zip(*args, strict=True)
    if incomplete == 'ignore':
        return zip(*args)
    else:
        raise ValueError('Expected fill, strict, or ignore')
</code></pre>
<h4> traal, Comment 134072545 Score: 0: </h4>The <code>grouper()</code> source is available in the docs in this form since 3.10; the <code>batched()</code> source is only in 3.11, but has become a built-in function since 3.12. Yaay! üòä<br>------------------------------------------------------------------ <br><h3> J.T. Hurley, Id: 319970, Score: 4: </h3><pre><code>def chunk(lst):
    out = []
    for x in xrange(2, len(lst) + 1):
        if not len(lst) % x:
            factor = len(lst) / x
            break
    while lst:
        out.append([lst.pop(0) for x in xrange(factor)])
    return out
</code></pre>
------------------------------------------------------------------ <br><h3> Be Wake Pandey, Id: 27371167, Score: 4: </h3><p>letting r be the chunk size  and L be the initial list, you can do. </p>

<pre><code>chunkL = [ [i for i in L[r*k:r*(k+1)] ] for k in range(len(L)/r)] 
</code></pre>
------------------------------------------------------------------ <br><h3> Claudiu, Id: 38808533, Score: 4: </h3><p>As per <a href="https://stackoverflow.com/a/21767522/15055">this answer</a>, the top-voted answer leaves a 'runt' at the end. Here's my solution to really get about as evenly-sized chunks as you can, with no runts. It basically tries to pick exactly the fractional spot where it should split the list, but just rounds it off to the nearest integer:</p>

<pre><code>from __future__ import division  # not needed in Python 3
def n_even_chunks(l, n):
    """Yield n as even chunks as possible from l."""
    last = 0
    for i in range(1, n+1):
        cur = int(round(i * (len(l) / n)))
        yield l[last:cur]
        last = cur
</code></pre>

<p>Demonstration:</p>

<pre><code>&gt;&gt;&gt; pprint.pprint(list(n_even_chunks(list(range(100)), 9)))
[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
 [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21],
 [22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32],
 [33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43],
 [44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55],
 [56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66],
 [67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77],
 [78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88],
 [89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]]
&gt;&gt;&gt; pprint.pprint(list(n_even_chunks(list(range(100)), 11)))
[[0, 1, 2, 3, 4, 5, 6, 7, 8],
 [9, 10, 11, 12, 13, 14, 15, 16, 17],
 [18, 19, 20, 21, 22, 23, 24, 25, 26],
 [27, 28, 29, 30, 31, 32, 33, 34, 35],
 [36, 37, 38, 39, 40, 41, 42, 43, 44],
 [45, 46, 47, 48, 49, 50, 51, 52, 53, 54],
 [55, 56, 57, 58, 59, 60, 61, 62, 63],
 [64, 65, 66, 67, 68, 69, 70, 71, 72],
 [73, 74, 75, 76, 77, 78, 79, 80, 81],
 [82, 83, 84, 85, 86, 87, 88, 89, 90],
 [91, 92, 93, 94, 95, 96, 97, 98, 99]]
</code></pre>

<p>Compare to the top-voted <code>chunks</code> answer:</p>

<pre><code>&gt;&gt;&gt; pprint.pprint(list(chunks(list(range(100)), 100//9)))
[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
 [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21],
 [22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32],
 [33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43],
 [44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54],
 [55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65],
 [66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76],
 [77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87],
 [88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98],
 [99]]
&gt;&gt;&gt; pprint.pprint(list(chunks(list(range(100)), 100//11)))
[[0, 1, 2, 3, 4, 5, 6, 7, 8],
 [9, 10, 11, 12, 13, 14, 15, 16, 17],
 [18, 19, 20, 21, 22, 23, 24, 25, 26],
 [27, 28, 29, 30, 31, 32, 33, 34, 35],
 [36, 37, 38, 39, 40, 41, 42, 43, 44],
 [45, 46, 47, 48, 49, 50, 51, 52, 53],
 [54, 55, 56, 57, 58, 59, 60, 61, 62],
 [63, 64, 65, 66, 67, 68, 69, 70, 71],
 [72, 73, 74, 75, 76, 77, 78, 79, 80],
 [81, 82, 83, 84, 85, 86, 87, 88, 89],
 [90, 91, 92, 93, 94, 95, 96, 97, 98],
 [99]]
</code></pre>
<h4> DragonTux, Comment 65989136 Score: 1: </h4>This solution seems to fail in some situations:  - when n &gt; len(l)  - for l = [0,1,2,3,4] and n=3 it returns [[0], [1], [2]] instead of [[0,1], [2,3], [4]]<br><h4> Claudiu, Comment 66001830 Score: 0: </h4>@DragonTux: Ah I wrote the function for Python 3 - it gives <code>[[0, 1], [2], [3, 4]]</code>. I added the future import so it works in Python 2 as well<br>------------------------------------------------------------------ <br><h3> Peter Gerdes, Id: 41586849, Score: 4: </h3><p>I have one solution below which does work but more important than that solution is a few comments on other approaches.  First, a good solution shouldn't require that one loop through the sub-iterators in order.  If I run</p>

<pre><code>g = paged_iter(list(range(50)), 11))
i0 = next(g)
i1 = next(g)
list(i1)
list(i0)
</code></pre>

<p>The appropriate output for the last command is   </p>

<pre><code> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
</code></pre>

<p>not</p>

<pre><code> []
</code></pre>

<p>As most of the itertools based solutions here return.  This isn't just the usual boring restriction about accessing iterators in order.  Imagine a consumer trying to clean up poorly entered data which reversed the appropriate order of blocks of 5, i.e., the data looks like [B5, A5, D5, C5] and should look like [A5, B5, C5, D5] (where A5 is just five elements not a sublist).  This consumer would look at the claimed behavior of the grouping function and not hesitate to write a loop like</p>

<pre><code>i = 0
out = []
for it in paged_iter(data,5)
    if (i % 2 == 0):
         swapped = it
    else: 
         out += list(it)
         out += list(swapped)
    i = i + 1
</code></pre>

<p>This will produce mysteriously wrong results if you sneakily assume that sub-iterators are always fully used in order.  It gets even worse if you want to interleave elements from the chunks. </p>

<p>Second, a decent number of the suggested solutions implicitly rely on the fact that iterators have a deterministic order (they don't e.g. set) and while some of the solutions using islice may be ok it worries me.</p>

<p>Third, the itertools grouper approach works but the recipe relies on internal behavior of the zip_longest (or zip) functions that isn't part of their published behavior.  In particular, the grouper function only works because in zip_longest(i0...in) the next function is always called in order next(i0), next(i1), ... next(in) before starting over.  As grouper passes n copies of the same iterator object it relies on this behavior.</p>

<p>Finally, while the solution below can be improved if you make the assumption criticized above that sub-iterators are accessed in order and fully perused without this assumption one MUST implicitly (via call chain) or explicitly (via deques or other data structure) store elements for each subiterator somewhere.  So don't bother wasting time (as I did) assuming one could get around this with some clever trick.</p>

<pre><code>def paged_iter(iterat, n):
    itr = iter(iterat)
    deq = None
    try:
        while(True):
            deq = collections.deque(maxlen=n)
            for q in range(n):
                deq.append(next(itr))
            yield (i for i in deq)
    except StopIteration:
        yield (i for i in deq)
</code></pre>
------------------------------------------------------------------ <br><h3> Kandarp, Id: 62643989, Score: 4: </h3><p>An abstraction would be</p>
<pre><code>l = [1,2,3,4,5,6,7,8,9]
n = 3
outList = []
for i in range(n, len(l) + n, n):
    outList.append(l[i-n:i])

print(outList)
</code></pre>
<p>This will print:</p>
<blockquote>
<p>[[1, 2, 3], [4, 5, 6], [7, 8, 9]]</p>
</blockquote>
------------------------------------------------------------------ <br><h3> rectangletangle, Id: 22138685, Score: 3: </h3><p>I wrote a small library expressly for this purpose, available <a href="https://github.com/rectangletangle/iterlib" rel="nofollow">here</a>. The library's <code>chunked</code> function is particularly efficient because it's implemented as a <a href="https://wiki.python.org/moin/Generators" rel="nofollow">generator</a>, so a substantial amount of memory can be saved in certain situations. It also doesn't rely on the slice notation, so any arbitrary iterator can be used.</p>

<pre><code>import iterlib

print list(iterlib.chunked(xrange(1, 1000), 10))
# prints [(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), (11, 12, 13, 14, 15, 16, 17, 18, 19, 20), ...]
</code></pre>
------------------------------------------------------------------ <br><h3> Flo, Id: 29707187, Score: 3: </h3><p>The answer above (by koffein) has a little problem: the list is always split into an equal number of splits, not equal number of items per partition. This is my version. The "// chs + 1" takes into account that the number of items may not be divideable exactly by the partition size, so the last partition will only be partially filled.</p>

<pre><code># Given 'l' is your list

chs = 12 # Your chunksize
partitioned = [ l[i*chs:(i*chs)+chs] for i in range((len(l) // chs)+1) ]
</code></pre>
------------------------------------------------------------------ <br><h3> Julien Palard, Id: 33517774, Score: 3: </h3><p>At this point, I think we need the obligatory anonymous-recursive function.</p>

<pre><code>Y = lambda f: (lambda x: x(x))(lambda y: f(lambda *args: y(y)(*args)))
chunks = Y(lambda f: lambda n: [n[0][:n[1]]] + f((n[0][n[1]:], n[1])) if len(n[0]) &gt; 0 else [])
</code></pre>
------------------------------------------------------------------ <br><h3> itub, Id: 42677465, Score: 3: </h3><p>Here's an idea using itertools.groupby:</p>

<pre><code>def chunks(l, n):
    c = itertools.count()
    return (it for _, it in itertools.groupby(l, lambda x: next(c)//n))
</code></pre>

<p>This returns a generator of generators. If you want a list of lists, just replace the last line with</p>

<pre><code>    return [list(it) for _, it in itertools.groupby(l, lambda x: next(c)//n)]
</code></pre>

<p>Example returning list of lists:</p>

<pre><code>&gt;&gt;&gt; chunks('abcdefghij', 4)
[['a', 'b', 'c', 'd'], ['e', 'f', 'g', 'h'], ['i', 'j']]
</code></pre>

<p>(So yes, this suffers form the "runt problem", which may or may not be a problem in a given situation.)</p>
------------------------------------------------------------------ <br><h3> guyskk, Id: 47010604, Score: 3: </h3><p>No magic, but simple and correct:</p>

<pre><code>def chunks(iterable, n):
    """Yield successive n-sized chunks from iterable."""
    values = []
    for i, item in enumerate(iterable, 1):
        values.append(item)
        if i % n == 0:
            yield values
            values = []
    if values:
        yield values
</code></pre>
------------------------------------------------------------------ <br><h3> cottontail, Id: 72960641, Score: 3: </h3><p>Simply using <code>zip()</code> to produce similar round-robin zips and returning the remaining elements of <code>lst</code> (that cannot make a &quot;whole&quot; sublist) should do the trick.</p>
<pre class="lang-py prettyprint-override"><code>def chunkify(lst, n):
    for tup in zip(*[iter(lst)]*n):
        yield tup
    rest = tuple(lst[len(lst)//n*n: ])
    if rest:
        yield rest

list(chunkify(range(7), 3)) # [(0, 1, 2), (3, 4, 5), (6,)]
</code></pre>
<p>Since Python 3.12, <code>itertools</code> in the standard library implements <a href="https://docs.python.org/3.12/library/itertools.html#itertools.batched" rel="nofollow noreferrer">batched</a> method that performs the very same operation. For example,</p>
<pre class="lang-py prettyprint-override"><code>from itertools import batched
list(batched(range(7), 3))  # [(0, 1, 2), (3, 4, 5), (6,)]
</code></pre>
<p>Both of these methods are at least as memory efficient as any function in other answers on this page that do the same operation (the peak memory usage is the size of a batch), they are also the fastest ways to do it. The following is a table of runtimes of chunking a list of 1,000,000 elements (the first column is when a chunk size=3 and the second is when chunk size=910).<sup>1</sup></p>
<pre class="lang-none prettyprint-override"><code>    Chunk size         3      910
Functions
cottontail        20.1ms    7.5ms
it_batched        22.1ms    8.3ms
NedBatchelder     72.8ms    8.4ms
nirvana_msu      140.4ms   18.8ms
pylang1          173.7ms   19.0ms
senderle         184.6ms   15.7ms
</code></pre>
<hr />
<p>A one-liner version (Python &gt;=3.8):</p>
<pre class="lang-py prettyprint-override"><code>list(map(list, zip(*[iter(lst)]*n))) + ([rest] if (rest:=lst[len(lst)//n*n : ]) else [])
</code></pre>
<hr />
<p><sup>1</sup> Code used to produce the table. Only the below functions were considered because the functions defined in @NedBatchelder, @oremj, @RianRizvi, @Mars and @atzz's answers are the same; those in @MarkusJarderot, @nirvana_msu and @RaymondHettinger's are the same, so only one from each group was selected. Tested on Python 3.12.0.</p>
<pre class="lang-py prettyprint-override"><code>from timeit import repeat

setup = &quot;&quot;&quot;
import itertools
import more_itertools as mit


def cottontail(lst, n):
    for tup in zip(*[iter(lst)]*n): tup
    rest = tuple(lst[len(lst)//n*n: ])
    if rest: rest

def it_batched(it, n):
    for x in itertools.batched(it, n): x

def NedBatchelder(lst, n):
    for i in range(0, len(lst), n): lst[i:i + n]

def pylang1(iterable, n):
    for x in mit.chunked(iterable, n): x

def senderle(it, size):
    it = iter(it)
    for x in iter(lambda: tuple(itertools.islice(it, size)), ()): x

def nirvana_msu(iterable, size):
    it = iter(iterable)
    while item := list(itertools.islice(it, size)):
        item

lst = list(range(1_000_000))
&quot;&quot;&quot;

out = {}
for f in (&quot;NedBatchelder&quot;, &quot;pylang1&quot;, &quot;senderle&quot;, 
          &quot;nirvana_msu&quot;, &quot;cottontail&quot;, &quot;it_batched&quot;):
    for k in (3, 910):
        tm = min(repeat(f&quot;{f}(lst, {k})&quot;, setup, number=100))
        out.setdefault(f, {})[k] = tm*10
out = dict(sorted(out.items(), key=lambda xy: xy[1][3]))

print('    Chunk size         3      910\nFunctions')
for func, val in out.items():
    print(&quot;{:&lt;15}  {:&gt;5.1f}ms  {:&gt;5.1f}ms&quot;.format(func, val[3], val[910]))
</code></pre>
<h4> bfontaine, Comment 134198228 Score: 0: </h4>Downvoted because this returns a list and so is very inefficient on large inputs where you would like to process the result one by one. See <a href="https://stackoverflow.com/a/59266741/735926">nirvana-msu‚Äôs answer</a> for an implementation that works on any iterable and return a generator with very simple code (= easier to read, understand, and debug).<br><h4> cottontail, Comment 136143194 Score: 0: </h4>@bfontaine my main argument to post the answer in the first place was based on runtime performance, so memory was never a concern. Besides, the generator version of my answer uses similar amount of peak memory as nirvana-msu&#39;s solution. Then again, now that Python 3.12 is out, all of these answers are obsolete and don&#39;t matter now.<br>------------------------------------------------------------------ <br><h3> CPBL, Id: 25650543, Score: 2: </h3><p>Like @AaronHall I got here looking for roughly evenly sized chunks. There are different interpretations of that. In my case, if the desired size is N, I would like each group to be of size>=N.
Thus, the orphans which are created in most of the above should be redistributed to other groups.</p>

<p>This can be done using:</p>

<pre><code>def nChunks(l, n):
    """ Yield n successive chunks from l.
    Works for lists,  pandas dataframes, etc
    """
    newn = int(1.0 * len(l) / n + 0.5)
    for i in xrange(0, n-1):
        yield l[i*newn:i*newn+newn]
    yield l[n*newn-newn:]
</code></pre>

<p>(from <a href="https://stackoverflow.com/questions/2130016/splitting-a-list-of-arbitrary-size-into-only-roughly-n-equal-parts">Splitting a list of into N parts of approximately equal length</a>) by simply calling it as nChunks(l,l/n)  or nChunks(l,floor(l/n))</p>
------------------------------------------------------------------ <br><h3> Andrey Cizov, Id: 44959796, Score: 2: </h3><p>This works in v2/v3, is inlineable, generator-based and uses only the standard library:</p>

<pre><code>import itertools
def split_groups(iter_in, group_size):
    return ((x for _, x in item) for _, item in itertools.groupby(enumerate(iter_in), key=lambda x: x[0] // group_size))
</code></pre>
<h4> Andrey Cizov, Comment 84941594 Score: 0: </h4>Just do a <code>(list(x) for x in split_groups(&#39;abcdefghij&#39;, 4))</code>, then iterate through them: as opposed to many examples here this would work with groups of any size.<br>------------------------------------------------------------------ <br><h3> Brandt, Id: 66967457, Score: 2: </h3><h1>A <em>simple</em> solution</h1>
<blockquote>
<p>The OP has requested &quot;equal sized chunk&quot;. I understand &quot;equal sized&quot; as &quot;balanced&quot; sizes: we are looking for groups of items of <em>approximately</em> the same sizes <em>if</em> equal sizes are not possible (e.g, 23/5).</p>
</blockquote>
<p>Inputs here are:</p>
<ul>
<li>the list of items: <code>input_list</code> (list of 23 numbers, for instance)</li>
<li>the number of groups to split those items: <code>n_groups</code> (<code>5</code>, for instance)</li>
</ul>
<p>Input:</p>
<pre class="lang-py prettyprint-override"><code>input_list = list(range(23))
n_groups = 5
</code></pre>
<h2>Groups of contiguous elements:</h2>
<pre class="lang-py prettyprint-override"><code>approx_sizes = len(input_list)/n_groups 

groups_cont = [input_list[int(i*approx_sizes):int((i+1)*approx_sizes)] 
               for i in range(n_groups)]
</code></pre>
<h2>Groups of &quot;every-Nth&quot; elements:</h2>
<pre class="lang-py prettyprint-override"><code>groups_leap = [input_list[i::n_groups] 
               for i in range(n_groups)]
</code></pre>
<h3>Results</h3>
<pre><code>print(len(input_list))

print('Contiguous elements lists:')
print(groups_cont)

print('Leap every &quot;N&quot; items lists:')
print(groups_leap)
</code></pre>
<blockquote>
<p>Will output:</p>
<pre><code>23

Contiguous elements lists:
[[0, 1, 2, 3], [4, 5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16, 17], [18, 19, 20, 21, 22]]

Leap every &quot;N&quot; items lists:
[[0, 5, 10, 15, 20], [1, 6, 11, 16, 21], [2, 7, 12, 17, 22], [3, 8, 13, 18], [4, 9, 14, 19]]
</code></pre>
</blockquote>
------------------------------------------------------------------ <br><h3> balki, Id: 18793562, Score: 1: </h3><ul>
<li>Works with any iterable</li>
<li>Inner data is generator object (not a list)</li>
<li>One liner</li>
</ul>

<pre>
In [259]: get_in_chunks = lambda itr,n: ( (v for _,v in g) for _,g in itertools.groupby(enumerate(itr),lambda (ind,_): ind/n))

In [260]: list(list(x) for x in get_in_chunks(range(30),7))
Out[260]:
[[0, 1, 2, 3, 4, 5, 6],
 [7, 8, 9, 10, 11, 12, 13],
 [14, 15, 16, 17, 18, 19, 20],
 [21, 22, 23, 24, 25, 26, 27],
 [28, 29]]
</pre>
<h4> Peter Gerdes, Comment 82735464 Score: 0: </h4>g =  get_in_chunks(range(30),7); i0=next(g);i1=next(g);list(i1);list(i0);  Last evaluation is empty.  Hidden requirement about accessing all the sublists in order seems really bad here to me because the goal with these kind of utils is often to shuffle data around in various ways.<br>------------------------------------------------------------------ <br><h3> Mikhail Lyundin, Id: 32658232, Score: 1: </h3><p>I have come up to following solution without creation temorary list object, which should work with any iterable object. Please note that this version for Python 2.x:</p>

<pre><code>def chunked(iterable, size):
    stop = []
    it = iter(iterable)
    def _next_chunk():
        try:
            for _ in xrange(size):
                yield next(it)
        except StopIteration:
            stop.append(True)
            return

    while not stop:
        yield _next_chunk()

for it in chunked(xrange(16), 4):
   print list(it)
</code></pre>

<p>Output:</p>

<pre><code>[0, 1, 2, 3]
[4, 5, 6, 7]
[8, 9, 10, 11]
[12, 13, 14, 15] 
[]
</code></pre>

<p>As you can see if len(iterable) % size == 0 then we have additional empty iterator object. But I do not think that it is big problem.</p>
------------------------------------------------------------------ <br><h3> Evan Zamir, Id: 33180285, Score: 1: </h3><p>Since I had to do something like this, here's my solution given a generator and a batch size:</p>

<pre><code>def pop_n_elems_from_generator(g, n):
    elems = []
    try:
        for idx in xrange(0, n):
            elems.append(g.next())
        return elems
    except StopIteration:
        return elems
</code></pre>
------------------------------------------------------------------ <br><h3> J-L, Id: 57042866, Score: 1: </h3><p>This question reminds me of the Raku (formerly Perl 6) <code>.comb(n)</code> method.  It breaks up strings into <code>n</code>-sized chunks.  (There's more to it than that, but I'll leave out the details.)</p>
<p>It's easy enough to implement a similar function in Python3 as a lambda expression:</p>
<pre><code>comb = lambda s,n: (s[i:i+n] for i in range(0,len(s),n))
</code></pre>
<p>Then you can call it like this:</p>
<pre><code>some_list = list(range(0, 20))  # creates a list of 20 elements
generator = comb(some_list, 4)  # creates a generator that will generate lists of 4 elements
for sublist in generator:
    print(sublist)  # prints a sublist of four elements, as it's generated
</code></pre>
<p>Of course, you don't have to assign the generator to a variable; you can just loop over it directly like this:</p>
<pre><code>for sublist in comb(some_list, 4):
    print(sublist)  # prints a sublist of four elements, as it's generated
</code></pre>
<p>As a bonus, this <code>comb()</code> function also operates on strings:</p>
<pre><code>list( comb('catdogant', 3) )  # returns ['cat', 'dog', 'ant']
</code></pre>
------------------------------------------------------------------ <br><h3> alani, Id: 62216571, Score: 1: </h3><p>A generic chunker for any iterable, which gives the user a choice of how to handle a partial chunk at the end.</p>

<p>Tested on Python 3.</p>

<p><code>chunker.py</code></p>

<pre><code>from enum import Enum

class PartialChunkOptions(Enum):
    INCLUDE = 0
    EXCLUDE = 1
    PAD = 2
    ERROR = 3

class PartialChunkException(Exception):
    pass

def chunker(iterable, n, on_partial=PartialChunkOptions.INCLUDE, pad=None):
    """
    A chunker yielding n-element lists from an iterable, with various options
    about what to do about a partial chunk at the end.

    on_partial=PartialChunkOptions.INCLUDE (the default):
                     include the partial chunk as a short (&lt;n) element list

    on_partial=PartialChunkOptions.EXCLUDE
                     do not include the partial chunk

    on_partial=PartialChunkOptions.PAD
                     pad to an n-element list 
                     (also pass pad=&lt;pad_value&gt;, default None)

    on_partial=PartialChunkOptions.ERROR
                     raise a RuntimeError if a partial chunk is encountered
    """

    on_partial = PartialChunkOptions(on_partial)        

    iterator = iter(iterable)
    while True:
        vals = []
        for i in range(n):
            try:
                vals.append(next(iterator))
            except StopIteration:
                if vals:
                    if on_partial == PartialChunkOptions.INCLUDE:
                        yield vals
                    elif on_partial == PartialChunkOptions.EXCLUDE:
                        pass
                    elif on_partial == PartialChunkOptions.PAD:
                        yield vals + [pad] * (n - len(vals))
                    elif on_partial == PartialChunkOptions.ERROR:
                        raise PartialChunkException
                    return
                return
        yield vals
</code></pre>

<p><code>test.py</code></p>

<pre><code>import chunker

chunk_size = 3

for it in (range(100, 107),
          range(100, 109)):

    print("\nITERABLE TO CHUNK: {}".format(it))
    print("CHUNK SIZE: {}".format(chunk_size))

    for option in chunker.PartialChunkOptions.__members__.values():
        print("\noption {} used".format(option))
        try:
            for chunk in chunker.chunker(it, chunk_size, on_partial=option):
                print(chunk)
        except chunker.PartialChunkException:
            print("PartialChunkException was raised")
    print("")
</code></pre>

<p>output of <code>test.py</code></p>

<pre><code>
ITERABLE TO CHUNK: range(100, 107)
CHUNK SIZE: 3

option PartialChunkOptions.INCLUDE used
[100, 101, 102]
[103, 104, 105]
[106]

option PartialChunkOptions.EXCLUDE used
[100, 101, 102]
[103, 104, 105]

option PartialChunkOptions.PAD used
[100, 101, 102]
[103, 104, 105]
[106, None, None]

option PartialChunkOptions.ERROR used
[100, 101, 102]
[103, 104, 105]
PartialChunkException was raised


ITERABLE TO CHUNK: range(100, 109)
CHUNK SIZE: 3

option PartialChunkOptions.INCLUDE used
[100, 101, 102]
[103, 104, 105]
[106, 107, 108]

option PartialChunkOptions.EXCLUDE used
[100, 101, 102]
[103, 104, 105]
[106, 107, 108]

option PartialChunkOptions.PAD used
[100, 101, 102]
[103, 104, 105]
[106, 107, 108]

option PartialChunkOptions.ERROR used
[100, 101, 102]
[103, 104, 105]
[106, 107, 108]

</code></pre>
------------------------------------------------------------------ <br><h3> Shubh Patel, Id: 75855076, Score: 1: </h3><p>To split a list into equally-sized chunks we can use a loop to iterate through the list and use the <code>slice()</code> function to extract a portion of the list at each iteration.</p>
<pre><code>def chunkify(lst, size):
    &quot;&quot;&quot;Split a list into equally-sized chunks.&quot;&quot;&quot;
    chunks = []
    for i in range(0, len(lst), size):
        chunks.append(lst[i:i+size])
    return chunks
</code></pre>
<p>Here, <code>lst</code> is the list you want to split and <code>size</code> is the size of each chunk.
The <code>range()</code> function is used to generate a sequence of indexes to slice the list. The <code>slice()</code> function extracts a portion of the list from index <code>i</code> to index <code>i+size</code>.</p>
<h4> OneCricketeer, Comment 133865088 Score: 0: </h4>What does this improve on over <a href="https://stackoverflow.com/a/312464/2308683">existing answers</a>?<br>------------------------------------------------------------------ <br><h3> Arthur Sult, Id: 49456217, Score: 0: </h3><p>I dislike idea of splitting elements by chunk size, e.g. script can devide 101 to 3 chunks as [50, 50, 1]. For my needs I needed spliting proportionly, and keeping order same. First I wrote my own script, which works fine, and it's very simple. But I've seen later <a href="https://stackoverflow.com/a/21767522/3110300">this answer</a>, where script is better than mine, I reccomend it.
Here's my script:</p>

<pre><code>def proportional_dividing(N, n):
    """
    N - length of array (bigger number)
    n - number of chunks (smaller number)
    output - arr, containing N numbers, diveded roundly to n chunks
    """
    arr = []
    if N == 0:
        return arr
    elif n == 0:
        arr.append(N)
        return arr
    r = N // n
    for i in range(n-1):
        arr.append(r)
    arr.append(N-r*(n-1))

    last_n = arr[-1]
    # last number always will be r &lt;= last_n &lt; 2*r
    # when last_n == r it's ok, but when last_n &gt; r ...
    if last_n &gt; r:
        # ... and if difference too big (bigger than 1), then
        if abs(r-last_n) &gt; 1:
            #[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7] # N=29, n=12
            # we need to give unnecessary numbers to first elements back
            diff = last_n - r
            for k in range(diff):
                arr[k] += 1
            arr[-1] = r
            # and we receive [3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2]
    return arr

def split_items(items, chunks):
    arr = proportional_dividing(len(items), chunks)
    splitted = []
    for chunk_size in arr:
        splitted.append(items[:chunk_size])
        items = items[chunk_size:]
    print(splitted)
    return splitted

items = [1,2,3,4,5,6,7,8,9,10,11]
chunks = 3
split_items(items, chunks)
split_items(['a','b','c','d','e','f','g','h','i','g','k','l', 'm'], 3)
split_items(['a','b','c','d','e','f','g','h','i','g','k','l', 'm', 'n'], 3)
split_items(range(100), 4)
split_items(range(99), 4)
split_items(range(101), 4)
</code></pre>

<p>and output:</p>

<pre><code>[[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11]]
[['a', 'b', 'c', 'd'], ['e', 'f', 'g', 'h'], ['i', 'g', 'k', 'l', 'm']]
[['a', 'b', 'c', 'd', 'e'], ['f', 'g', 'h', 'i', 'g'], ['k', 'l', 'm', 'n']]
[range(0, 25), range(25, 50), range(50, 75), range(75, 100)]
[range(0, 25), range(25, 50), range(50, 75), range(75, 99)]
[range(0, 25), range(25, 50), range(50, 75), range(75, 101)]
</code></pre>
------------------------------------------------------------------ <br><h3> Matheus Vin&#237;cius de Andrade, Id: 61212415, Score: 0: </h3><pre><code>def main():
  print(chunkify([1,2,3,4,5,6],2))

def chunkify(list, n):
  chunks = []
  for i in range(0, len(list), n):
    chunks.append(list[i:i+n])
  return chunks

main()
</code></pre>

<p>I think that it's simple and can give you a chunk of an array.</p>
------------------------------------------------------------------ <br><h3> Arty, Id: 64041110, Score: 0: </h3><p>I've created these two fancy one-liners which are efficient and lazy, both input and output are iterables, also they doen't depend on any module:</p>
<p>First one-liner is totally lazy meaning that it returns iterator producing iterators (i.e. each chunk produced is iterator iterating over chunk's elements), this version is good for the case if chunks are very large or elements are produced slowly one by one and should become available immediately as they are produced:</p>
<p><a href="https://tio.run/##RY/BCsIwDIbve4ocG6hg0dPAJxlDutltURdH7Q768jXpBvZQmvD9X9Llk6YXn3Lup5UfV0ohvuECTz93Nw@ULHANxgQYXhHIwgjEEHidQ/QpGGMGixZ6SogFuVsIinxpMdHzKIgTBxzAYUOtsONOSkZBoyPlQru1B22qr6q0ZC03kXjcGesK5CyROBm20DRdiXXK@ba8fVH8/7MvcpS8kwUYW8z5Bw" rel="nofollow noreferrer" title="Python 3 ‚Äì Try It Online">Try it online!</a></p>
<pre><code>chunk_iters = lambda it, n: ((e for i, g in enumerate(((f,), cit)) for j, e in zip(range((1, n - 1)[i]), g)) for cit in (iter(it),) for f in cit)
</code></pre>
<p>Second one-liner returns iterator that produces lists. Each list is produced as soon as elements of whole chunk become available through input iterator or if very last element of last chunk is reached. This version should be used if input elements are produced fast or all available immediately. Other wise first more-lazy one-liner version should be used.</p>
<p><a href="https://tio.run/##TY/BDoIwEETvfMV4MNmNNYHoqQlfQoipWqCxLATKwa/HVhJlb7sz8zYzvkM3yGVdH90ir5t3c5hRwpv@/jRwQUE0yKMZJng4AVW14u/qFNp0sbL0djLBEiU/ESvmzWKT3u7CvtLeCnnGEVLjhMrWlS5whktY10TLT0dZImccSjjOsgSRBJmMtJYKheLKOkOccXISSFSk/d/uCtEWyWOk4NiIa17XDw" rel="nofollow noreferrer" title="Python 3 ‚Äì Try It Online">Try it online!</a></p>
<pre><code>chunk_lists = lambda it, n: (l for l in ([],) for i, g in enumerate((it, ((),))) for e in g for l in (l[:len(l) % n] + [e][:1 - i],) if (len(l) % n == 0) != i)
</code></pre>
<p>Also I provide multi-line version of first <code>chunk_iters</code> one-liner, which returns iterator producing another iterators (going through each chunk's elements):</p>
<p><a href="https://tio.run/##XY/LCsIwEEX3@YpZJhDBoivBLyml9DGxgzItMV3Un4@ZtGpxVsnlnDvJtIRh5FOMPTrohpnvNQX0T03BApuLgjQdBbiC5Ck2ORJ8ZKyzot0GyiyEjx7c9@5GD2QBgRheNGnf8A01wwEKY6V65/58VB/XiZiw/w377UoJyUKu9YWF4rwVT544aLZQlm1ubIVrqnxucvvu36t/TL48j01lYnwD" rel="nofollow noreferrer" title="Python 3 ‚Äì Try It Online">Try it online!</a></p>
<pre><code>def chunk_iters(it, n):
    cit = iter(it)
    def one_chunk(f):
        yield f
        for i, e in zip(range(n - 1), cit):
            yield e
    for f in cit:
        yield one_chunk(f)
</code></pre>
------------------------------------------------------------------ <br><h3> shanu khera, Id: 70927990, Score: 0: </h3><p>Let's say the list is <code>lst</code></p>
<pre><code>import math

# length of the list len(lst) is ln
# size of a chunk is size

for num in range ( math.ceil(ln/size) ):
    start, end = num*size, min((num+1)*size, ln)
    print(lst[start:end])
</code></pre>
------------------------------------------------------------------ <br><h3> mikey, Id: 73268211, Score: 0: </h3><p>You may use <code>more_itertools.chunked_even</code> along with <code>math.ceil</code>. Likely the easiest to reason?</p>
<pre class="lang-py prettyprint-override"><code>from math import ceil
import more_itertools as mit
from pprint import pprint

pprint([*mit.chunked_even(range(19), ceil(19 / 5))])
# [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18]]

pprint([*mit.chunked_even(range(20), ceil(20 / 5))])
# [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19]]

pprint([*mit.chunked_even(range(21), ceil(21 / 5))])
# [[0, 1, 2, 3, 4],
# [5, 6, 7, 8],
# [9, 10, 11, 12],
# [13, 14, 15, 16],
# [17, 18, 19, 20]]

pprint([*mit.chunked_even(range(3), ceil(3 / 5))])
# [[0], [1], [2]]


</code></pre>
<h4> wim, Comment 131072981 Score: 0: </h4>It was already shown in a 2018 answer <a href="https://stackoverflow.com/a/52022535/674039">stackoverflow.com/a/52022535/674039</a><br>------------------------------------------------------------------ <br><h3> Tim, Id: 76267125, Score: 0: </h3><p>Here's a short and readable answer (different from all previous answers):</p>
<ul>
<li>No packages</li>
<li>Works when list not evenly divisible into <code>n</code> chunks</li>
<li>Easily changeable into generator</li>
</ul>
<pre><code>import math
 
def chunk(lst, n):
    chunk_size = math.ceil(len(lst) / n)
    return [lst[i: min(i+chunk_size, len(lst))] for i in range(0, len(lst), chunk_size)]
</code></pre>
<hr />
<p>Examples:</p>
<p><code>chunk(lst=list(range(9)), n=3)</code> gives
<code>[[0, 1, 2], [3, 4, 5], [6, 7, 8]]</code></p>
<p><code>chunk(lst=list(range(10)), n=3)</code> gives
<code>[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9]]</code></p>
<p><code>chunk(lst=list(range(10)), n=3)</code> gives
<code>[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10]]</code></p>
------------------------------------------------------------------ <br><h3> iamkroot, Id: 77198393, Score: 0: </h3><p>With Python 3.12, this is now natively supported with <a href="https://docs.python.org/3.12/library/itertools.html#itertools.batched" rel="nofollow noreferrer"><code>itertools.batched</code></a></p>
<pre class="lang-py prettyprint-override"><code>from itertools import batched

flattened_data = ['roses', 'red', 'violets', 'blue', 'sugar']
unflattened = list(batched(flattened_data, 2))
assert unflattened == [('roses', 'red'), ('violets', 'blue'), ('sugar',)]
</code></pre>
<p>This is completely lazy - iterator is only ever consumed enough to fill the current chunk.</p>
------------------------------------------------------------------ <br><h3> luckydonald, Id: 55776536, Score: -1: </h3><h3>Lazy loading version</h3>

<blockquote>
  <pre class="lang-py prettyprint-override"><code>import pprint
pprint.pprint(list(chunks(range(10, 75), 10)))
[range(10, 20),
 range(20, 30),
 range(30, 40),
 range(40, 50),
 range(50, 60),
 range(60, 70),
 range(70, 75)]
</code></pre>
  
  <p><em><sup><sub> Confer this implementation's result with the example usage result of the <a href="https://stackoverflow.com/a/312464/3423324">accepted answer</a>. </sub></sup></em></p>
</blockquote>

<p>Many of the above functions assume that the length of the whole iterable are known up front, or at least are cheap to calculate.</p>

<p>For some streamed objects that would mean loading the full data into memory first (e.g. to download the whole file) to get the length information.</p>

<p>If you however don't know the the full size yet, you can use this code instead:</p>

<pre class="lang-py prettyprint-override"><code>def chunks(iterable, size):
    """
    Yield successive chunks from iterable, being `size` long.

    https://stackoverflow.com/a/55776536/3423324
    :param iterable: The object you want to split into pieces.
    :param size: The size each of the resulting pieces should have.
    """
    i = 0
    while True:
        sliced = iterable[i:i + size]
        if len(sliced) == 0:
            # to suppress stuff like `range(max, max)`.
            break
        # end if
        yield sliced
        if len(sliced) &lt; size:
            # our slice is not the full length, so we must have passed the end of the iterator
            break
        # end if
        i += size  # so we start the next chunk at the right place.
    # end while
# end def
</code></pre>

<p>This works because the slice command will return less/no elements if you passed the end of an iterable:</p>

<pre class="lang-py prettyprint-override"><code>"abc"[0:2] == 'ab'
"abc"[2:4] == 'c'
"abc"[4:6] == ''
</code></pre>

<p>We now use that result of the slice, and calculate the length of that generated chunk. If it is less than what we expect, we know we can end the iteration.</p>

<p>That way the iterator will not be executed unless access.</p>
------------------------------------------------------------------ <br><h3> Realfun, Id: 59163343, Score: -1: </h3><p>An old school approach that does not require itertools but still works with arbitrary generators:</p>

<pre><code>def chunks(g, n):
  """divide a generator 'g' into small chunks
  Yields:
    a chunk that has 'n' or less items
  """
  n = max(1, n)
  buff = []
  for item in g:
    buff.append(item)
    if len(buff) == n:
      yield buff
      buff = []
  if buff:
    yield buff
</code></pre>
------------------------------------------------------------------ <br><h3> Amin Rezaei, Id: 70381614, Score: -1: </h3><p>This task can be easily done using the generator in the <a href="http://https:/https://stackoverflow.com/a/312464/8010865" rel="nofollow noreferrer">accepted answer</a>. I'm adding class implementation that implements length methods, which may be useful to somebody. I needed to know the progress (with <code>tqdm</code>) so the generator should've returned the number of chunks.</p>
<pre class="lang-py prettyprint-override"><code>class ChunksIterator(object):
    def __init__(self, data, n):
        self._data = data
        self._l = len(data)
        self._n = n

    def __iter__(self):
        for i in range(0, self._l, self._n):
            yield self._data[i:i + self._n]

    def __len__(self):
        rem = 1 if self._l % self._n != 0 else 0
        return self._l // self._n + rem
</code></pre>
<p>Usage:</p>
<pre class="lang-py prettyprint-override"><code>it = ChunksIterator([1,2,3,4,5,6,7,8,9], 2)
print(len(it))
for i in it:
  print(i)
</code></pre>
<h4> Sam Mason, Comment 127831440 Score: 0: </h4>your <code>__len__</code> method might be nicer if you used <code>divmod()</code><br>------------------------------------------------------------------ <br><h3> Jatin, Id: 76275047, Score: -1: </h3><pre><code>def devideChunks(x, n):
    newList = []
    for i in range(0, len(x), n):
        newList.append(x[i:i + n])

    print(newList)
</code></pre>
<h4> jmoerdyk, Comment 134506590 Score: 3: </h4>While this code may solve the question, <a href="https://meta.stackexchange.com/q/114762">including an explanation</a> of how and why this solves the problem would really help to improve the quality of your post, and probably result in more up-votes. Remember that you are answering the question for readers in the future, not just the person asking now. Please <a href="https://stackoverflow.com/posts/76275047/edit">edit</a> your answer to add explanations and give an indication of what limitations and assumptions apply<br><h4> Community, Comment 134506623 Score: 3: </h4>Your answer could be improved with additional supporting information. Please <a href="https://stackoverflow.com/posts/76275047/edit">edit</a> to add further details, such as citations or documentation, so that others can confirm that your answer is correct. You can find more information on how to write good answers <a href="/help/how-to-answer">in the help center</a>.<br>------------------------------------------------------------------ <br><h3> nikicat, Id: 70555495, Score: -2: </h3><p>One-liner version of <a href="https://stackoverflow.com/a/22045226/1022684">senderle's answer</a>:</p>
<pre><code>from itertools import islice
from functools import partial

seq = [1,2,3,4,5,6,7]
size = 3
result = list(iter(partial(lambda it: tuple(islice(it, size)), iter(seq)), ()))
assert result == [(1, 2, 3), (4, 5, 6), (7,)]
</code></pre>
