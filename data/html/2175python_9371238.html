 <h2> Title: Why is reading lines from stdin much slower in C++ than Python? </h2> <h4> JJC, question_id: 9371238 </h4>Score: 2175, Tags: {python,c++,benchmarking,iostream,getline} <br><p>I wanted to compare reading lines of string input from stdin using Python and C++ and was shocked to see my C++ code run an order of magnitude slower than the equivalent Python code. Since my C++ is rusty and I'm not yet an expert Pythonista, please tell me if I'm doing something wrong or if I'm misunderstanding something.</p>
<hr />
<p>(<strong>TLDR answer:</strong> include the statement: <code>cin.sync_with_stdio(false)</code> or just use <code>fgets</code> instead.</p>
<p><strong>TLDR results:</strong> scroll all the way down to the bottom of my question and look at the table.)</p>
<hr />
<p><strong>C++ code:</strong></p>
<pre class="lang-cpp prettyprint-override"><code>#include &lt;iostream&gt;
#include &lt;time.h&gt;

using namespace std;

int main() {
    string input_line;
    long line_count = 0;
    time_t start = time(NULL);
    int sec;
    int lps;

    while (cin) {
        getline(cin, input_line);
        if (!cin.eof())
            line_count++;
    };

    sec = (int) time(NULL) - start;
    cerr &lt;&lt; &quot;Read &quot; &lt;&lt; line_count &lt;&lt; &quot; lines in &quot; &lt;&lt; sec &lt;&lt; &quot; seconds.&quot;;
    if (sec &gt; 0) {
        lps = line_count / sec;
        cerr &lt;&lt; &quot; LPS: &quot; &lt;&lt; lps &lt;&lt; endl;
    } else
        cerr &lt;&lt; endl;
    return 0;
}

// Compiled with:
// g++ -O3 -o readline_test_cpp foo.cpp
</code></pre>
<p><strong>Python Equivalent:</strong></p>
<pre class="lang-py prettyprint-override"><code>#!/usr/bin/env python
import time
import sys

count = 0
start = time.time()

for line in  sys.stdin:
    count += 1

delta_sec = int(time.time() - start_time)
if delta_sec &gt;= 0:
    lines_per_sec = int(round(count/delta_sec))
    print(&quot;Read {0} lines in {1} seconds. LPS: {2}&quot;.format(count, delta_sec,
       lines_per_sec))
</code></pre>
<p><strong>Here are my results:</strong></p>
<pre class="lang-none prettyprint-override"><code>$ cat test_lines | ./readline_test_cpp
Read 5570000 lines in 9 seconds. LPS: 618889

$ cat test_lines | ./readline_test.py
Read 5570000 lines in 1 seconds. LPS: 5570000
</code></pre>
<p><em>I should note that I tried this both under Mac OS X v10.6.8 (Snow Leopard) and Linux 2.6.32 (Red Hat Linux 6.2). The former is a MacBook Pro, and the latter is a very beefy server, not that this is too pertinent.</em></p>
<pre class="lang-sh prettyprint-override"><code>$ for i in {1..5}; do echo &quot;Test run $i at `date`&quot;; echo -n &quot;CPP:&quot;; cat test_lines | ./readline_test_cpp ; echo -n &quot;Python:&quot;; cat test_lines | ./readline_test.py ; done
</code></pre>
<pre class="lang-none prettyprint-override"><code>Test run 1 at Mon Feb 20 21:29:28 EST 2012
CPP:   Read 5570001 lines in 9 seconds. LPS: 618889
Python:Read 5570000 lines in 1 seconds. LPS: 5570000
Test run 2 at Mon Feb 20 21:29:39 EST 2012
CPP:   Read 5570001 lines in 9 seconds. LPS: 618889
Python:Read 5570000 lines in 1 seconds. LPS: 5570000
Test run 3 at Mon Feb 20 21:29:50 EST 2012
CPP:   Read 5570001 lines in 9 seconds. LPS: 618889
Python:Read 5570000 lines in 1 seconds. LPS: 5570000
Test run 4 at Mon Feb 20 21:30:01 EST 2012
CPP:   Read 5570001 lines in 9 seconds. LPS: 618889
Python:Read 5570000 lines in 1 seconds. LPS: 5570000
Test run 5 at Mon Feb 20 21:30:11 EST 2012
CPP:   Read 5570001 lines in 10 seconds. LPS: 557000
Python:Read 5570000 lines in  1 seconds. LPS: 5570000
</code></pre>
<hr />
<p>Tiny benchmark addendum and recap</p>
<p>For completeness, I thought I'd update the read speed for the same file on the same box with the original (synced) C++ code. Again, this is for a 100M line file on a fast disk. Here's the comparison, with several solutions/approaches:</p>
<div class="s-table-container">
<table class="s-table">
<thead>
<tr>
<th style="text-align: left;">Implementation</th>
<th style="text-align: right;">Lines per second</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">python (default)</td>
<td style="text-align: right;">3,571,428</td>
</tr>
<tr>
<td style="text-align: left;">cin (default/naive)</td>
<td style="text-align: right;">819,672</td>
</tr>
<tr>
<td style="text-align: left;">cin (no sync)</td>
<td style="text-align: right;">12,500,000</td>
</tr>
<tr>
<td style="text-align: left;">fgets</td>
<td style="text-align: right;">14,285,714</td>
</tr>
<tr>
<td style="text-align: left;">wc (not fair comparison)</td>
<td style="text-align: right;">54,644,808</td>
</tr>
</tbody>
</table>
</div><h4> Xeo, Id: 11852573 Score: 27: </h4>Since nobody seems to have mentioned why you get an extra line with C++: <b>Do not test against <code>cin.eof()</code>!!</b> Put the <code>getline</code> call into the &#39;if` statement.<br><h4> jfs, Id: 11966378 Score: 27: </h4><code>wc -l</code> is fast because it reads the stream more than one line at a time (it might be <code>fread(stdin)&#47;memchr(&#39;\n&#39;)</code> combination). Python results are in the same order of magnitude e.g., <a href="http://ideone.com/Ri0ia" rel="nofollow noreferrer"><code>wc-l.py</code></a><br><h4> Vaughn Cato, Id: 11835760 Score: 21: </h4>The problem is synchronization with stdio -- see my answer.<br><h4> FeRD, Id: 131886879 Score: 0: </h4>There&#39;s no need to guess about how <code>wc -l</code> gets results: <a href="https://ftp.gnu.org/gnu/coreutils/coreutils-9.0.tar.xz" rel="nofollow noreferrer">the code</a> reveals that in coreutils 9.0, <code>wc</code> has two implementations: One does buffered reads 16KiB at a time and uses simple string walking for short lines, <code>rawmemchr()</code> for longer lines (&gt;= 15 chars/line average). The second is AVX2-based, and uses parallel <code>__mm256i</code> accumulators that it populates using <code>_mm256_cmpeq_epi8()</code> and <code>_mm256_sub_epi8()</code>, then sums with <code>_mm256_sad_epu8()</code> and extracts the counts from using <code>_mm256_extract_epi16()</code>. Yeah, it&#39;s built to be <b>fast</b>.<br><h4> Martin York, Id: 133493090 Score: 0: </h4>Also note: That reading from <code>std::cin</code> forces a flush of <code>std::cout</code> (as you want user to see any instructions before the user enters input). But if there is no user in the loop you can prevent this flush with <code>std::cin.tie(nullptr)</code>.<br><h4> Gabriel Staples, Id: 125498471 Score: 0: </h4>If you ever need high-resolution timestamps for testing smaller sample sizes, see <a href="https://stackoverflow.com/q/5833094/4561887">here for C</a>, <a href="https://stackoverflow.com/q/21856025/4561887">here for C++</a>, and <a href="https://stackoverflow.com/q/38319606/4561887">here for Python</a>.<br>------------------------------------------------------------------ <br><h3> Vaughn Cato, Id: 9371717, Score: 1934: </h3><h3>tl;dr: Because of different default settings in C++ requiring more system calls.</h3>
<p>By default, <code>cin</code> is synchronized with stdio, which causes it to avoid any input buffering.  If you add this to the top of your main, you should see much better performance:</p>
<pre><code>std::ios_base::sync_with_stdio(false);
</code></pre>
<p>Normally, when an input stream is buffered, instead of reading one character at a time, the stream will be read in larger chunks.  This reduces the number of system calls, which are typically relatively expensive.  However, since the <code>FILE*</code> based <code>stdio</code> and <code>iostreams</code> often have separate implementations and therefore separate buffers, this could lead to a problem if both were used together.  For example:</p>
<pre><code>int myvalue1;
cin &gt;&gt; myvalue1;
int myvalue2;
scanf(&quot;%d&quot;,&amp;myvalue2);
</code></pre>
<p>If more input was read by <code>cin</code> than it actually needed, then the second integer value wouldn't be available for the <code>scanf</code> function, which has its own independent buffer.  This would lead to unexpected results.</p>
<p>To avoid this, by default, streams are synchronized with <code>stdio</code>.  One common way to achieve this is to have <code>cin</code> read each character one at a time as needed using <code>stdio</code> functions.  Unfortunately, this introduces a lot of overhead.  For small amounts of input, this isn't a big problem, but when you are reading millions of lines, the performance penalty is significant.</p>
<p>Fortunately, the library designers decided that you should also be able to disable this feature to get improved performance if you knew what you were doing, so they provided the <a href="http://en.cppreference.com/w/cpp/io/ios_base/sync_with_stdio" rel="noreferrer"><code>sync_with_stdio</code></a> method. From this link (emphasis added):</p>
<blockquote>
<p>If the synchronization is turned off, the C++ standard streams are allowed to buffer their I/O independently, <strong>which may be considerably faster in some cases</strong>.</p>
</blockquote>
<h4> Karl Knechtel, Comment 11835795 Score: 177: </h4>This should be at the top. It is almost certainly correct. The answer cannot lie in replacing the read with an <code>fscanf</code> call, because that quite simply doesn&#39;t do as much work as Python does. Python must allocate memory for the string, possibly multiple times as the existing allocation is deemed inadequate - exactly like the C++ approach with <code>std::string</code>. This task is almost certainly I/O bound and there is way too much FUD going around about the cost of creating <code>std::string</code> objects in C++ or using <code>&lt;iostream&gt;</code> in and of itself.<br><h4> John Zwinck, Comment 44497768 Score: 70: </h4>Note that <code>sync_with_stdio()</code> is a static member function, and a call to this function on any stream object (e.g. <code>cin</code>) toggles on or off synchronization for <i>all</i> standard iostream objects.<br><h4> JJC, Comment 11835912 Score: 67: </h4>Yes, adding this line immediately above my original while loop sped the code up to surpass even python.  I&#39;m about to post the results as the final edit.  Thanks again!<br>------------------------------------------------------------------ <br><h3> 2mia, Id: 9657502, Score: 218: </h3><p>Just out of curiosity I've taken a look at what happens under the hood, and I've used <a href="http://en.wikipedia.org/wiki/Strace">dtruss/strace</a> on each test.</p>

<p>C++</p>

<pre><code>./a.out &lt; in
Saw 6512403 lines in 8 seconds.  Crunch speed: 814050
</code></pre>

<p>syscalls <code>sudo dtruss -c ./a.out &lt; in</code></p>

<pre><code>CALL                                        COUNT
__mac_syscall                                   1
&lt;snip&gt;
open                                            6
pread                                           8
mprotect                                       17
mmap                                           22
stat64                                         30
read_nocancel                               25958
</code></pre>

<p>Python</p>

<pre><code>./a.py &lt; in
Read 6512402 lines in 1 seconds. LPS: 6512402
</code></pre>

<p>syscalls <code>sudo dtruss -c ./a.py &lt; in</code></p>

<pre><code>CALL                                        COUNT
__mac_syscall                                   1
&lt;snip&gt;
open                                            5
pread                                           8
mprotect                                       17
mmap                                           21
stat64                                         29
</code></pre>
------------------------------------------------------------------ <br><h3> Bela Lubkin, Id: 43825662, Score: 214: </h3><p>I'm a few years behind here, but:</p>

<p>In 'Edit 4/5/6' of the original post, you are using the construction:</p>

<pre><code>$ /usr/bin/time cat big_file | program_to_benchmark
</code></pre>

<p>This is wrong in a couple of different ways:</p>

<ol>
<li><p>You're actually timing the execution of <code>cat</code>, not your benchmark.  The 'user' and 'sys' CPU usage displayed by <code>time</code> are those of <code>cat</code>, not your benchmarked program.  Even worse, the 'real' time is also not necessarily accurate. Depending on the implementation of <code>cat</code> and of pipelines in your local OS, it is possible that <code>cat</code> writes a final giant buffer and exits long before the reader process finishes its work.</p></li>
<li><p>Use of <code>cat</code> is unnecessary and in fact counterproductive; you're adding moving parts.  If you were on a sufficiently old system (i.e. with a single CPU and -- in certain generations of computers -- I/O faster than CPU) -- the mere fact that <code>cat</code> was running could substantially color the results.  You are also subject to whatever input and output buffering and other processing <code>cat</code> may do.  (This would likely earn you a <a href="https://en.wikipedia.org/wiki/Cat_(Unix)#Useless_use_of_cat" rel="noreferrer">'Useless Use Of Cat'</a> award if I were Randal Schwartz.</p></li>
</ol>

<p>A better construction would be:</p>

<pre><code>$ /usr/bin/time program_to_benchmark &lt; big_file
</code></pre>

<p>In this statement it is the <em>shell</em> which opens big_file, passing it to your program (well, actually to <code>time</code> which then executes your program as a subprocess) as an already-open file descriptor. 100% of the file reading is strictly the responsibility of the program you're trying to benchmark.  This gets you a real reading of its performance without spurious complications.</p>

<p>I will mention two possible, but actually wrong, 'fixes' which could also be considered (but I 'number' them differently as these are not things which were wrong in the original post):</p>

<p>A. You could 'fix' this by timing only your program:</p>

<pre><code>$ cat big_file | /usr/bin/time program_to_benchmark
</code></pre>

<p>B. or by timing the entire pipeline:</p>

<pre><code>$ /usr/bin/time sh -c 'cat big_file | program_to_benchmark'
</code></pre>

<p>These are wrong for the same reasons as #2: they're still using <code>cat</code> unnecessarily. I mention them for a few reasons:</p>

<ul>
<li><p>they're more 'natural' for people who aren't entirely comfortable with the I/O redirection facilities of the POSIX shell</p></li>
<li><p>there may be cases where <code>cat</code> <em>is</em> needed (e.g.: the file to be read requires some sort of privilege to access, and you do not want to grant that privilege to the program to be benchmarked: <code>sudo cat /dev/sda | /usr/bin/time my_compression_test --no-output</code>)</p></li>
<li><p><em>in practice</em>, on modern machines, the added <code>cat</code> in the pipeline is probably of no real consequence.</p></li>
</ul>

<p>But I say that last thing with some hesitation. If we examine the last result in 'Edit 5' --</p>

<pre><code>$ /usr/bin/time cat temp_big_file | wc -l
0.01user 1.34system 0:01.83elapsed 74%CPU ...
</code></pre>

<p>-- this claims that <code>cat</code> consumed 74% of the CPU during the test; and indeed 1.34/1.83 is approximately 74%.  Perhaps a run of:</p>

<pre><code>$ /usr/bin/time wc -l &lt; temp_big_file
</code></pre>

<p>would have taken only the remaining .49 seconds!  Probably not: <code>cat</code> here had to pay for the <code>read()</code> system calls (or equivalent) which transferred the file from 'disk' (actually buffer cache), as well as the pipe writes to deliver them to <code>wc</code>.  The correct test would still have had to do those <code>read()</code> calls; only the write-to-pipe and read-from-pipe calls would have been saved, and those should be pretty cheap.</p>

<p>Still, I predict you would be able to measure the difference between <code>cat file | wc -l</code> and <code>wc -l &lt; file</code> and find a noticeable (2-digit percentage) difference. Each of the slower tests will have paid a similar penalty in absolute time; which would however amount to a smaller fraction of its larger total time.</p>

<p>In fact I did some quick tests with a 1.5 gigabyte file of garbage, on a Linux 3.13 (Ubuntu 14.04) system, obtaining these results (these are actually 'best of 3' results; after priming the cache, of course): </p>

<pre><code>$ time wc -l &lt; /tmp/junk
real 0.280s user 0.156s sys 0.124s (total cpu 0.280s)
$ time cat /tmp/junk | wc -l
real 0.407s user 0.157s sys 0.618s (total cpu 0.775s)
$ time sh -c 'cat /tmp/junk | wc -l'
real 0.411s user 0.118s sys 0.660s (total cpu 0.778s)
</code></pre>

<p>Notice that the two pipeline results claim to have taken more CPU time (user+sys) than real wall-clock time. This is because I'm using the shell (bash)'s built-in 'time' command, which is cognizant of the pipeline; and I'm on a multi-core machine where separate processes in a pipeline can use separate cores, accumulating CPU time faster than realtime.  Using <code>/usr/bin/time</code> I see smaller CPU time than realtime -- showing that it can only time the single pipeline element passed to it on its command line. Also, the shell's output gives milliseconds while <code>/usr/bin/time</code> only gives hundredths of a second.</p>

<p>So at the efficiency level of <code>wc -l</code>, the <code>cat</code> makes a huge difference: 409 / 283 = 1.453 or 45.3% more realtime, and 775 / 280 = 2.768, or a whopping 177% more CPU used!  On my random it-was-there-at-the-time test box.</p>

<p>I should add that there is at least one other significant difference between these styles of testing, and I can't say whether it is a benefit or fault; you have to decide this yourself:</p>

<p>When you run <code>cat big_file | /usr/bin/time my_program</code>, your program is receiving input from a pipe, at precisely the pace sent by <code>cat</code>, and in chunks no larger than written by <code>cat</code>.</p>

<p>When you run <code>/usr/bin/time my_program &lt; big_file</code>, your program receives an open file descriptor to the actual file.  Your program -- <em>or</em> in many cases the I/O libraries of the language in which it was written -- may take different actions when presented with a file descriptor referencing a regular file.  It may use <code>mmap(2)</code> to map the input file into its address space, instead of using explicit <code>read(2)</code> system calls.  These differences could have a far larger effect on your benchmark results than the small cost of running the <code>cat</code> binary.</p>

<p>Of course it is an interesting benchmark result if the same program performs significantly differently between the two cases. It shows that, indeed, the program or its I/O libraries <em>are</em> doing something interesting, like using <code>mmap()</code>. So in practice it might be good to run the benchmarks both ways; perhaps discounting the <code>cat</code> result by some small factor to "forgive" the cost of running <code>cat</code> itself.</p>
<h4> JJC, Comment 74754618 Score: 42: </h4>Wow, that was quite insightful!  While I&#39;ve been aware that cat is unnecessary for feeding input to stdin of programs and that the &lt; shell redirect is preferred, I&#39;ve generally stuck to cat due to the left-to-right flow of data that the former method preserves visually when I reason about pipelines. Performance differences in such cases I&#39;ve found to be negligible.  But, I do appreciate your educating us, Bela.<br><h4> Bela Lubkin, Comment 74840596 Score: 21: </h4>Redirection is parsed out of the shell command line at an early stage, which allows you to do one of these, if it gives a more pleasing appearance of left-to-right flow:      <code>$ &lt; big_file time my_program</code>     <code>$ time &lt; big_file my_program</code>  This should work in any POSIX shell (i.e. not `csh` and I&#39;m not sure about exotica like `rc` : )<br>------------------------------------------------------------------ <br><h3> karunski, Id: 9371800, Score: 109: </h3><p>I reproduced the original result on my computer using g++ on a Mac.</p>
<p>Adding the following statements to the C++ version just before the <code>while</code> loop brings it inline with the <a href="http://en.wikipedia.org/wiki/Python_%28programming_language%29" rel="nofollow noreferrer">Python</a> version:</p>
<pre class="lang-cpp prettyprint-override"><code>std::ios_base::sync_with_stdio(false);
char buffer[1048576];
std::cin.rdbuf()-&gt;pubsetbuf(buffer, sizeof(buffer));
</code></pre>
<p><code>sync_with_stdio</code> improved speed to 2 seconds, and setting a larger buffer brought it down to 1 second.</p>
<h4> Matthieu M., Comment 11838522 Score: 130: </h4>I would also avoid setting up a 1MB buffer on the stack. It can lead to stackoverflow (though I guess it&#39;s a good place to debate about it!)<br><h4> &#201;tienne, Comment 34089412 Score: 26: </h4>@SEK Windows default Stack size is 1MB.<br><h4> SEK, Comment 31759802 Score: 15: </h4>Matthieu, Mac uses a 8MB process stack by default. Linux uses 4MB per thread default, IIRC. 1MB isn&#39;t that much of an issue for a program that transforms input with relatively shallow stack depth. More importantly, though, std::cin will trash the stack if the buffer goes out of scope.<br>------------------------------------------------------------------ <br><h3> Stu, Id: 9693553, Score: 48: </h3><p><code>getline</code>, stream operators, <code>scanf</code>, can be convenient if you don't care about file loading time or if you are loading small text files. But, if the performance is something you care about, you should really just buffer the entire file into memory (assuming it will fit).</p>

<p>Here's an example:</p>

<pre><code>//open file in binary mode
std::fstream file( filename, std::ios::in|::std::ios::binary );
if( !file ) return NULL;

//read the size...
file.seekg(0, std::ios::end);
size_t length = (size_t)file.tellg();
file.seekg(0, std::ios::beg);

//read into memory buffer, then close it.
char *filebuf = new char[length+1];
file.read(filebuf, length);
filebuf[length] = '\0'; //make it null-terminated
file.close();
</code></pre>

<p>If you want, you can wrap a stream around that buffer for more convenient access like this:</p>

<pre><code>std::istrstream header(&amp;filebuf[0], length);
</code></pre>

<p>Also, if you are in control of the file, consider using a flat binary data format instead of text. It's more reliable to read and write because you don't have to deal with all the ambiguities of whitespace. It's also smaller and much faster to parse.</p>
<h4> ljleb, Comment 128962049 Score: 0: </h4>even though I&#39;m not confident enough in my knowledge to write code for it here, I just want to mention memory mapping as another alternative to reading files into memory. see <a href="https://www.man7.org/linux/man-pages/man2/mmap.2.html" rel="nofollow noreferrer">mmap</a> for the linux-specific api.<br>------------------------------------------------------------------ <br><h3> Petter, Id: 23248053, Score: 27: </h3><p>The following code was faster for me than the other code posted here so far:
(Visual Studio 2013, 64-bit, 500 MB file with line length uniformly in [0, 1000)).</p>

<pre><code>const int buffer_size = 500 * 1024;  // Too large/small buffer is not good.
std::vector&lt;char&gt; buffer(buffer_size);
int size;
while ((size = fread(buffer.data(), sizeof(char), buffer_size, stdin)) &gt; 0) {
    line_count += count_if(buffer.begin(), buffer.begin() + size, [](char ch) { return ch == '\n'; });
}
</code></pre>

<p>It beats all my Python attempts by more than a factor 2.</p>
------------------------------------------------------------------ <br><h3> Gregg, Id: 9656778, Score: 22: </h3><p>By the way, the reason the line count for the C++ version is one greater than the count for the Python version is that the eof flag only gets set when an attempt is made to read beyond eof. So the correct loop would be:</p>

<pre><code>while (cin) {
    getline(cin, input_line);

    if (!cin.eof())
        line_count++;
};
</code></pre>
<h4> Jonathan Wakely, Comment 13513097 Score: 82: </h4>The really correct loop would be:       <code>while (getline(cin, input_line)) line_count++;</code><br>------------------------------------------------------------------ <br><h3> davinchi, Id: 9371784, Score: 17: </h3><p>In your second example (with <code>scanf()</code>) reason why this is still slower might be because <code>scanf(&quot;%s&quot;)</code> parses string and looks for any space char (space, tab, newline).</p>
<p>Also, yes, CPython does some caching to avoid harddisk reads.</p>
------------------------------------------------------------------ <br><h3> J.N., Id: 9371651, Score: 14: </h3><p>A first element of an answer: <code>&lt;iostream&gt;</code> is slow. Damn slow. I get a huge performance boost with <code>scanf</code> as in the below, but it is still two times slower than Python.</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;time.h&gt;
#include &lt;cstdio&gt;

using namespace std;

int main() {
    char buffer[10000];
    long line_count = 0;
    time_t start = time(NULL);
    int sec;
    int lps;

    int read = 1;
    while(read &gt; 0) {
        read = scanf("%s", buffer);
        line_count++;
    };
    sec = (int) time(NULL) - start;
    line_count--;
    cerr &lt;&lt; "Saw " &lt;&lt; line_count &lt;&lt; " lines in " &lt;&lt; sec &lt;&lt; " seconds." ;
    if (sec &gt; 0) {
        lps = line_count / sec;
        cerr &lt;&lt; "  Crunch speed: " &lt;&lt; lps &lt;&lt; endl;
    } 
    else
        cerr &lt;&lt; endl;
    return 0;
}
</code></pre>
------------------------------------------------------------------ <br><h3> Jos&#233; Ernesto Lara Rodr&#237;guez, Id: 9388343, Score: 12: </h3><p>Well, I see that in your second solution you switched from <code>cin</code> to <code>scanf</code>, which was the first suggestion I was going to make you (<code>cin</code> is sloooooooooooow). Now, if you switch from <code>scanf</code> to <code>fgets</code>, you would see another boost in performance: <code>fgets</code> is the fastest C++ function for string input.</p>
<p>BTW, didn't know about that sync thing, nice. But you should still try <code>fgets</code>.</p>
