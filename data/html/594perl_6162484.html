 <h2> Title: Why does modern Perl avoid UTF-8 by default? </h2> <h3> w.k, question_id: 6162484 </h3>Score: 594, Tags: {perl,unicode,utf-8} <br><p>I wonder why most modern solutions built using Perl don't enable <a href="http://en.wikipedia.org/wiki/UTF-8" rel="noreferrer">UTF-8</a> by default.</p>

<p>I understand there are many legacy problems for core Perl scripts, where it may break things. But, from my point of view, in the 21<sup>st</sup> century, big new projects (or projects with a big perspective) should make their software UTF-8 proof from scratch. Still I don't see it happening. For example, <a href="http://en.wikipedia.org/wiki/Moose_%28Perl%29" rel="noreferrer">Moose</a> enables strict and warnings, but not <a href="http://en.wikipedia.org/wiki/Unicode" rel="noreferrer">Unicode</a>. <a href="http://search.cpan.org/~chromatic/Modern-Perl-1.03/lib/Modern/Perl.pm" rel="noreferrer">Modern::Perl</a> reduces boilerplate too, but no UTF-8 handling.</p>

<p>Why? Are there some reasons to avoid UTF-8 in modern Perl projects in the year 2011?</p>

<hr>

<p>Commenting @tchrist got too long, so I'm adding it here.</p>

<p>It seems that I did not make myself clear. Let me try to add some things.</p>

<p><strong>tchrist</strong> and I see situation pretty similarly, but our conclusions are completely in opposite ends. I agree, the situation with Unicode is complicated, but this is why we (Perl users and coders) need some layer (or pragma) which makes UTF-8 handling as easy as it must be nowadays.</p>

<p><strong>tchrist</strong> pointed to many aspects to cover, I will read and think about them for days or even weeks. Still, this is not my point. <strong>tchrist</strong> tries to prove that there is not one single way "to enable UTF-8". I have not so much knowledge to argue with that. So, I stick to live examples.</p>

<p>I played around with <a href="http://en.wikipedia.org/wiki/Rakudo_Perl" rel="noreferrer">Rakudo</a> and UTF-8 was just there <strong>as I needed</strong>. I didn't have any problems, it just worked. Maybe there are some limitation somewhere deeper, but at start, all I tested worked as I expected.</p>

<p>Shouldn't that be a goal in modern Perl&nbsp;5 too? I stress it more: I'm not suggesting UTF-8 as the default character set for core Perl, I suggest the possibility to trigger it <strong>with a snap</strong> for those who develop <strong>new</strong> projects.</p>

<p>Another example, but with a more negative tone. Frameworks should make development easier. Some years ago, I tried web frameworks, but just threw them away because "enabling UTF-8" was so obscure. I did not find how and where to hook Unicode support. It was so time-consuming that I found it easier to go the old way. Now I saw here there was a bounty to deal with the same problem with <a href="http://en.wikipedia.org/wiki/Mason_%28Perl%29" rel="noreferrer">Mason</a> 2: <em><a href="https://stackoverflow.com/questions/5858596/how-to-make-mason2-utf8-clean">How to make Mason2 UTF-8 clean?</a></em>. So, it is pretty new framework, but using it with UTF-8 needs deep knowledge of its internals. It is like a big red sign: STOP, don't use me!</p>

<p>I really like Perl. But dealing with Unicode is painful. I still find myself running against walls. Some way <strong>tchrist</strong> is right and answers my questions: new projects don't attract UTF-8 because it is too complicated in Perl&nbsp;5.</p>
<h4> Comment 7201768 Billy ONeal: </h4>I&#39;m sorry but I agree with @tchrist -- UTF-8 is extremely hard. There&#39;s no framework or tool that just &quot;flips a switch&quot; and then handles it correctly. It&#39;s something you have to think about directly when designing your application -- not something any kind of framework or language can handle for you. If rakudo just happened to work for you, you were not adventurous enough with your test cases -- as it will take several of the examples in @tchrist&#39;s answer and butcher then.<br><h4> Comment 8190666 Jakub Narębski: </h4>Nb. <b>tchrist</b> (Tom Christiansen) posted his [<a href="http://training.perl.com/OSCON2011/index.html" rel="nofollow noreferrer">training.perl.com/OSCON2011/index.html</a> Tom Christiansen’s Materials for OSCON 2011] about Unicode.  The one titled &quot;Unicode Support Shootout: The Good, The Bad, &amp; the (mostly) Ugly&quot; talks about Unicode support in different programming languages.  Only Google Go and Perl5 has support for full Unicode, only Google Go builtin (no mention of Perl6).<br><h4> Comment 7208039 jrockway: </h4>What does that mean?  Moose has nothing to do with text manipulation.  Why should it know about character encoding, much less choose a default one for you?  (Anyway, the reason why the pragmas you list don&#39;t touch the encoding is because the convention is for Perl pragmas to affect <i>lexical</i> behavior.  Assuming that the Entire World, other modules included, is UTF-8 is simply the Wrong Thing To Do.  This isn&#39;t PHP or Ruby here.)<br><h4> Comment 7202274 jrockway: </h4>What exactly are you hoping Moose or Modern::Perl will do?  Magically make randomly-encoded character data in files and databases into valid data again?<br><h4> Comment 7208045 jrockway: </h4>(Also... &quot;most Modern Perl apps&quot; break on UTF-8?  I&#39;ve certainly never written an application, Perl or otherwise, that&#39;s not Unicode-clean.)<br><h4> Comment 29251012 Mark Reed: </h4>If I&#39;m on a POSIX system and have <code>ENV[&#39;LC_ALL&#39;]</code> set to e.g. &quot;en_US.UTF-8&quot;, then that is an explicit statement of intent which Perl should honor by assuming that its standard input is encoded as UTF-8, and encoding its standard output likewise. If my code breaks because it doesn&#39;t handle some of the many subtleties of Unicode, maybe I shouldn&#39;t run it in an environment that claims to <i>be</i> Unicode.  I don&#39;t understand why Perl should ignore the locale settings in favor of whatever the heck its default is.<br><h4> Comment 7170509 Kev: </h4>Hi Folks - there&#39;s a few flags raised here on these comments. What I&#39;ve done is taken a snapshot of the comments here and dropped them into this chat room where you can carry on this discussion: <a href="http://chat.stackoverflow.com/rooms/846/why-does-modern-perl-avoid-utf-8-by-default">chat.stackoverflow.com/rooms/846/&hellip;</a><br><h4> Comment 114381327 Peter Mortensen: </h4><a href="https://www.perl.com/article/announcing-perl-7/" rel="nofollow noreferrer">It will change in Perl 7</a>.<br><h4> Comment 7202945 w.k: </h4>@Billy ONeal: looping over the @tchrist list, there is no one and only cure. I agree. Still is there some common level of UTF-8 handling, which is pluggable just so and which helps developer step into the game. I think, the knowledge in this new module <code>utf8::all</code> is very good beginning. If it (or similar functionality) were in core and <code>perluniintro</code> suggest it as quick start, would be much better.<br><h4> Comment 100331743 Nils Lindemann: </h4>@tchrist Im not sure if i get your point. Python uses unicode internally everywhere and there is no need to worry about bits and bytes. len(&#39;aou&#39;) == len(&#39;&#228;&#246;&#252;&#39;) == len(&#39;테스트&#39;). If a module has no encoding declaration python assumes utf-8 and decodes it to unicode. Windows filesystem and console encoding was changed to UTF-8 in v3.6 All relevant python 3 libraries encode in utf-8 and internally use unicode. Only when open() ing files in text mode without the encoding parameter (which no library does) python will still prefer locale.getpreferredencoding().<br><h4> Comment 99864224 Nils Lindemann: </h4>I know, this is a bit offtopic and trolly, but why not get rid of anachronistic languages like Perl and PHP and just use Python and have unicode be the default. To convert to a specific encoding,do <code>&#39;string&#39;.encode(&#39;utf-8&#39;)</code> (you get <code>b&#39;string&#39;</code>) and to convert that binary string back to unicode, do <code>b&#39;string&#39;.decode(&#39;utf-8&#39;)</code> (you get <code>&#39;string&#39;</code>). Now you can stop thinking about it. That would be my way of getting things done in 2019. Being old usually means being stable, but it often also means not getting rid of ugly ways to do things (this of course also affects Python).<br><h4> Comment 100241571 tchrist: </h4>@Nils Because if you have to worry about encoding and decoding binary bit patterns, you&#39;re doing it wrong. UTF-8 is nothing but an encoding, and you should never have to think about its individual, constituent byte-sized code units. At most you should be thinking of abstract code points — and not whether they&#39;re big- or little-ending either. :) Encoding and decoding should virtually always happen at the very boundaries of the interface layering for interchange with external entities. Trust me, intra-converting code points w/bit patterns is the <i>least</i> of your worries when it comes to Unicode.<br><h4> Comment 7203063 w.k: </h4>@jrockway: what is the purpose on Modern::Perl? Reduce boilerplate and introduce best practices of nowadays technologies available in Perl. Including UTF-8 handling suits here very well, IMHO. Similar with Moose: it is modern object system for Perl. So, why not to make another step and include UTF-8 as default charset in Moose?<br><h4> Comment 40126428 Lee Goddard: </h4>I&#39;ve not looked into it much, but utf8::all seems to work for my basic needs. FWIW, I think the sort of (public) simplicity of utf-8 use in Java is something Perl could hugely benefit from.<br><h4> Comment 21136851 hippietrail: </h4>Is your question specifically about any one operating system? The most voted answer seems to be Linux specific. Or at least specific to Unices other than MacOS X.<br><h4> Comment 21140117 w.k: </h4>@hippietrail: i work mostly on Linux but i have seen a lot UTF-8 related Perl questions related to Win too. I have too few knowledge with MacOS X, but as far i understand, the same questions should be actual in Mac too. If not, i am glad about it and looking forward to work soon with Perl on Mac.<br>------------------------------------------------------------------ <br><h3> Answer 6163129 tchrist: </h3><h1>𝙎𝙞𝙢𝙥𝙡𝙚𝙨𝙩 <em>℞</em>:   𝟕 𝘿𝙞𝙨𝙘𝙧𝙚𝙩𝙚  𝙍𝙚𝙘𝙤𝙢𝙢𝙚𝙣𝙙𝙖𝙩𝙞𝙤𝙣𝙨</h1>

<ol>
<li><p>Set your <code>PERL_UNICODE</code> envariable to <code>AS</code>. This makes all Perl scripts decode <code>@ARGV</code> as UTF‑8 strings, and sets the encoding of all three of stdin, stdout, and stderr to UTF‑8. Both these are global effects, not lexical ones.</p></li>
<li><p>At the top of your source file (program, module, library, <code>do</code>hickey), prominently assert that you are running perl version 5.12 or better via:</p>

<pre><code>use v5.12;  # minimal for unicode string feature
use v5.14;  # optimal for unicode string feature
</code></pre></li>
<li><p>Enable warnings, since the previous declaration only enables strictures and features, not warnings. I also suggest promoting Unicode warnings into exceptions, so use both these lines, not just one of them.  Note however that under v5.14, the <code>utf8</code> warning class comprises three other subwarnings which can all be separately enabled: <code>nonchar</code>, <code>surrogate</code>, and <code>non_unicode</code>. These you may wish to exert greater control over.</p>

<pre><code>use warnings;
use warnings qw( FATAL utf8 );
</code></pre></li>
<li><p>Declare that this source unit is encoded as UTF‑8. Although once upon a time this pragma did other things, it now serves this one singular purpose alone and no other:</p>

<pre><code>use utf8;
</code></pre></li>
<li><p>Declare that anything that opens a filehandle <em>within this lexical scope but not elsewhere</em> is to assume that that stream is encoded in UTF‑8 unless you tell it otherwise. That way you do not affect other module’s or other program’s code.</p>

<pre><code>use open qw( :encoding(UTF-8) :std );
</code></pre></li>
<li><p>Enable named characters via <code>\N{CHARNAME}</code>.</p>

<pre><code>use charnames qw( :full :short );
</code></pre></li>
<li><p>If you have a <code>DATA</code> handle, you must explicitly set its encoding. If you want this to be UTF‑8, then say:</p>

<pre><code>binmode(DATA, ":encoding(UTF-8)");
</code></pre></li>
</ol>

<p>There is of course no end of other matters with which you may eventually find yourself concerned, but these will suffice to approximate the state goal to “make everything just work with UTF‑8”, albeit for a somewhat weakened sense of those terms. </p>

<p>One other pragma, although it is not Unicode related, is:</p>

<pre><code>      use autodie;
</code></pre>

<p>It is strongly recommended.</p>

<p>🌴 🐪🐫🐪 🌞 <em>𝕲𝖔  𝕿𝖍𝖔𝖚  𝖆𝖓𝖉  𝕯𝖔  𝕷𝖎𝖐𝖊𝖜𝖎𝖘𝖊</em> 🌞 🐪🐫🐪 🐁</p>

<hr>

<h2>        🎁   🐪       𝕭𝖔𝖎𝖑𝖊𝖗⸗𝖕𝖑𝖆𝖙𝖊  𝖋𝖔𝖗   𝖀𝖓𝖎𝖈𝖔𝖉𝖊⸗𝕬𝖜𝖆𝖗𝖊    𝕮𝖔𝖉𝖊        🐪    🎁</h2>

<hr>

<p>My own boilerplate these days tends to look like this:</p>

<pre><code>use 5.014;

use utf8;
use strict;
use autodie;
use warnings; 
use warnings    qw&lt; FATAL  utf8     &gt;;
use open        qw&lt; :std  :utf8     &gt;;
use charnames   qw&lt; :full &gt;;
use feature     qw&lt; unicode_strings &gt;;

use File::Basename      qw&lt; basename &gt;;
use Carp                qw&lt; carp croak confess cluck &gt;;
use Encode              qw&lt; encode decode &gt;;
use Unicode::Normalize  qw&lt; NFD NFC &gt;;

END { close STDOUT }

if (grep /\P{ASCII}/ =&gt; @ARGV) { 
   @ARGV = map { decode("UTF-8", $_) } @ARGV;
}

$0 = basename($0);  # shorter messages
$| = 1;

binmode(DATA, ":utf8");

# give a full stack dump on any untrapped exceptions
local $SIG{__DIE__} = sub {
    confess "Uncaught exception: @_" unless $^S;
};

# now promote run-time warnings into stack-dumped
#   exceptions *unless* we're in an try block, in
#   which case just cluck the stack dump instead
local $SIG{__WARN__} = sub {
    if ($^S) { cluck   "Trapped warning: @_" } 
    else     { confess "Deadly warning: @_"  }
};

while (&lt;&gt;)  {
    chomp;
    $_ = NFD($_);
    ...
} continue {
    say NFC($_);
}

__END__
</code></pre>

<hr>

<h1>                     🎅      𝕹 𝖔   𝕸 𝖆 𝖌 𝖎 𝖈   𝕭 𝖚 𝖑 𝖑 𝖊 𝖙    🎅</h1>

<hr>

<p>Saying that “Perl should [<strong>somehow!</strong>] enable Unicode by default” doesn’t even start to begin to think about getting around to saying enough to be even marginally useful in some sort of rare and isolated case.  Unicode is much much more than just a larger character repertoire; it’s also how those characters all interact in many, many ways.</p>

<p>Even the simple-minded minimal measures that (some) people seem to think they want are guaranteed to miserably break millions of lines of code, code that has no chance to “upgrade” to your spiffy new <em>Brave New World</em> modernity. </p>

<p>It is way way way more complicated than people pretend.  I’ve thought about this a huge, whole lot over the past few years.  I would love to be shown that I am wrong.  But I don’t think I am.  Unicode is fundamentally more complex than the model that you would like to impose on it, and there is complexity here that you can never sweep under the carpet. If you try, you’ll break either your own code or somebody else’s.  At some point, you simply have to break down and learn what Unicode is about.  You cannot pretend it is something it is not. </p>

<p>🐪  goes out of its way to make Unicode easy, far more than anything else I’ve ever used. If you think this is bad, try something else for a while. Then come back to 🐪: either you will have returned to a better world, or else you will bring knowledge of the same with you so that we can make use of your new knowledge to make 🐪  better at these things.</p>

<hr>

<h2>         💡     𝕴𝖉𝖊𝖆𝖘       𝖋𝖔𝖗    𝖆       𝖀𝖓𝖎𝖈𝖔𝖉𝖊 ⸗ 𝕬𝖜𝖆𝖗𝖊    🐪    𝕷𝖆𝖚𝖓𝖉𝖗𝖞    𝕷𝖎𝖘𝖙      💡</h2>

<hr>

<p>At a minimum, here  are some things that would appear to be required for 🐪 to “enable Unicode by default”, as you put it:</p>

<ol>
<li><p>All 🐪  source code should be in UTF-8 by default.  You can get that with <code>use utf8</code> or <code>export PERL5OPTS=-Mutf8</code>.</p></li>
<li><p>The 🐪  <code>DATA</code> handle should be UTF-8. You will have to do this on a per-package basis, as in <code>binmode(DATA, ":encoding(UTF-8)")</code>.</p></li>
<li><p>Program arguments to 🐪  scripts should be understood to be UTF-8 by default.  <code>export PERL_UNICODE=A</code>, or <code>perl -CA</code>, or <code>export PERL5OPTS=-CA</code>.</p></li>
<li><p>The standard input, output, and error streams should default to UTF-8. <code>export PERL_UNICODE=S</code> for all of them, or <code>I</code>, <code>O</code>, and/or <code>E</code> for just some of them. This is like <code>perl -CS</code>.</p></li>
<li><p>Any other handles opened by 🐪 should be considered UTF-8 unless declared otherwise; <code>export PERL_UNICODE=D</code> or with <code>i</code> and <code>o</code> for particular ones of these; <code>export PERL5OPTS=-CD</code> would work.  That makes <code>-CSAD</code> for all of them.</p></li>
<li><p>Cover both bases plus all the streams you open with <code>export PERL5OPTS=-Mopen=:utf8,:std</code>. See <a href="http://training.perl.com/scripts/uniquote" rel="noreferrer"><em>uniquote</em></a>.</p></li>
<li><p>You don’t want to miss UTF-8 encoding errors. Try <code>export PERL5OPTS=-Mwarnings=FATAL,utf8</code>.  And make sure your input streams are always <code>binmode</code>d to <code>:encoding(UTF-8)</code>, not just to <code>:utf8</code>.</p></li>
<li><p>Code points between 128–255 should be understood by 🐪 to be the corresponding Unicode code points, not just unpropertied binary values.  <code>use feature "unicode_strings"</code> or <code>export PERL5OPTS=-Mfeature=unicode_strings</code>.  That will make <code>uc("\xDF") eq "SS"</code> and <code>"\xE9" =~ /\w/</code>.  A simple <code>export PERL5OPTS=-Mv5.12</code> or better will also get that.</p></li>
<li><p>Named Unicode characters are not by default enabled, so add <code>export PERL5OPTS=-Mcharnames=:full,:short,latin,greek</code> or some such. See <a href="http://training.perl.com/scripts/uninames" rel="noreferrer"><em>uninames</em></a> and <a href="http://training.perl.com/scripts/tcgrep" rel="noreferrer">tcgrep</a>.</p></li>
<li><p>You almost always need access to the functions from <a href="https://metacpan.org/pod/Unicode::Normalize" rel="noreferrer">the standard <code>Unicode::Normalize</code> module</a> various types of decompositions.  <code>export PERL5OPTS=-MUnicode::Normalize=NFD,NFKD,NFC,NFKD</code>, and then always run incoming stuff through NFD and outbound stuff from NFC. There’s no I/O layer for these yet that I’m aware of, but see <a href="http://training.perl.com/scripts/nfc" rel="noreferrer"><em>nfc</em></a>, <a href="http://training.perl.com/scripts/nfd" rel="noreferrer"><em>nfd</em></a>, <a href="http://training.perl.com/scripts/nfkd" rel="noreferrer"><em>nfkd</em></a>, and <a href="http://training.perl.com/scripts/nfkc" rel="noreferrer"><em>nfkc</em></a>.</p></li>
<li><p>String comparisons in 🐪 using <code>eq</code>, <code>ne</code>, <code>lc</code>, <code>cmp</code>, <code>sort</code>, &amp;c&amp;cc are always wrong.  So instead of <code>@a = sort @b</code>, you need <code>@a = Unicode::Collate-&gt;new-&gt;sort(@b)</code>.  Might as well add that to your <code>export PERL5OPTS=-MUnicode::Collate</code>. You can cache the key for binary comparisons.</p></li>
<li><p>🐪 built-ins like <code>printf</code> and <code>write</code> do the wrong thing with Unicode data.  You need to use <a href="https://metacpan.org/pod/Unicode::GCString" rel="noreferrer">the <code>Unicode::GCString</code> module</a> for the former, and both that and also <a href="https://metacpan.org/pod/Unicode::LineBreak" rel="noreferrer">the <code>Unicode::LineBreak</code> module</a> as well for the latter. See <a href="http://training.perl.com/scripts/uwc" rel="noreferrer"><em>uwc</em></a> and <a href="http://training.perl.com/scripts/ucsort" rel="noreferrer"><em>unifmt</em></a>.</p></li>
<li><p>If you want them to count as integers, then you are going to have to run your <code>\d+</code> captures through <a href="https://metacpan.org/pod/release/JESSE/perl-5.14.0/lib/Unicode/UCD.pm#num" rel="noreferrer">the <code>Unicode::UCD::num</code> function</a> because 🐪’s built-in <em>atoi</em>(3) isn’t currently clever enough.</p></li>
<li><p>You are going to have filesystem issues on 👽 filesystems. Some filesystems silently enforce a conversion to NFC; others silently enforce a conversion to NFD. And others do something else still. Some even ignore the matter altogether, which leads to even greater problems. So you have to do your own NFC/NFD handling to keep sane.</p></li>
<li><p>All your 🐪  code involving <code>a-z</code> or <code>A-Z</code> and such <strong>MUST BE CHANGED</strong>, including <code>m//</code>, <code>s///</code>, and <code>tr///</code>. It’s should stand out as a screaming red flag that your code is broken. But it is not clear how it must change. Getting the right properties, and understanding their casefolds, is harder than you might think. I use <a href="http://training.perl.com/scripts/unichars" rel="noreferrer"><em>unichars</em></a> and <a href="http://training.perl.com/scripts/uniprops" rel="noreferrer"><em>uniprops</em></a> every single day.</p></li>
<li><p>Code that uses <code>\p{Lu}</code> is almost as wrong as code that uses <code>[A-Za-z]</code>.  You need to use <code>\p{Upper}</code> instead, and know the reason why. Yes, <code>\p{Lowercase}</code> and <code>\p{Lower}</code> are different from <code>\p{Ll}</code> and <code>\p{Lowercase_Letter}</code>.</p></li>
<li><p>Code that uses <code>[a-zA-Z]</code> is even worse.  And it can’t use <code>\pL</code> or <code>\p{Letter}</code>; it needs to use <code>\p{Alphabetic}</code>. Not all alphabetics are letters, you know!</p></li>
<li><p>If you are looking for 🐪 variables with <code>/[\$\@\%]\w+/</code>, then you have a problem.  You need to look for <code>/[\$\@\%]\p{IDS}\p{IDC}*/</code>, and even that isn’t thinking about the punctuation variables or package variables.</p></li>
<li><p>If you are checking for whitespace, then you should choose between <code>\h</code> and <code>\v</code>, depending.  And you should never use <code>\s</code>, since it <strong>DOES NOT MEAN</strong> <code>[\h\v]</code>, contrary to popular belief.</p></li>
<li><p>If you are using <code>\n</code> for a line boundary, or even <code>\r\n</code>, then you are doing it wrong.  You have to use <code>\R</code>, which is not the same!</p></li>
<li><p>If you don’t know when and whether to call <a href="https://metacpan.org/pod/Unicode::Stringprep" rel="noreferrer">Unicode::Stringprep</a>, then you had better learn.</p></li>
<li><p>Case-insensitive comparisons need to check for whether two things are the same letters no matter their diacritics and such.  The easiest way to do that is with the <a href="https://metacpan.org/pod/Unicode::Collate" rel="noreferrer">standard Unicode::Collate</a> module. <code>Unicode::Collate-&gt;new(level =&gt; 1)-&gt;cmp($a, $b)</code>.  There are also <code>eq</code> methods and such, and you should probably learn about the <code>match</code> and <code>substr</code> methods, too. These are have distinct advantages over the 🐪  built-ins.</p></li>
<li><p>Sometimes that’s still not enough, and you need <a href="https://metacpan.org/pod/Unicode::Collate::Locale" rel="noreferrer">the Unicode::Collate::Locale</a> module instead, as in  <code>Unicode::Collate::Locale-&gt;new(locale =&gt; "de__phonebook", level =&gt; 1)-&gt;cmp($a, $b)</code> instead.   Consider that <code>Unicode::Collate::-&gt;new(level =&gt; 1)-&gt;eq("d", "ð")</code> is true, but <code>Unicode::Collate::Locale-&gt;new(locale=&gt;"is",level =&gt; 1)-&gt;eq("d", " ð")</code> is false. Similarly, "ae" and "æ" are <code>eq</code> if you don’t use locales, or if you use the English one, but they are different in the Icelandic locale.  Now what? It’s tough, I tell you.  You can play with  <a href="http://training.perl.com/scripts/ucsort" rel="noreferrer"><em>ucsort</em></a> to test some of these things out.</p></li>
<li><p>Consider how to match the pattern CVCV (consonsant, vowel, consonant, vowel)  in the string “<em>niño</em>”.  Its NFD form — which you had darned well better have remembered to put it in — becomes “nin\x{303}o”.  Now what are you going to do?  Even pretending that a vowel is <code>[aeiou]</code> (which is wrong, by the way), you won’t be able to do something like <code>(?=[aeiou])\X)</code> either, because even in NFD a code point like ‘ø’ <strong>does not decompose</strong>!  However, it will test equal to an ‘o’ using the UCA comparison I just showed you. You can’t rely on NFD, you have to rely on UCA. </p></li>
</ol>

<hr>

<h2>                💩          𝔸 𝕤 𝕤 𝕦 𝕞 𝕖   𝔹 𝕣 𝕠 𝕜 𝕖 𝕟 𝕟 𝕖 𝕤 𝕤           💩</h2>

<hr>

<p>And that’s not all. There are a million broken assumptions that people make about Unicode. Until they understand these things, their  🐪 code will be broken.</p>

<ol>
<li><p>Code that assumes it can open a text file without specifying the encoding is broken.</p></li>
<li><p>Code that assumes the default encoding is some sort of native platform encoding is broken.</p></li>
<li><p>Code that assumes that web pages in Japanese or Chinese take up less space in UTF‑16 than in UTF‑8 is wrong.</p></li>
<li><p>Code that assumes Perl uses UTF‑8 internally is wrong.</p></li>
<li><p>Code that assumes that encoding errors will always raise an exception is wrong.</p></li>
<li><p>Code that assumes Perl code points are limited to 0x10_FFFF is wrong.</p></li>
<li><p>Code that assumes you can set <code>$/</code> to something that will work with any valid line separator is wrong.</p></li>
<li><p>Code that assumes roundtrip equality on casefolding, like <code>lc(uc($s)) eq $s</code> or <code>uc(lc($s)) eq $s</code>, is completely broken and wrong.  Consider that the <code>uc("σ")</code> and <code>uc("ς")</code>  are both <code>"Σ"</code>, but <code>lc("Σ")</code> cannot possibly return both of those.</p></li>
<li><p>Code that assumes every lowercase code point has a distinct uppercase one, or vice versa, is broken. For example, <code>"ª"</code> is a lowercase letter with no uppercase; whereas both <code>"ᵃ"</code> and <code>"ᴬ"</code> are letters, but they are not lowercase letters; however, they are both lowercase code points without corresponding uppercase versions. Got that? They are <strong>not</strong> <code>\p{Lowercase_Letter}</code>, despite being both <code>\p{Letter}</code> and <code>\p{Lowercase}</code>.</p></li>
<li><p>Code that assumes changing the case doesn’t change the length of the string is broken.</p></li>
<li><p>Code that assumes there are only two cases is broken. There’s also titlecase.</p></li>
<li><p>Code that assumes only letters have case is broken. Beyond just letters, it turns out that numbers, symbols, and even marks have case. In fact, changing the case can even make something change its main general category, like a <code>\p{Mark}</code> turning into a <code>\p{Letter}</code>. It can also make it switch from one script to another.</p></li>
<li><p>Code that assumes that case is never locale-dependent is broken.</p></li>
<li><p>Code that assumes Unicode gives a fig about POSIX locales is broken.</p></li>
<li><p>Code that assumes you can remove diacritics to get at base ASCII letters is evil, still, broken, brain-damaged, wrong, and justification for capital punishment.</p></li>
<li><p>Code that assumes that diacritics <code>\p{Diacritic}</code> and marks <code>\p{Mark}</code> are the same thing is broken.</p></li>
<li><p>Code that assumes <code>\p{GC=Dash_Punctuation}</code> covers as much as <code>\p{Dash}</code> is broken.</p></li>
<li><p>Code that assumes dash, hyphens, and minuses are the same thing as each other, or that there is only one of each, is broken and wrong.</p></li>
<li><p>Code that assumes every code point takes up no more than one print column is broken.</p></li>
<li><p>Code that assumes that all <code>\p{Mark}</code> characters take up zero print columns is broken.</p></li>
<li><p>Code that assumes that characters which look alike <em>are</em> alike is broken.</p></li>
<li><p>Code that assumes that characters which do <em>not</em> look alike are <em>not</em> alike is broken.</p></li>
<li><p>Code that assumes there is a limit to the number of code points in a row that just one <code>\X</code> can match is wrong.</p></li>
<li><p>Code that assumes <code>\X</code> can never start with a <code>\p{Mark}</code> character is wrong.</p></li>
<li><p>Code that assumes that <code>\X</code> can never hold two non-<code>\p{Mark}</code> characters is wrong.</p></li>
<li><p>Code that assumes that it cannot use <code>"\x{FFFF}"</code> is wrong.</p></li>
<li><p>Code that assumes a non-BMP code point that requires two UTF-16 (surrogate) code units will encode to two separate UTF-8 characters, one per code unit, is wrong. It doesn’t: it encodes to single code point.</p></li>
<li><p>Code that transcodes from UTF‐16 or UTF‐32 with leading BOMs into UTF‐8 is broken if it puts a BOM at the start of the resulting UTF-8.  This is so stupid the engineer should have their eyelids removed.</p></li>
<li><p>Code that assumes the CESU-8 is a valid UTF encoding is wrong. Likewise, code that thinks encoding U+0000 as <code>"\xC0\x80"</code> is UTF-8 is broken and wrong. These guys also deserve the eyelid treatment.</p></li>
<li><p>Code that assumes characters like <code>&gt;</code> always points to the right and <code>&lt;</code> always points to the left are wrong — because they in fact do not.</p></li>
<li><p>Code that assumes if you first output character <code>X</code> and then character <code>Y</code>, that those will show up as <code>XY</code> is wrong. Sometimes they don’t.</p></li>
<li><p><strong>Code that assumes that ASCII is good enough for writing English properly is stupid, shortsighted, illiterate, broken, evil, and wrong.</strong>  Off with their heads! If that seems too extreme, we can compromise: henceforth they may type only with their big toe from one foot. (The rest will be duct taped.)</p></li>
<li><p>Code that assumes that all <code>\p{Math}</code> code points are visible characters is wrong.</p></li>
<li><p>Code that assumes <code>\w</code> contains only letters, digits, and underscores is wrong.</p></li>
<li><p>Code that assumes that <code>^</code> and <code>~</code> are punctuation marks is wrong.</p></li>
<li><p>Code that assumes that <code>ü</code> has an umlaut is wrong.</p></li>
<li><p>Code that believes things like <code>₨</code> contain any letters in them is wrong.</p></li>
<li><p>Code that believes <code>\p{InLatin}</code> is the same as <code>\p{Latin}</code> is  heinously broken. </p></li>
<li><p>Code that believe that <code>\p{InLatin}</code> is almost ever useful is almost certainly wrong.</p></li>
<li><p>Code that believes that given <code>$FIRST_LETTER</code> as the first letter in some alphabet and <code>$LAST_LETTER</code> as the last letter in that same alphabet, that <code>[${FIRST_LETTER}-${LAST_LETTER}]</code> has any meaning whatsoever is almost always complete broken and wrong and meaningless.</p></li>
<li><p>Code that believes someone’s name can only contain certain characters is stupid, offensive, and wrong.</p></li>
<li><p>Code that tries to reduce Unicode to ASCII is not merely wrong, its perpetrator should never be allowed to work in programming again. Period. I’m not even positive they should even be allowed to see again, since it obviously hasn’t done them much good so far.</p></li>
<li><p>Code that believes there’s some way to pretend textfile encodings don’t exist is broken and dangerous. Might as well poke the other eye out, too.</p></li>
<li><p>Code that converts unknown characters to <code>?</code> is broken, stupid, braindead, and runs contrary to the standard recommendation, which says <strong>NOT TO DO THAT!</strong> RTFM for why not.</p></li>
<li><p>Code that believes it can reliably guess the encoding of an unmarked textfile is guilty of a fatal mélange of hubris and naïveté that only a lightning bolt from  Zeus will fix.</p></li>
<li><p>Code that believes you can use 🐪 <code>printf</code> widths to pad and justify Unicode data is broken and wrong.</p></li>
<li><p>Code that believes once you successfully create a file by a given name, that when you run <code>ls</code> or <code>readdir</code> on its enclosing directory, you’ll actually find that file with the name you created it under is buggy, broken, and wrong. Stop being surprised by this!</p></li>
<li><p>Code that believes UTF-16 is a fixed-width encoding is stupid, broken, and wrong. Revoke their programming licence.</p></li>
<li><p>Code that treats code points from one plane one whit differently than those from any other plane is <em>ipso facto</em> broken and wrong. Go back to school.</p></li>
<li><p>Code that believes that stuff like <code>/s/i</code> can only match <code>"S"</code> or <code>"s"</code> is broken and wrong.  You’d be surprised.</p></li>
<li><p>Code that uses <code>\PM\pM*</code> to find grapheme clusters instead of using <code>\X</code> is broken and wrong.</p></li>
<li><p>People who want to go back to the ASCII world should be whole-heartedly encouraged to do so, and in honor of their glorious upgrade they should be provided <em>gratis</em> with a pre-electric manual typewriter for all their data-entry needs.  Messages sent to them should be sent via an ᴀʟʟᴄᴀᴘs telegraph at 40 characters per line and hand-delivered by a courier.  STOP.</p></li>
</ol>

<hr>

<h1>                        😱      𝕾 𝖀 𝕸 𝕸 𝕬 𝕽 𝖄     😱</h1>

<hr>

<p>I don’t know how much more “default Unicode in 🐪” you can get than what I’ve written. Well, yes I do: you should be using <code>Unicode::Collate</code> and <code>Unicode::LineBreak</code>, too.  And probably more.</p>

<p>As you see, there are far too many Unicode things that you really <em>do</em> have to worry about for there to <em>ever</em> exist any such thing as “default to Unicode”.</p>

<p>What you’re going to discover, just as we did back in 🐪 5.8, that it is simply impossible to impose all these things on code that hasn’t been designed right from the beginning to account for them. Your well-meaning selfishness just broke the entire world.</p>

<p>And even once you do, there are still critical issues that require a great deal of thought to get right.  There is no switch you can flip.  Nothing but brain, and I mean <em>real brain</em>, will suffice here. There’s a heck of a lot of stuff you have to learn. Modulo the retreat to the manual typewriter, you simply cannot hope to sneak by in ignorance. This is the 21ˢᵗ century, and you cannot wish Unicode away by willful ignorance. </p>

<p>You have to learn it. Period. It will never be so easy that “everything just works,” because that will guarantee that a lot of things <strong>don’t</strong> work — which invalidates the assumption that there can ever be a way to “make it all work.”</p>

<p>You may be able to get a few reasonable defaults for a very few and very limited operations, but not without thinking about things a whole lot more than I think you have.</p>

<p>As just one example, canonical ordering is going to cause some real headaches. 😭<code>"\x{F5}"</code> <strong>‘õ’</strong>, <code>"o\x{303}"</code> <strong>‘õ’</strong>, <code>"o\x{303}\x{304}"</code> <strong>‘ȭ’</strong>, and <code>"o\x{304}\x{303}"</code> <strong>‘ō̃’</strong> should all match <strong>‘õ’</strong>, but how in the world are you going to do that? This is harder than it looks, but it’s something you need to account for.  💣 </p>

<p>If there’s one thing I know about Perl, it is what its Unicode bits do and do not do, and this thing I promise you:  <strong>“   ̲ᴛ̲ʜ̲ᴇ̲ʀ̲ᴇ̲ ̲ɪ̲s̲ ̲ɴ̲ᴏ̲ ̲U̲ɴ̲ɪ̲ᴄ̲ᴏ̲ᴅ̲ᴇ̲ ̲ᴍ̲ᴀ̲ɢ̲ɪ̲ᴄ̲ ̲ʙ̲ᴜ̲ʟ̲ʟ̲ᴇ̲ᴛ̲ ̲  ”</strong>  😞 </p>

<p>You cannot just change some defaults and get smooth sailing.  It’s true that I run 🐪 with <code>PERL_UNICODE</code> set to <code>"SA"</code>, but that’s all, and even that is mostly for command-line stuff.  For real work, I go through all the many steps outlined above, and I do it very, ** very** carefully.</p>

<hr>

<h1>  😈 ¡ƨdləɥ ƨᴉɥʇ ədoɥ puɐ ʻλɐp əɔᴉu ɐ əʌɐɥ ʻʞɔnl poo⅁   😈</h1>
<h4> Comment 7174026 damageboy: </h4>Am I the only one who finds it ironic that this post by tchrist renders so wildly different on FF/Chrome/IE/Opera, sometime to the point of illegibility?<br><h4> Comment 7164462 w.k: </h4>Like Sherm Pendley pointed: &quot;All!&quot;. If i write today something new, UTF-8 should be <b>easiest</b> way to get things done. It is not. Your boilerplate prooves it. Not everyone has such knowledge to turn so many tumblers to right positions. I&#39;m sorry, i had long and hard day, so i will comment in main entry tomorrow more with examples.<br><h4> Comment 7185190 tchrist: </h4>@xenoterracide No I didn’t use intentionally problematic code points; it’s a plot to get you to install <a href="http://users.teilar.gr/~g1951d/" rel="nofollow noreferrer">George Douros’s super-awesome Symbola font</a>, which covers Unicode 6.0. 😈 @depesz There isn’t room here to explain why each broken assuption is wrong. @leonbloy <b>Lots and lots</b> of this applies to Unicode in general, not just Perl. Some of this material may show up in <a href="http://oreilly.com/catalog/9780596004927/" rel="nofollow noreferrer">🐪 Programming Perl 🐪, 4th edition</a>, due out in October. 🎃 I’ve one month left to ✍ work on it, and <b>Unicode is ᴍᴇɢᴀ</b> there; regexes, too<br><h4> Comment 7170786 Tim Bray: </h4>One conclusion should be obvious from reading the list above: Don&#39;t case-fold. Just don&#39;t. Ever. Computationally expensive and with semantics that depend crucially on whatever it is that &quot;locale&quot; tries unsuccessfully to identify.<br><h4> Comment 7180469 user80168: </h4>While I generally like the post, and did upvote, one thing bugs the hell out of me. There is a lot of &quot;code that ... is broken&quot;. While I don&#39;t argue with the statement, I think it would be good to show the brokenness. In this way it would traverse (this part of answer) from a rant, to education.<br><h4> Comment 7327588 clt60: </h4>Perfect answer. But the main point of the question is still here. In the 21th century SHOULD be working with unicode <b>much, much, much</b> easier and more intuitive. Yes, understand than &quot;no magic bullet is here&quot;. But the framework developers (like the above Mason2) really <i>SHOULD</i> care about it. Yes, I understand than it is a volunteer work and when i don&#39;t like the framework, it is easy do not useing it. But the all <b>unicode madness</b> in the perl really HURTS perl itself.<br><h4> Comment 7294858 tchrist: </h4>@Mark: No, it is not superfluous. I don&#39;t know who is going to decide that they don’t want to go all the way to 5.14. If they back down far enough, the strict goes away, and I never want that to happen. Therefore it is not superfluous. Plus it is declarative and therefore useful. Similarly, I like to make the <code>unicode_strings</code> feature explicit so that people realize it’s in effect. That&#39;s like how I often initialize things to 0 even when I don&#39;t have to: I like to signal my intent. I’m not fond of secret side-effects.<br><h4> Comment 7164545 tchrist: </h4>@wk: So it’s cool that code like <code>perl -i.bak -pe &#39;s&#47;foo&#47;bar&#39;</code> breaks? There’s a helluva lot of that in the world. What sort of comparison do you want for <code>eq</code>? A UCA3 compare? Does <code>lc</code> turn it into UCA1? How can you know? How’ll you match partial and/or discontiguous glyphs? Is it OK that all old code with 8-bit data in it now fails to compile? Is it ok that Perl no longer works on binary data? Is it ok to get different answers? Is it ok to diddle <code>a-z</code> out from under people without their consent? Is it ok to break-up graphemes? Is a 100x slowdown in sort code acceptable? What about filesys?<br><h4> Comment 7175088 xenoterracide: </h4>curious though if it was your intent to have many of the unicode characters unreadable due to lack of font support.<br><h4> Comment 7196764 w.k: </h4>@tchrist: thank you for your great answer, it helped to see a big picture. Still  i believe, that to resolve all those problems you pointed will take at least 10 years. And to resolve them effectively we need use Unicode day by day. If we say &quot;Unicode issues are too complex, lets resolve them before and make an ideal solution, use then&quot;, we can&#39;t move forward. And most growing software will not incorporate UTF-8 until this Great Day, even at minimum level. To have some clear point to rely on is <b>a must</b> (like <code>utf8::all</code>, but i prefer it in core). You may call it na&#239;vet&#233;.<br><h4> Comment 12930757 ikegami: </h4>Re &quot;Code that believes someone’s name can only contain certain characters is stupid, offensive, and wrong.&quot;, Did Unicode adopt the new name of the artist formerly known as Prince?<br><h4> Comment 28058650 mvmn: </h4>&quot;Code that believes once you successfully create a file by a given name, that when you run ls or readdir on its enclosing directory, you’ll actually find that file with the name you created it under is buggy, broken, and wrong.&quot; - I say any filesystem API that does that to it&#39;s user is the source of problem, and it - not user&#39;s code - should be fixed. Why would this kind of behaviour be considered correct? In your words, authors of such filesystem APIs should be... well, pick any horrific punishment yourself, you seem to be VERY good at it.<br><h4> Comment 7209272 Jan Goyvaerts: </h4>Even with the Symbola font installed, MSIE 9 does not render the camels and other symbols.  Firefox 3.6 on the same Windows 7 PC does renber all characters.<br><h4> Comment 7241162 Scott McIntyre: </h4>I installed Symbola, it doesn&#39;t fix it in Chrome.  Wonder if I need to restart? Unicode is hard.<br><h4> Comment 7387387 tchrist: </h4>@jm666 This much I grant you: that we should adopt a zero-tolerance policy <i>vis-&#224;-vis</i> Unicode compatibility in <i>all new code.</i> Yes, you will have to make a distinction between binary files of bytes and text files with characters in them, but the sorely abused Pʀɪsᴏɴᴇʀs Oꜰ Bɪʟʟ have had to do this since time immemorial. As far as I am concerned, any new code that deals with text <b><i>MUST ASSUME AND UNDERSTAND UNICODE</i></b>. I give suggestions above for how one might selectively upgrade some existing programs through envariables. But everybody needs to know Unicode. This has 0 to do with Perl.<br><h4> Comment 7290702 Mark Fowler: </h4>The &quot;use strict&quot; in the boilerplate is superfluous, if you&#39;ve said &quot;use 5.14.0&quot; then it&#39;s on by default.<br><h4> Comment 7697611 tchrist: </h4>@jm666: Yes, that’s right.  I forgot to mention that.  I found it, too.  It’s rather annoying.  And technically, it should <i>really</i> be <code>use open qw&lt;:encoding(UTF-8) :std&gt;</code> because you should be using the strict version of utf8, not the loose one.<br><h4> Comment 43594281 Vector Gorgoth: </h4>(1) A lot of what you say is true, in theory, but in practice-- well, very few people are talented enough to simultaneously handle every stipulation you make and ever get anything useful done; certainly not large enough number to service even a significant fraction of the companies who need perl programmers. (2) Even if enabling the boilerplate you include by default is insanity, there is no reason that some future version of Perl can&#39;t have the corresponding <code>use $version</code> pragma enable it on-demand. It&#39;s even crazier that ~50 lines of code are required just to &#39;enable Unicode&#39; in perl.<br><h4> Comment 43594395 Vector Gorgoth: </h4>A final note is that many of the stipulations made here imply that individuals (including native speakers) of any given language will have an absolutely correct understanding of their own language; this is never true in the general case, and so rarely true of specific individuals that it can be dismissed entirely as a possibility; it also assumes &quot;correct&quot; behavior is always desired! Programs exist to serve people, not to be perfect-- correctness is simply a side effect of performing the desired behavior consistently-- even when the desired behavior is &quot;incorrect&quot;!<br><h4> Comment 16047343 Mechanical snail: </h4>@tchrist &quot;Code that tries to reduce Unicode to ASCII is not merely wrong, its perpetrator should never be allowed to work in programming again.&quot; So you&#39;re firing the Stack Exchange team?<br><h4> Comment 12367145 Matt Fenwick: </h4>@tchrist how can I tell if I&#39;m seeing your post entirely correctly?  I&#39;ve installed the symbola font, which has improved things considerably, but there are still some white squares -- are there supposed to be?  I need a unit test!!!<br><h4> Comment 47140036 MarkI: </h4>You forgot to mention number 53: Code that assumes that characters have properties that can be trusted is broken. Every edition of the Unicode standard has things that are broken in it. You cite a perfect example: upper-case superscript &quot;A&quot; is lower-case. Under no circumstances can that be correct, so you can bet that that will change in the future, breaking all code you write today. And I know all about the &quot;guarantees&quot; that Unicode makes regarding future-proofing, they are almost as broken as Unicode is.<br><h4> Comment 53726865 user146043: </h4>It&#39;s 2015 and I&#39;ve a fully patched OS/browser (Firefox on Windows 7) and parts of that answer still don&#39;t render correctly.  What do I do to see this answer as it was supposed to be seen (or are all the bad control characters part of the point?)<br><h4> Comment 7697152 clt60: </h4>Just found than the boilerplate not working fully because of the bug in the &quot;autodie&quot;. When using open qw(:utf8 :std) pragma, the &quot;use autodie&quot; somewhat turn it off. So either open, or autodie - not both... ;) (old perl bug: <a href="http://stackoverflow.com/questions/4959384/does-the-autodie-pragma-have-influence-on-the-encoding/4959646#4959646" title="does the autodie pragma have influence on the encoding">stackoverflow.com/questions/4959384/&hellip;</a>)<br><h4> Comment 7314276 Joel Berger: </h4>Interestingly, after installing the Symbola fonts (Ubuntu/Chromium), some of the symbols show up, the others that are still boxes, if I highlight and right click, Chromium offers to search google for that character, which is shown perfectly in the context menu!<br><h4> Comment 7174541 Kent Fredric: </h4>@wk: the obvious problem will be utf8 bleed, data travelling from unicode-aware contexts to non-unicode-aware contexts ( ie: the 3rd party code you use in your code, your database, your host environment ( OS , filesystem, etc ) ) which can have dangerous circumstances. If you&#39;re not using prepared/bound queries for your Database interface, I have bad news for you.<br><h4> Comment 7168865 w.k: </h4>@tchrist: why should it break some old code, when we enable unicode use in <b>new</b> projects? Lets forget legacy code and core Perl. For example, is there any reason to avoid UTF-8 in Moose-based projects? If not, i think that Moose could enable UTF-8 support as widely as possible as it enables warnings and strict pragma. Now we just wasting time, because there is already a lot code written with Moose, which may break ;)<br><h4> Comment 7184715 leonbloy: </h4>Though I don&#39;t fully agree with some implications of this answer (I feel there is indeed some problem with the Perl CULTURE in relation with Unicode), that is matter of discussion:  this is a great answer and this is what makes SO so valuable. I agree specially with the &#39;assume brokeness&#39; general motto (not onyl for perl)<br><h4> Comment 7246087 tchrist: </h4>@Smackfu: Symbola made it work just fine for me under Chrome, which is pretty much as good as Opera.  Safari has the right glyphs, but seems to have non-scaling ideas of certain text blocks. Wonder why your Chrome isn’t good but mine is?<br><h4> Comment 7263903 tchrist: </h4>@leonbloy: You said <i>“I feel there is indeed some problem with the Perl CULTURE in relation with Unicode”</i>, and I am <i>𝔼𝕏𝕋ℝ𝔼𝕄𝔼𝕃𝕐</i> interested in hearing more about your point of view here. I happen to agree with you, but I don’t want to “lead the witness” and put words in your mouth. If there isn’t enough room here to go into it, please don’t hesitate to send me mail about this at my standard address of 𝕿𝖔𝖒 𝕮𝖍𝖗𝖎𝖘𝖙𝖎𝖆𝖓𝖘𝖊𝖓 &#65308;𝖙𝖈𝖍𝖗𝖎𝖘𝖙＠𝖕𝖊𝖗𝖑｡𝖈𝖔𝖒&#65310; — 𝒔𝒊𝒄𝒖𝒕 𝒊𝒏 𝒑𝒓𝒊𝒏𝒄𝒊𝒑𝒊𝒐 𝒆𝒕 𝒏𝒖𝒏𝒄 𝒆𝒕 𝒔𝒆𝒎𝒑𝒆𝒓.<br><h4> Comment 8997744 nordicdyno: </h4>&quot;Code that assumes that &#252; has an umlaut is wrong.&quot; - Why? I search and found 2 articles about that theme: <a href="http://en.wikipedia.org/wiki/%C3%9C" rel="nofollow noreferrer">en.wikipedia.org/wiki/%C3%9C</a> -&gt; <a href="http://en.wikipedia.org/wiki/Diaeresis_(diacritic)" rel="nofollow noreferrer">en.wikipedia.org/wiki/Diaeresis_(diacritic)</a>. Quote from second article: <i>&quot;The two uses originated separately, with the diaeresis being considerably older. <b>In modern computer systems using Unicode, the umlaut and diaeresis diacritics are identical</b>: ‹&#228;› represents both a-umlaut and a-diaeresis.&quot;</i> Is it true for Perl or not?<br><h4> Comment 9003645 tchrist: </h4>@nordicdyno: When in NFC it doesn’t have <code>COMBINING DIAERESIS</code>. Also, there are lookalikes like <code>NKO COMBINING DOUBLE DOT ABOVE</code>. But yes, the name of the mark is diaeresis.  The two functions are different linquistically: in the Spanish word <i>Arg&#252;elles</i> for example, there is no umlaut happening, and similarly in French <i>na&#239;ve</i>. The point is that you often cannot judge something by its appearance.<br><h4> Comment 7697949 clt60: </h4>Yes, :) but even so is hard to convert the boilerplate into the package for possibility &quot;use My::CorrectUtfPerl&quot;. (as you can see in the <a href="http://stackoverflow.com/q/6412799/632407">stackoverflow.com/q/6412799/632407</a>)<br><h4> Comment 7392450 tchrist: </h4>@ysth: I dunno. In 2E we took a lot of flak for <i>thingie</i>. So in 3E Jon and I, and perhaps also Damian, prevailed upon Larry to go for <i>referent</i>. But I confess I have at times resorting to <i>thingie</i> again. But it seems a strange mix having <i>invocant</i> on one side and <i>thingiemadongle</i> on the other, eh? Larry has Right-of-Last-Edit on 4E, so we’ll see what he does when he gets to those chapters (which I’m already done with).<br><h4> Comment 16047361 Mechanical snail: </h4>@tchrist: But seriously, +1 for the broken assumptions section. These need to be more widely known.<br><h4> Comment 19769018 tchrist: </h4>@J.F.Sebastian That&#39;s the PRESCRIPTION TAKE code point.  It&#39;s the Rx symbol.<br><h4> Comment 20992195 rjh: </h4>training.perl.com is currently down, but utilities such as unifmt can be found on CPAN, e.g. <a href="http://search.cpan.org/perldoc?unifmt" rel="nofollow noreferrer">search.cpan.org/perldoc?unifmt</a><br><h4> Comment 7391488 tchrist: </h4>@ysth: Considering that I personally have specific permission from Tim to use the 🐪 when discussing Perl for my website, writings, and business, and considering that I’m the primary author of the 4th edition of <i>Programming Perl</i> that I still haven’t finished the draft of, I find it highly unlikely that Tim would be annoyed. I certainly hope not. I’m sure I could spin this as an advert for him if I were hard-pressed to do so.<br><h4> Comment 7391730 ysth: </h4>@tchrist: it was a joke.  but can the 4th edition s/referent/thingy/ ?  I liked it soo much better.<br><h4> Comment 7387549 clt60: </h4>@tchrist - you&#39;re right and i understand and agree with your answer. 1. (as you told) module developers. I love volunteer developers - but in 21th century should be <b>zero tolerance</b> for not Unicode ready CPAN submissions. Simply delete, or (at least FLAG them). Non Unicode ready modules HURTs perl!. 2. perl6 - i hope than perl6 will have default utf8 enabled (because don&#39;t need maintain backward compat. - honestly, i know nothing about perl6 yet) 3. something like uni::perl (i&#39;m using it) (or something like your broilerplate) should be in CORE - for easy enabling all <i>common</i> utf8 features.<br><h4> Comment 7178578 Donal Fellows: </h4>@Kent: If they&#39;ve not used prepared queries, they&#39;ll probably have some other surprises coming their way too, SQL injection being one of the script kiddies favorite attack methods these days. Moreover, their code will be slow…<br><h4> Comment 53730896 tchrist: </h4>@Alex It’s always looked fine on Macs.<br><h4> Comment 44958940 Ed Avis: </h4>I think that as of perl 5.16 you can use the fc() builtin instead of Unicode::CaseFold.<br><h4> Comment 46813847 ikegami: </h4><code>binmode(DATA, &quot;:utf8&quot;);</code> is redundant with <code>use utf8;</code> since <code>DATA</code> is simply the file handle the Perl parser uses to read the file.<br><h4> Comment 46815135 tchrist: </h4>@ikegami You’re right. You only need it if you don’t have <code>use utf8;</code> in that compilation unit. Because a lot of times you don’t, it’s listed separately, as <code>use open</code> won’t catch it.<br><h4> Comment 15935859 unhammer: </h4>Amazingly good answer, very useful even for us who don&#39;t spend much time in perl :) BTW, on 23. (locale-dependent collate), you&#39;ve got &quot; &#240;&quot; where it should be &quot;&#240;&quot; (making it trivially non-equal =P)<br><h4> Comment 21136996 hippietrail: </h4>This is an amazlingly great answer! But I must nitpick an important point. Perl runs happily on many platforms, but this answer seems to only treat mainstream Unix style OSes. For instance all the <code>export FOO=BAR</code> won&#39;t work on Windows, some of the stuff about &quot;alien&quot; filesystems will be wrong as Windows uses UTF-16 and Mac OS X though it uses UTF-8 enforces a specific normalization form which doesn&#39;t change as new Unicode editions emerge. Running on those OSes they will be native filesystems and Unix filesystems will be the alien ones.<br><h4> Comment 19764866 jfs: </h4>What does <code>℞</code> (P&lt;sub&gt;x&lt;/sub&gt;) after <code>𝙎𝙞𝙢𝙥𝙡𝙚𝙨𝙩</code> mean?<br>------------------------------------------------------------------ <br><h3> Answer 6192088 jrockway: </h3><p>There are two stages to processing Unicode text. The first is "how can I input it and output it without losing information". The second is "how do I treat text according to local language conventions".</p>

<p>tchrist's post covers both, but the second part is where 99% of the text in his post comes from. Most programs don't even handle I/O correctly, so it's important to understand that before you even begin to worry about normalization and collation.</p>

<p>This post aims to solve that first problem</p>

<p>When you read data into Perl, it doesn't care what encoding it is. It allocates some memory and stashes the bytes away there. If you say <code>print $str</code>, it just blits those bytes out to your terminal, which is probably set to assume everything that is written to it is UTF-8, and your text shows up.</p>

<p>Marvelous.</p>

<p>Except, it's not. If you try to treat the data as text, you'll see that Something Bad is happening. You need go no further than <code>length</code> to see that what Perl thinks about your string and what you think about your string disagree. Write a one-liner like: <code>perl -E 'while(&lt;&gt;){ chomp; say length }'</code> and type in <code>文字化け</code> and you get 12... not the correct answer, 4.</p>

<p>That's because Perl assumes your string is not text. You have to tell it that it's text before it will give you the right answer.</p>

<p>That's easy enough; the Encode module has the functions to do that. The generic entry point is <code>Encode::decode</code> (or <code>use Encode qw(decode)</code>, of course). That function takes some string from the outside world (what we'll call "octets", a fancy of way of saying "8-bit bytes"), and turns it into some text that Perl will understand. The first argument is a character encoding name, like "UTF-8" or "ASCII" or "EUC-JP". The second argument is the string. The return value is the Perl scalar containing the text.</p>

<p>(There is also <code>Encode::decode_utf8</code>, which assumes UTF-8 for the encoding.)</p>

<p>If we rewrite our one-liner:</p>

<pre><code>perl -MEncode=decode -E 'while(&lt;&gt;){ chomp; say length decode("UTF-8", $_) }'
</code></pre>

<p>We type in 文字化け and get "4" as the result. Success.</p>

<p>That, right there, is the solution to 99% of Unicode problems in Perl.</p>

<p>The key is, whenever any text comes into your program, you must decode it. The Internet cannot transmit characters. Files cannot store characters. There are no characters in your database. There are only octets, and you can't treat octets as characters in Perl. You must decode the encoded octets into Perl characters with the Encode module.</p>

<p>The other half of the problem is getting data out of your program. That's easy to; you just say <code>use Encode qw(encode)</code>, decide what the encoding your data will be in (UTF-8 to terminals that understand UTF-8, UTF-16 for files on Windows, etc.), and then output the result of <code>encode($encoding, $data)</code> instead of just outputting <code>$data</code>.</p>

<p>This operation converts Perl's characters, which is what your program operates on, to octets that can be used by the outside world. It would be a lot easier if we could just send characters over the Internet or to our terminals, but we can't: octets only. So we have to convert characters to octets, otherwise the results are undefined.</p>

<p>To summarize: encode all outputs and decode all inputs.</p>

<p>Now we'll talk about three issues that make this a little challenging. The first is libraries. Do they handle text correctly? The answer is... they try. If you download a web page, LWP will give you your result back as text. If you call the right method on the result, that is (and that happens to be <code>decoded_content</code>, not <code>content</code>, which is just the octet stream that it got from the server.) Database drivers can be flaky; if you use DBD::SQLite with just Perl, it will work out, but if some other tool has put text stored as some encoding other than UTF-8 in your database... well... it's not going to be handled correctly until you write code to handle it correctly.</p>

<p>Outputting data is usually easier, but if you see "wide character in print", then you know you're messing up the encoding somewhere. That warning means "hey, you're trying to leak Perl characters to the outside world and that doesn't make any sense". Your program appears to work (because the other end usually handles the raw Perl characters correctly), but it is very broken and could stop working at any moment. Fix it with an explicit <code>Encode::encode</code>!</p>

<p>The second problem is UTF-8 encoded source code. Unless you say <code>use utf8</code> at the top of each file, Perl will not assume that your source code is UTF-8. This means that each time you say something like <code>my $var = 'ほげ'</code>, you're injecting garbage into your program that will totally break everything horribly. You don't have to "use utf8", but if you don't, you <em>must</em> not use any non-ASCII characters in your program.</p>

<p>The third problem is how Perl handles The Past. A long time ago, there was no such thing as Unicode, and Perl assumed that everything was Latin-1 text or binary. So when data comes into your program and you start treating it as text, Perl treats each octet as a Latin-1 character. That's why, when we asked for the length of "文字化け", we got 12. Perl assumed that we were operating on the  Latin-1 string "æå­åã" (which is 12 characters, some of which are non-printing).</p>

<p>This is called an "implicit upgrade", and it's a perfectly reasonable thing to do, but it's not what you want if your text is not Latin-1. That's why it's critical to explicitly decode input: if you don't do it, Perl will, and it might do it wrong.</p>

<p>People run into trouble where half their data is a proper character string, and some is still binary. Perl will interpret the part that's still binary as though it's Latin-1 text and then combine it with the correct character data. This will make it look like handling your characters correctly broke your program, but in reality, you just haven't fixed it enough.</p>

<p>Here's an example: you have a program that reads a UTF-8-encoded text file, you tack on a Unicode <code>PILE OF POO</code> to each line, and you print it out. You write it like:</p>

<pre><code>while(&lt;&gt;){
    chomp;
    say "$_ 💩";
}
</code></pre>

<p>And then run on some UTF-8 encoded data, like:</p>

<pre><code>perl poo.pl input-data.txt
</code></pre>

<p>It prints the UTF-8 data with a poo at the end of each line. Perfect, my program works!</p>

<p>But nope, you're just doing binary concatenation. You're reading octets from the file, removing a <code>\n</code> with chomp, and then tacking on the bytes in the UTF-8 representation of the <code>PILE OF POO</code> character. When you revise your program to decode the data from the file and encode the output, you'll notice that you get garbage ("ð©") instead of the poo. This will lead you to believe that decoding the input file is the wrong thing to do. It's not.</p>

<p>The problem is that the poo is being implicitly upgraded as latin-1. If you <code>use utf8</code> to make the literal text instead of binary, then it will work again!</p>

<p>(That's the number one problem I see when helping people with Unicode. They did part right and that broke their program. That's what's sad about undefined results: you can have a working program for a long time, but when you start to repair it, it breaks. Don't worry; if you are adding encode/decode statements to your program and it breaks, it just means you have more work to do. Next time, when you design with Unicode in mind from the beginning, it will be much easier!)</p>

<p>That's really all you need to know about Perl and Unicode. If you tell Perl what your data is, it has the best Unicode support among all popular programming languages. If you assume it will magically know what sort of text you are feeding it, though, then you're going to trash your data irrevocably. Just because your program works today on your UTF-8 terminal doesn't mean it will work tomorrow on a UTF-16 encoded file. So make it safe now, and save yourself the headache of trashing your users' data!</p>

<p>The easy part of handling Unicode is encoding output and decoding input. The hard part is finding all your input and output, and determining which encoding it is. But that's why you get the big bucks :)</p>
<h4> Comment 77877347 Palec: </h4>The principle is explained well, but the practical approach for I/O is missing. Explicitly using the <code>Encode</code> module is tedious and error-prone, and it makes reading the code concerning I/O really painful. I/O layers provide a solution as they transparently encode and decode, where needed. <code>open</code> and <code>binmode</code> allow for their specification, and pragma <code>open</code> sets the defaults, as tchrist recommends in his answer.<br>------------------------------------------------------------------ <br><h3> Answer 6169757 Randy Stauner: </h3><p>We're all in agreement that it is a difficult problem for many reasons,
but that's precisely the reason to try to make it easier on everybody.</p>

<p>There is a recent module on CPAN, <a href="http://search.cpan.org/perldoc?utf8::all" rel="noreferrer">utf8::all</a>, that attempts to "turn on Unicode. All of it".</p>

<p>As has been pointed out, you can't magically make the entire system (outside programs, external web requests, etc.) use Unicode as well, but we can work together to make sensible tools that make doing common problems easier.  That's the reason that we're programmers.</p>

<p>If utf8::all doesn't do something you think it should, let's improve it to make it better. Or let's make additional tools that together can suit people's varying needs as well as possible.</p>

<p>`</p>
<h4> Comment 7394669 Schwern: </h4>@tchrist The issue tracker for utf8::all is here.  <a href="https://github.com/doherty/utf8-all/issues" rel="nofollow noreferrer">github.com/doherty/utf8-all/issues</a>  They&#39;d love to hear your suggestions.<br><h4> Comment 7387480 tchrist: </h4>I see lots of <b>room for improvement</b> in the cited <code>utf8::all</code> module. It was written before the <code>unicode_strings</code> feature, which Fɪɴᴀʟʟʏ ᴀɴᴅ ᴀᴛ Lᴏɴɢ Lᴀsᴛ fixes regexes to have a <code>&#47;u</code> on them. I’m not convinced it raises an exception on encoding errors, and that is something you truly must have. It doesn’t load in the <code>use charnames &quot;:full&quot;</code> pragma, which isn’t yet autloaded. It doesn’t warn on <code>[a-z]</code> and such, <code>printf</code> string widths, using <code>\n</code> instead of <code>\R</code> and <code>.</code> instead of <code>\X</code>, but maybe those’re more a <code>Perl::Critic</code> matter. If it were I, I’d add 𝐍𝐅𝐃 in and 𝐍𝐅𝐂 out.<br><h4> Comment 7397194 tchrist: </h4>@Schwern: ᴇɴᴏᴛᴜɪᴛs, but feel free to pilfer and pinch from the stuff I’ve written here. To be honest, I’m still feeling/learning what can be done vs what should be done, and where. Here’s a nice example off offloading sorting: <code>unichars -gs &#39;&#47;(?=\P{Ll})\p{Lower}|(?=\P{Lu})\p{Upper}&#47;x&#39; | ucsort --upper | cat -n | less -r</code>. Similarly, little preprocessing steps like <code>... | ucsort --upper --preprocess=&#39;s&#47;(\d+)&#47;sprintf &quot;%#012d&quot;, $1&#47;ge&#39;</code> can be really nice, too, and I wouldn’t want to make others’ decisions for them. I’m still <a href="http://training.perl.com/scripts/" rel="nofollow noreferrer">building my Unicode toolbox</a>.<br>------------------------------------------------------------------ <br><h3> Answer 6169374 brian d foy: </h3><p>I think you misunderstand Unicode and its relationship to Perl. No matter which way you store data, Unicode, <a href="http://en.wikipedia.org/wiki/ISO/IEC_8859-1" rel="nofollow noreferrer">ISO-8859-1</a>, or many other things, your program has to know how to interpret the bytes it gets as input (decoding) and how to represent the information it wants to output (encoding). Get that interpretation wrong and you garble the data. There isn't some magic default setup inside your program that's going to tell the stuff outside your program how to act.</p>
<p>You think it's hard, most likely, because you are used to everything being ASCII. Everything you should have been thinking about was simply ignored by the programming language and all of the things it had to interact with. If everything used nothing but UTF-8 and you had no choice, then UTF-8 would be just as easy. But not everything does use UTF-8. For instance, you don't want your input handle to think that it's getting UTF-8 octets unless it actually is, and you don't want your output handles to be UTF-8 if the thing reading from them can't handle UTF-8. Perl has no way to know those things. That's why you are the programmer.</p>
<p>I don't think Unicode in Perl 5 is too complicated. I think it's scary and people avoid it. There's a difference. To that end, I've put Unicode in <i>Learning Perl, 6th Edition</i>, and there's a lot of Unicode stuff in <i>Effective Perl Programming</i>. You have to spend the time to learn and understand Unicode and how it works. You're not going to be able to use it effectively otherwise.</p>
<h4> Comment 7172657 w.k: </h4>I think you have a point: it is scary. Should it be? For me is Unicode blessing, using it in Perl5 is not (i don&#39;t assume anything being ASCII, my mother tongue needs at least iso8859-4).   I installed Rakudo and everything i tried with UTF-8 (in this limited sandbox) worked out of box. Did i miss something? I stress it again: it is good to have fine tuned Unicode support, but on most time is no need for that. To get fear away on topic, one way is that everyone reads a lot to understand internals. Other: we have special pragma, so <code>use utf8_everywhere</code> makes people happy. Why not last one?<br><h4> Comment 7174952 brian d foy: </h4>I still think you&#39;re missing the point. What worked? You don&#39;t need to understand internals. You need to understand <i>externals</i> and how to you want to handle strings that have different encodings and different representations of the same characters. Read Tom&#39;s advice again. Most of what he says I bet you&#39;ll find Rakudo doesn&#39;t handle for you.<br><h4> Comment 7358787 w.k: </h4>@brian d foy: i think that those limitation are fine, like tchrist says, there is no magic bullet for every aspect (i admit: i did not saw most of them before asking this question here). So, when we cover lots of basic stuff with something like utf8::all, there is no need for everyone to build his own huge boilerplate only to get basics on utf8 handling to work. With &quot;no fear at all&quot; i mean: everyone can start his projects knowing that basics are covered. Yes, you are right, there is still lots of problems. But when starting is easier, we will have more people involved in solving those. IMHO<br><h4> Comment 7269018 brian d foy: </h4>@wk: Read Randy&#39;s answer again. He&#39;s already told you what the limitations are.<br><h4> Comment 7390151 clt60: </h4>@wk - the only &quot;wrong&quot; with the &quot;utf8:all&quot; or &quot;uni::perl is only one - they are not in the CORE - so everyone must install it from the CPAN. And if you think that this not a big deal - rethink please - yes, it is easier use utf8 with a helper module. Without it, the CORE perl still has unicode support - but much-much complicated. And this is wrong.<br><h4> Comment 9363272 w.k: </h4>@jm666: i am really confused, why you addressed this comment to me? I&#39;d like to have something like <code>utf8::all</code> in core, but it does not depend of my desire. The whole topic i raised here is in one sentence: how to get UTF-8 handling as easy as possible? So your comment is rephrase of my whole problem. I don&#39;t understand, what should i rethink?<br><h4> Comment 7180669 w.k: </h4>Maybe you are right and i miss the point, i don&#39;t want to argue. [And i certainly read Tom&#39;s answer more and more.] But Randy Stauner pointed in his answer new module <a href="http://search.cpan.org/perldoc?utf8%3a%3aall" rel="nofollow noreferrer">utf::all</a>. Is there something wrong with such module? Shouldn&#39;t we have it (or similar) with core Perl? From my point of view it makes using UTF-8 so much easier and code clean. No fear at all.<br><h4> Comment 114536534 Peter Mortensen: </h4>Re <i>&quot;you don&#39;t want your output handles to be UTF-8 if the thing reading from them can handle UTF-8&quot;</i>: Don&#39;t you mean <i>&quot;...from them</i> <b><i>can&#39;t</i></b> <i>handle UTF-8&quot;</i>?<br><h4> Comment 114537752 brian d foy: </h4>@PeterMortensen yeah, that makes more sense :)<br>------------------------------------------------------------------ <br><h3> Answer 6174609 MeirG: </h3><p>While reading this thread, I often get the impression that people are using "<a href="http://en.wikipedia.org/wiki/UTF-8" rel="noreferrer">UTF-8</a>" as a synonym to "<a href="http://en.wikipedia.org/wiki/Unicode" rel="noreferrer">Unicode</a>". Please make a distinction between Unicode's "Code-Points" which are an enlarged relative of the ASCII code and Unicode's various "encodings". And there are a few of them, of which UTF-8, <a href="https://en.wikipedia.org/wiki/UTF-16" rel="noreferrer">UTF-16</a> and <a href="https://en.wikipedia.org/wiki/UTF-32" rel="noreferrer">UTF-32</a> are the current ones and a few more are obsolete.</p>

<p>Please, UTF-8 (as well as all other <em>encodings</em>) exists and have meaning in input or in output only. Internally, since Perl 5.8.1, all strings are kept as Unicode "Code-points". True, you have to enable some features as admiringly covered previously.</p>
<h4> Comment 7203657 tchrist: </h4>I agree  people too often confuse Uɴɪᴄᴏᴅᴇ with UTF-8⧸16⧸32, but <b>it’s fundamentally and critically <i>not true</i> that Uɴɪᴄᴏᴅᴇ is just some enlarged character set relative to ᴀsᴄɪɪ.</b> At most, that’s <a href="http://en.wikipedia.org/wiki/Universal_Character_Set#Differences_between_ISO_10646_and_Unicode" rel="nofollow noreferrer">nothing more than mere ɪsᴏ‑10646</a>. <b>Uɴɪᴄᴏᴅᴇ includes much more</b>: rules for <i>collation,casefolding,normalization forms,grapheme clusters,word-&amp;line-breaking,scripts,numeric equivs,widths,bidirectionality,glyph variants,contextual behavior,locales,regexes,combining classes,100s of properties,&amp; much more‼</i><br><h4> Comment 7208031 jrockway: </h4>@tchrist: the first step is to get data into your program and out to the outside world without trashing it.  then you can worry about collation, case folding, glyph variants, etc.  baby steps.<br><h4> Comment 8106083 hlovdal: </h4>I agree, getting perl not to trash input or output must be the first priority. What I would like was to have a module or pragma that could embody the following fictitious conversation: &quot;- Dear Perl. For this program, all input and output will be will be UTF-8 exclusively. Could you please not trash my data? - So only UFT-8 you say. Are you sure? - Yes. - Really, really sure? - Absolutely. - And you accept that I might behave strangely if I&#39;m served non-UTF-8 data? - Yes, fine. - Ok then.&quot;<br>------------------------------------------------------------------ <br><h3> Answer 6162515 geekosaur: </h3><p>There's a truly horrifying amount of ancient code out there in the wild, much of it in the form of common CPAN modules.  I've found I have to be fairly careful enabling Unicode if I use external modules that might be affected by it, and am still trying to identify and fix some Unicode-related failures in several Perl scripts I use regularly (in particular, <a href="http://code.google.com/p/itivo/" rel="noreferrer">iTiVo</a> fails badly on anything that's not 7-bit ASCII due to transcoding issues).</p>
<h4> Comment 7162092 tchrist: </h4>A lone <code>-C</code> without options is <b>buggy and error-prone</b>.  You break the world.  Set the <code>PERL5OPT</code> envariable to <code>-C</code> and you will see what I mean. We tried this way back in v5.8, and it was a disaster. You simply cannot and must not tell programs that aren’t expecting it that now they are dealing with Unicode whether they like it or not. There are also security issues. At the very least, anything that does <code>print while &lt;&gt;</code> will break if passed binary data. So too will all database code. This is a terrible idea.<br><h4> Comment 7162142 geekosaur: </h4>I was talking generically, actually, not specifically <code>-C</code> without options. The specific invocation I had been working with was <code>-CSDA</code>. That said, I was stuck with 5.8.x for a long time (hello MacPorts...), so maybe that <i>was</i> part of it.<br><h4> Comment 7162173 tchrist: </h4>I run with PERL_UNICODE set to SA.  You <b>CANNOT</b> set it to D.<br><h4> Comment 13743990 Ashley: </h4>@tchrist: Some Perl varmint has been <a href="http://www.perl.com/pub/2012/05/perlunicook-make-all-io-default-to-utf-8.html" rel="nofollow noreferrer">posting code showing the -CSDA  and PERL_UNICODE=SDA usage</a>. Please use your influence in the community. He must be stopped!<br><h4> Comment 40778400 aidan: </h4>@tchrist &quot;A lone -C without options is buggy and error-prone.&quot; <code>perldoc perlrun</code> is clear about what <code>-C</code> means. Do you advise against using it because it behaves differently in different versions of Perl? I tried setting <code>PERL5OPT</code> as suggested and saw no difference.<br><h4> Comment 7162005 geekosaur: </h4>I meant using the <code>-C</code> option to make sure Perl is on the same page as I am Unicode-wise, because I keep having it decide to use ISO 8859/1 instead of Unicode even though I am explicitly setting <code>$LANG</code> and <code>$LC_ALL</code> properly. (This may actually reflect bugs in the platform locale libraries.) Whatever it is, it&#39;s been highly annoying that I can&#39;t use iTivo on programs with accents in them because the Perl scripts that do the work fall over with conversion errors.<br>------------------------------------------------------------------ <br><h3> Answer 50329771 rurban: </h3><p>You should enable the Unicode strings feature, and this is the default if you use <code>v5.14;</code>.</p>
<p>You should not really use Unicode identifiers, especially for foreign code via UTF-8 as they are insecure in Perl 5; only cperl got that right. See e.g. <a href="http://perl11.github.io/blog/unicode-identifiers.html" rel="nofollow noreferrer">http://perl11.github.io/blog/unicode-identifiers.html</a></p>
<p>Regarding UTF-8 for your filehandles/streams: You need decide by yourself the encoding of your external data. A library cannot know that, and since not even <a href="https://en.wikipedia.org/wiki/C_standard_library" rel="nofollow noreferrer">libc</a> supports UTF-8, proper UTF-8 data is rare. There's more <a href="https://en.wikipedia.org/wiki/UTF-8#WTF-8" rel="nofollow noreferrer">WTF-8</a>, the Windows aberration of UTF-8 around.</p>
<p>BTW: <a href="https://en.wikipedia.org/wiki/Moose_(Perl)" rel="nofollow noreferrer">Moose</a> is not really &quot;Modern Perl&quot;; they just hijacked the name. Moose is perfect <a href="https://en.wikipedia.org/wiki/Larry_Wall" rel="nofollow noreferrer">Larry Wall</a>-style postmodern Perl mixed with <a href="https://en.wikipedia.org/wiki/Bjarne_Stroustrup" rel="nofollow noreferrer">Bjarne Stroustrup</a>-style everything goes, with an eclectic aberration of proper <a href="https://en.wikipedia.org/wiki/Raku_(programming_language)" rel="nofollow noreferrer">Perl 6</a> syntax, e.g., using strings for variable names, horrible fields syntax, and a very immature naive implementation which is 10x slower than a proper implementation.</p>
<p>cperl and Perl 6 are the true modern Perl implementations, where form follows function, and the implementation is reduced and optimized.</p>
<h4> Comment 136613343 Peter Mortensen: </h4>The perl11.org link is broken: <i>&quot;Unable to connect. An error occurred during a connection to perl11.org.&quot;</i><br>